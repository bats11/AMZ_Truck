import {
  Color3,
  DrawWrapper,
  Effect,
  EncodeArrayBufferToBase64,
  EngineStore,
  Epsilon,
  GetClass,
  InstantiationTools,
  InternalTexture,
  InternalTextureSource,
  IsDocumentAvailable,
  IsWindowObjectExist,
  LoadImage,
  Logger,
  Matrix,
  Observable,
  PerfCounter,
  Plane,
  PostProcessManager,
  PrecisionDate,
  Quaternion,
  RandomGUID,
  RegisterClass,
  RenderingManager,
  Scalar,
  Scene,
  SerializationHelper,
  ShaderLanguage,
  ShaderStore,
  SmartArray,
  ThinEngine,
  TimingTools,
  TmpVectors,
  ToLinearSpace,
  Tools,
  Vector2,
  Vector3,
  VertexBuffer,
  WebGLDataBuffer,
  WebGLHardwareTexture,
  _ObserveArray,
  _WarnImport,
  __decorate,
  serialize,
  serializeAsColor4,
  serializeAsTexture
} from "./chunk-DCOFHBAG.js";

// node_modules/@babylonjs/core/Maths/math.size.js
var Size = class _Size {
  /**
   * Creates a Size object from the given width and height (floats).
   * @param width width of the new size
   * @param height height of the new size
   */
  constructor(width, height) {
    this.width = width;
    this.height = height;
  }
  /**
   * Returns a string with the Size width and height
   * @returns a string with the Size width and height
   */
  toString() {
    return `{W: ${this.width}, H: ${this.height}}`;
  }
  /**
   * "Size"
   * @returns the string "Size"
   */
  getClassName() {
    return "Size";
  }
  /**
   * Returns the Size hash code.
   * @returns a hash code for a unique width and height
   */
  getHashCode() {
    let hash = this.width | 0;
    hash = hash * 397 ^ (this.height | 0);
    return hash;
  }
  /**
   * Updates the current size from the given one.
   * @param src the given size
   */
  copyFrom(src) {
    this.width = src.width;
    this.height = src.height;
  }
  /**
   * Updates in place the current Size from the given floats.
   * @param width width of the new size
   * @param height height of the new size
   * @returns the updated Size.
   */
  copyFromFloats(width, height) {
    this.width = width;
    this.height = height;
    return this;
  }
  /**
   * Updates in place the current Size from the given floats.
   * @param width width to set
   * @param height height to set
   * @returns the updated Size.
   */
  set(width, height) {
    return this.copyFromFloats(width, height);
  }
  /**
   * Multiplies the width and height by numbers
   * @param w factor to multiple the width by
   * @param h factor to multiple the height by
   * @returns a new Size set with the multiplication result of the current Size and the given floats.
   */
  multiplyByFloats(w, h) {
    return new _Size(this.width * w, this.height * h);
  }
  /**
   * Clones the size
   * @returns a new Size copied from the given one.
   */
  clone() {
    return new _Size(this.width, this.height);
  }
  /**
   * True if the current Size and the given one width and height are strictly equal.
   * @param other the other size to compare against
   * @returns True if the current Size and the given one width and height are strictly equal.
   */
  equals(other) {
    if (!other) {
      return false;
    }
    return this.width === other.width && this.height === other.height;
  }
  /**
   * The surface of the Size : width * height (float).
   */
  get surface() {
    return this.width * this.height;
  }
  /**
   * Create a new size of zero
   * @returns a new Size set to (0.0, 0.0)
   */
  static Zero() {
    return new _Size(0, 0);
  }
  /**
   * Sums the width and height of two sizes
   * @param otherSize size to add to this size
   * @returns a new Size set as the addition result of the current Size and the given one.
   */
  add(otherSize) {
    const r = new _Size(this.width + otherSize.width, this.height + otherSize.height);
    return r;
  }
  /**
   * Subtracts the width and height of two
   * @param otherSize size to subtract to this size
   * @returns a new Size set as the subtraction result of  the given one from the current Size.
   */
  subtract(otherSize) {
    const r = new _Size(this.width - otherSize.width, this.height - otherSize.height);
    return r;
  }
  /**
   * Scales the width and height
   * @param scale the scale to multiply the width and height by
   * @returns a new Size set with the multiplication result of the current Size and the given floats.
   */
  scale(scale) {
    return new _Size(this.width * scale, this.height * scale);
  }
  /**
   * Creates a new Size set at the linear interpolation "amount" between "start" and "end"
   * @param start starting size to lerp between
   * @param end end size to lerp between
   * @param amount amount to lerp between the start and end values
   * @returns a new Size set at the linear interpolation "amount" between "start" and "end"
   */
  static Lerp(start, end, amount) {
    const w = start.width + (end.width - start.width) * amount;
    const h = start.height + (end.height - start.height) * amount;
    return new _Size(w, h);
  }
};

// node_modules/@babylonjs/core/Maths/math.axis.js
var Space;
(function(Space2) {
  Space2[Space2["LOCAL"] = 0] = "LOCAL";
  Space2[Space2["WORLD"] = 1] = "WORLD";
  Space2[Space2["BONE"] = 2] = "BONE";
})(Space || (Space = {}));
var Axis = class {
};
Axis.X = new Vector3(1, 0, 0);
Axis.Y = new Vector3(0, 1, 0);
Axis.Z = new Vector3(0, 0, 1);
var Coordinate;
(function(Coordinate2) {
  Coordinate2[Coordinate2["X"] = 0] = "X";
  Coordinate2[Coordinate2["Y"] = 1] = "Y";
  Coordinate2[Coordinate2["Z"] = 2] = "Z";
})(Coordinate || (Coordinate = {}));

// node_modules/@babylonjs/core/Maths/math.path.js
var Orientation;
(function(Orientation2) {
  Orientation2[Orientation2["CW"] = 0] = "CW";
  Orientation2[Orientation2["CCW"] = 1] = "CCW";
})(Orientation || (Orientation = {}));
var BezierCurve = class {
  /**
   * Returns the cubic Bezier interpolated value (float) at "t" (float) from the given x1, y1, x2, y2 floats
   * @param t defines the time
   * @param x1 defines the left coordinate on X axis
   * @param y1 defines the left coordinate on Y axis
   * @param x2 defines the right coordinate on X axis
   * @param y2 defines the right coordinate on Y axis
   * @returns the interpolated value
   */
  static Interpolate(t, x1, y1, x2, y2) {
    const f0 = 1 - 3 * x2 + 3 * x1;
    const f1 = 3 * x2 - 6 * x1;
    const f2 = 3 * x1;
    let refinedT = t;
    for (let i = 0; i < 5; i++) {
      const refinedT2 = refinedT * refinedT;
      const refinedT3 = refinedT2 * refinedT;
      const x = f0 * refinedT3 + f1 * refinedT2 + f2 * refinedT;
      const slope = 1 / (3 * f0 * refinedT2 + 2 * f1 * refinedT + f2);
      refinedT -= (x - t) * slope;
      refinedT = Math.min(1, Math.max(0, refinedT));
    }
    return 3 * Math.pow(1 - refinedT, 2) * refinedT * y1 + 3 * (1 - refinedT) * Math.pow(refinedT, 2) * y2 + Math.pow(refinedT, 3);
  }
};
var Angle = class _Angle {
  /**
   * Creates an Angle object of "radians" radians (float).
   * @param radians the angle in radians
   */
  constructor(radians) {
    this._radians = radians;
    if (this._radians < 0) {
      this._radians += 2 * Math.PI;
    }
  }
  /**
   * Get value in degrees
   * @returns the Angle value in degrees (float)
   */
  degrees() {
    return this._radians * 180 / Math.PI;
  }
  /**
   * Get value in radians
   * @returns the Angle value in radians (float)
   */
  radians() {
    return this._radians;
  }
  /**
   * Gets a new Angle object with a value of the angle (in radians) between the line connecting the two points and the x-axis
   * @param a defines first point as the origin
   * @param b defines point
   * @returns a new Angle
   */
  static BetweenTwoPoints(a, b) {
    const delta = b.subtract(a);
    const theta = Math.atan2(delta.y, delta.x);
    return new _Angle(theta);
  }
  /**
   * Gets the angle between the two vectors
   * @param a defines first vector
   * @param b defines vector
   * @returns Returns an new Angle between 0 and PI
   */
  static BetweenTwoVectors(a, b) {
    let product = a.lengthSquared() * b.lengthSquared();
    if (product === 0)
      return new _Angle(Math.PI / 2);
    product = Math.sqrt(product);
    let cosVal = a.dot(b) / product;
    cosVal = Scalar.Clamp(cosVal, -1, 1);
    const angle = Math.acos(cosVal);
    return new _Angle(angle);
  }
  /**
   * Gets a new Angle object from the given float in radians
   * @param radians defines the angle value in radians
   * @returns a new Angle
   */
  static FromRadians(radians) {
    return new _Angle(radians);
  }
  /**
   * Gets a new Angle object from the given float in degrees
   * @param degrees defines the angle value in degrees
   * @returns a new Angle
   */
  static FromDegrees(degrees) {
    return new _Angle(degrees * Math.PI / 180);
  }
};
var Arc2 = class {
  /**
   * Creates an Arc object from the three given points : start, middle and end.
   * @param startPoint Defines the start point of the arc
   * @param midPoint Defines the middle point of the arc
   * @param endPoint Defines the end point of the arc
   */
  constructor(startPoint, midPoint, endPoint) {
    this.startPoint = startPoint;
    this.midPoint = midPoint;
    this.endPoint = endPoint;
    const temp = Math.pow(midPoint.x, 2) + Math.pow(midPoint.y, 2);
    const startToMid = (Math.pow(startPoint.x, 2) + Math.pow(startPoint.y, 2) - temp) / 2;
    const midToEnd = (temp - Math.pow(endPoint.x, 2) - Math.pow(endPoint.y, 2)) / 2;
    const det = (startPoint.x - midPoint.x) * (midPoint.y - endPoint.y) - (midPoint.x - endPoint.x) * (startPoint.y - midPoint.y);
    this.centerPoint = new Vector2((startToMid * (midPoint.y - endPoint.y) - midToEnd * (startPoint.y - midPoint.y)) / det, ((startPoint.x - midPoint.x) * midToEnd - (midPoint.x - endPoint.x) * startToMid) / det);
    this.radius = this.centerPoint.subtract(this.startPoint).length();
    this.startAngle = Angle.BetweenTwoPoints(this.centerPoint, this.startPoint);
    const a1 = this.startAngle.degrees();
    let a2 = Angle.BetweenTwoPoints(this.centerPoint, this.midPoint).degrees();
    let a3 = Angle.BetweenTwoPoints(this.centerPoint, this.endPoint).degrees();
    if (a2 - a1 > 180) {
      a2 -= 360;
    }
    if (a2 - a1 < -180) {
      a2 += 360;
    }
    if (a3 - a2 > 180) {
      a3 -= 360;
    }
    if (a3 - a2 < -180) {
      a3 += 360;
    }
    this.orientation = a2 - a1 < 0 ? Orientation.CW : Orientation.CCW;
    this.angle = Angle.FromDegrees(this.orientation === Orientation.CW ? a1 - a3 : a3 - a1);
  }
};
var Path2 = class _Path2 {
  /**
   * Creates a Path2 object from the starting 2D coordinates x and y.
   * @param x the starting points x value
   * @param y the starting points y value
   */
  constructor(x, y) {
    this._points = new Array();
    this._length = 0;
    this.closed = false;
    this._points.push(new Vector2(x, y));
  }
  /**
   * Adds a new segment until the given coordinates (x, y) to the current Path2.
   * @param x the added points x value
   * @param y the added points y value
   * @returns the updated Path2.
   */
  addLineTo(x, y) {
    if (this.closed) {
      return this;
    }
    const newPoint = new Vector2(x, y);
    const previousPoint = this._points[this._points.length - 1];
    this._points.push(newPoint);
    this._length += newPoint.subtract(previousPoint).length();
    return this;
  }
  /**
   * Adds _numberOfSegments_ segments according to the arc definition (middle point coordinates, end point coordinates, the arc start point being the current Path2 last point) to the current Path2.
   * @param midX middle point x value
   * @param midY middle point y value
   * @param endX end point x value
   * @param endY end point y value
   * @param numberOfSegments (default: 36)
   * @returns the updated Path2.
   */
  addArcTo(midX, midY, endX, endY, numberOfSegments = 36) {
    if (this.closed) {
      return this;
    }
    const startPoint = this._points[this._points.length - 1];
    const midPoint = new Vector2(midX, midY);
    const endPoint = new Vector2(endX, endY);
    const arc = new Arc2(startPoint, midPoint, endPoint);
    let increment = arc.angle.radians() / numberOfSegments;
    if (arc.orientation === Orientation.CW) {
      increment *= -1;
    }
    let currentAngle = arc.startAngle.radians() + increment;
    for (let i = 0; i < numberOfSegments; i++) {
      const x = Math.cos(currentAngle) * arc.radius + arc.centerPoint.x;
      const y = Math.sin(currentAngle) * arc.radius + arc.centerPoint.y;
      this.addLineTo(x, y);
      currentAngle += increment;
    }
    return this;
  }
  /**
   * Adds _numberOfSegments_ segments according to the quadratic curve definition to the current Path2.
   * @param controlX control point x value
   * @param controlY control point y value
   * @param endX end point x value
   * @param endY end point y value
   * @param numberOfSegments (default: 36)
   * @returns the updated Path2.
   */
  addQuadraticCurveTo(controlX, controlY, endX, endY, numberOfSegments = 36) {
    if (this.closed) {
      return this;
    }
    const equation = (t, val0, val1, val2) => {
      const res = (1 - t) * (1 - t) * val0 + 2 * t * (1 - t) * val1 + t * t * val2;
      return res;
    };
    const startPoint = this._points[this._points.length - 1];
    for (let i = 0; i <= numberOfSegments; i++) {
      const step = i / numberOfSegments;
      const x = equation(step, startPoint.x, controlX, endX);
      const y = equation(step, startPoint.y, controlY, endY);
      this.addLineTo(x, y);
    }
    return this;
  }
  /**
   * Adds _numberOfSegments_ segments according to the bezier curve definition to the current Path2.
   * @param originTangentX tangent vector at the origin point x value
   * @param originTangentY tangent vector at the origin point y value
   * @param destinationTangentX tangent vector at the destination point x value
   * @param destinationTangentY tangent vector at the destination point y value
   * @param endX end point x value
   * @param endY end point y value
   * @param numberOfSegments (default: 36)
   * @returns the updated Path2.
   */
  addBezierCurveTo(originTangentX, originTangentY, destinationTangentX, destinationTangentY, endX, endY, numberOfSegments = 36) {
    if (this.closed) {
      return this;
    }
    const equation = (t, val0, val1, val2, val3) => {
      const res = (1 - t) * (1 - t) * (1 - t) * val0 + 3 * t * (1 - t) * (1 - t) * val1 + 3 * t * t * (1 - t) * val2 + t * t * t * val3;
      return res;
    };
    const startPoint = this._points[this._points.length - 1];
    for (let i = 0; i <= numberOfSegments; i++) {
      const step = i / numberOfSegments;
      const x = equation(step, startPoint.x, originTangentX, destinationTangentX, endX);
      const y = equation(step, startPoint.y, originTangentY, destinationTangentY, endY);
      this.addLineTo(x, y);
    }
    return this;
  }
  /**
   * Defines if a given point is inside the polygon defines by the path
   * @param point defines the point to test
   * @returns true if the point is inside
   */
  isPointInside(point) {
    let isInside = false;
    const count = this._points.length;
    for (let p = count - 1, q = 0; q < count; p = q++) {
      let edgeLow = this._points[p];
      let edgeHigh = this._points[q];
      let edgeDx = edgeHigh.x - edgeLow.x;
      let edgeDy = edgeHigh.y - edgeLow.y;
      if (Math.abs(edgeDy) > Number.EPSILON) {
        if (edgeDy < 0) {
          edgeLow = this._points[q];
          edgeDx = -edgeDx;
          edgeHigh = this._points[p];
          edgeDy = -edgeDy;
        }
        if (point.y < edgeLow.y || point.y > edgeHigh.y) {
          continue;
        }
        if (point.y === edgeLow.y && point.x === edgeLow.x) {
          return true;
        } else {
          const perpEdge = edgeDy * (point.x - edgeLow.x) - edgeDx * (point.y - edgeLow.y);
          if (perpEdge === 0) {
            return true;
          }
          if (perpEdge < 0) {
            continue;
          }
          isInside = !isInside;
        }
      } else {
        if (point.y !== edgeLow.y) {
          continue;
        }
        if (edgeHigh.x <= point.x && point.x <= edgeLow.x || edgeLow.x <= point.x && point.x <= edgeHigh.x) {
          return true;
        }
      }
    }
    return isInside;
  }
  /**
   * Closes the Path2.
   * @returns the Path2.
   */
  close() {
    this.closed = true;
    return this;
  }
  /**
   * Gets the sum of the distance between each sequential point in the path
   * @returns the Path2 total length (float).
   */
  length() {
    let result = this._length;
    if (this.closed) {
      const lastPoint = this._points[this._points.length - 1];
      const firstPoint = this._points[0];
      result += firstPoint.subtract(lastPoint).length();
    }
    return result;
  }
  /**
   * Gets the area of the polygon defined by the path
   * @returns area value
   */
  area() {
    const n = this._points.length;
    let value = 0;
    for (let p = n - 1, q = 0; q < n; p = q++) {
      value += this._points[p].x * this._points[q].y - this._points[q].x * this._points[p].y;
    }
    return value * 0.5;
  }
  /**
   * Gets the points which construct the path
   * @returns the Path2 internal array of points.
   */
  getPoints() {
    return this._points;
  }
  /**
   * Retrieves the point at the distance aways from the starting point
   * @param normalizedLengthPosition the length along the path to retrieve the point from
   * @returns a new Vector2 located at a percentage of the Path2 total length on this path.
   */
  getPointAtLengthPosition(normalizedLengthPosition) {
    if (normalizedLengthPosition < 0 || normalizedLengthPosition > 1) {
      return Vector2.Zero();
    }
    const lengthPosition = normalizedLengthPosition * this.length();
    let previousOffset = 0;
    for (let i = 0; i < this._points.length; i++) {
      const j = (i + 1) % this._points.length;
      const a = this._points[i];
      const b = this._points[j];
      const bToA = b.subtract(a);
      const nextOffset = bToA.length() + previousOffset;
      if (lengthPosition >= previousOffset && lengthPosition <= nextOffset) {
        const dir = bToA.normalize();
        const localOffset = lengthPosition - previousOffset;
        return new Vector2(a.x + dir.x * localOffset, a.y + dir.y * localOffset);
      }
      previousOffset = nextOffset;
    }
    return Vector2.Zero();
  }
  /**
   * Creates a new path starting from an x and y position
   * @param x starting x value
   * @param y starting y value
   * @returns a new Path2 starting at the coordinates (x, y).
   */
  static StartingAt(x, y) {
    return new _Path2(x, y);
  }
};
var Path3D = class _Path3D {
  /**
   * new Path3D(path, normal, raw)
   * Creates a Path3D. A Path3D is a logical math object, so not a mesh.
   * please read the description in the tutorial : https://doc.babylonjs.com/features/featuresDeepDive/mesh/path3D
   * @param path an array of Vector3, the curve axis of the Path3D
   * @param firstNormal (options) Vector3, the first wanted normal to the curve. Ex (0, 1, 0) for a vertical normal.
   * @param raw (optional, default false) : boolean, if true the returned Path3D isn't normalized. Useful to depict path acceleration or speed.
   * @param alignTangentsWithPath (optional, default false) : boolean, if true the tangents will be aligned with the path.
   */
  constructor(path, firstNormal = null, raw, alignTangentsWithPath = false) {
    this.path = path;
    this._curve = new Array();
    this._distances = new Array();
    this._tangents = new Array();
    this._normals = new Array();
    this._binormals = new Array();
    this._pointAtData = {
      id: 0,
      point: Vector3.Zero(),
      previousPointArrayIndex: 0,
      position: 0,
      subPosition: 0,
      interpolateReady: false,
      interpolationMatrix: Matrix.Identity()
    };
    for (let p = 0; p < path.length; p++) {
      this._curve[p] = path[p].clone();
    }
    this._raw = raw || false;
    this._alignTangentsWithPath = alignTangentsWithPath;
    this._compute(firstNormal, alignTangentsWithPath);
  }
  /**
   * Returns the Path3D array of successive Vector3 designing its curve.
   * @returns the Path3D array of successive Vector3 designing its curve.
   */
  getCurve() {
    return this._curve;
  }
  /**
   * Returns the Path3D array of successive Vector3 designing its curve.
   * @returns the Path3D array of successive Vector3 designing its curve.
   */
  getPoints() {
    return this._curve;
  }
  /**
   * @returns the computed length (float) of the path.
   */
  length() {
    return this._distances[this._distances.length - 1];
  }
  /**
   * Returns an array populated with tangent vectors on each Path3D curve point.
   * @returns an array populated with tangent vectors on each Path3D curve point.
   */
  getTangents() {
    return this._tangents;
  }
  /**
   * Returns an array populated with normal vectors on each Path3D curve point.
   * @returns an array populated with normal vectors on each Path3D curve point.
   */
  getNormals() {
    return this._normals;
  }
  /**
   * Returns an array populated with binormal vectors on each Path3D curve point.
   * @returns an array populated with binormal vectors on each Path3D curve point.
   */
  getBinormals() {
    return this._binormals;
  }
  /**
   * Returns an array populated with distances (float) of the i-th point from the first curve point.
   * @returns an array populated with distances (float) of the i-th point from the first curve point.
   */
  getDistances() {
    return this._distances;
  }
  /**
   * Returns an interpolated point along this path
   * @param position the position of the point along this path, from 0.0 to 1.0
   * @returns a new Vector3 as the point
   */
  getPointAt(position) {
    return this._updatePointAtData(position).point;
  }
  /**
   * Returns the tangent vector of an interpolated Path3D curve point at the specified position along this path.
   * @param position the position of the point along this path, from 0.0 to 1.0
   * @param interpolated (optional, default false) : boolean, if true returns an interpolated tangent instead of the tangent of the previous path point.
   * @returns a tangent vector corresponding to the interpolated Path3D curve point, if not interpolated, the tangent is taken from the precomputed tangents array.
   */
  getTangentAt(position, interpolated = false) {
    this._updatePointAtData(position, interpolated);
    return interpolated ? Vector3.TransformCoordinates(Vector3.Forward(), this._pointAtData.interpolationMatrix) : this._tangents[this._pointAtData.previousPointArrayIndex];
  }
  /**
   * Returns the tangent vector of an interpolated Path3D curve point at the specified position along this path.
   * @param position the position of the point along this path, from 0.0 to 1.0
   * @param interpolated (optional, default false) : boolean, if true returns an interpolated normal instead of the normal of the previous path point.
   * @returns a normal vector corresponding to the interpolated Path3D curve point, if not interpolated, the normal is taken from the precomputed normals array.
   */
  getNormalAt(position, interpolated = false) {
    this._updatePointAtData(position, interpolated);
    return interpolated ? Vector3.TransformCoordinates(Vector3.Right(), this._pointAtData.interpolationMatrix) : this._normals[this._pointAtData.previousPointArrayIndex];
  }
  /**
   * Returns the binormal vector of an interpolated Path3D curve point at the specified position along this path.
   * @param position the position of the point along this path, from 0.0 to 1.0
   * @param interpolated (optional, default false) : boolean, if true returns an interpolated binormal instead of the binormal of the previous path point.
   * @returns a binormal vector corresponding to the interpolated Path3D curve point, if not interpolated, the binormal is taken from the precomputed binormals array.
   */
  getBinormalAt(position, interpolated = false) {
    this._updatePointAtData(position, interpolated);
    return interpolated ? Vector3.TransformCoordinates(Vector3.UpReadOnly, this._pointAtData.interpolationMatrix) : this._binormals[this._pointAtData.previousPointArrayIndex];
  }
  /**
   * Returns the distance (float) of an interpolated Path3D curve point at the specified position along this path.
   * @param position the position of the point along this path, from 0.0 to 1.0
   * @returns the distance of the interpolated Path3D curve point at the specified position along this path.
   */
  getDistanceAt(position) {
    return this.length() * position;
  }
  /**
   * Returns the array index of the previous point of an interpolated point along this path
   * @param position the position of the point to interpolate along this path, from 0.0 to 1.0
   * @returns the array index
   */
  getPreviousPointIndexAt(position) {
    this._updatePointAtData(position);
    return this._pointAtData.previousPointArrayIndex;
  }
  /**
   * Returns the position of an interpolated point relative to the two path points it lies between, from 0.0 (point A) to 1.0 (point B)
   * @param position the position of the point to interpolate along this path, from 0.0 to 1.0
   * @returns the sub position
   */
  getSubPositionAt(position) {
    this._updatePointAtData(position);
    return this._pointAtData.subPosition;
  }
  /**
   * Returns the position of the closest virtual point on this path to an arbitrary Vector3, from 0.0 to 1.0
   * @param target the vector of which to get the closest position to
   * @returns the position of the closest virtual point on this path to the target vector
   */
  getClosestPositionTo(target) {
    let smallestDistance = Number.MAX_VALUE;
    let closestPosition = 0;
    for (let i = 0; i < this._curve.length - 1; i++) {
      const point = this._curve[i + 0];
      const tangent = this._curve[i + 1].subtract(point).normalize();
      const subLength = this._distances[i + 1] - this._distances[i + 0];
      const subPosition = Math.min(Math.max(Vector3.Dot(tangent, target.subtract(point).normalize()), 0) * Vector3.Distance(point, target) / subLength, 1);
      const distance = Vector3.Distance(point.add(tangent.scale(subPosition * subLength)), target);
      if (distance < smallestDistance) {
        smallestDistance = distance;
        closestPosition = (this._distances[i + 0] + subLength * subPosition) / this.length();
      }
    }
    return closestPosition;
  }
  /**
   * Returns a sub path (slice) of this path
   * @param start the position of the fist path point, from 0.0 to 1.0, or a negative value, which will get wrapped around from the end of the path to 0.0 to 1.0 values
   * @param end the position of the last path point, from 0.0 to 1.0, or a negative value, which will get wrapped around from the end of the path to 0.0 to 1.0 values
   * @returns a sub path (slice) of this path
   */
  slice(start = 0, end = 1) {
    if (start < 0) {
      start = 1 - start * -1 % 1;
    }
    if (end < 0) {
      end = 1 - end * -1 % 1;
    }
    if (start > end) {
      const _start = start;
      start = end;
      end = _start;
    }
    const curvePoints = this.getCurve();
    const startPoint = this.getPointAt(start);
    let startIndex = this.getPreviousPointIndexAt(start);
    const endPoint = this.getPointAt(end);
    const endIndex = this.getPreviousPointIndexAt(end) + 1;
    const slicePoints = [];
    if (start !== 0) {
      startIndex++;
      slicePoints.push(startPoint);
    }
    slicePoints.push(...curvePoints.slice(startIndex, endIndex));
    if (end !== 1 || start === 1) {
      slicePoints.push(endPoint);
    }
    return new _Path3D(slicePoints, this.getNormalAt(start), this._raw, this._alignTangentsWithPath);
  }
  /**
   * Forces the Path3D tangent, normal, binormal and distance recomputation.
   * @param path path which all values are copied into the curves points
   * @param firstNormal which should be projected onto the curve
   * @param alignTangentsWithPath (optional, default false) : boolean, if true the tangents will be aligned with the path
   * @returns the same object updated.
   */
  update(path, firstNormal = null, alignTangentsWithPath = false) {
    for (let p = 0; p < path.length; p++) {
      this._curve[p].x = path[p].x;
      this._curve[p].y = path[p].y;
      this._curve[p].z = path[p].z;
    }
    this._compute(firstNormal, alignTangentsWithPath);
    return this;
  }
  // private function compute() : computes tangents, normals and binormals
  _compute(firstNormal, alignTangentsWithPath = false) {
    const l = this._curve.length;
    if (l < 2) {
      return;
    }
    this._tangents[0] = this._getFirstNonNullVector(0);
    if (!this._raw) {
      this._tangents[0].normalize();
    }
    this._tangents[l - 1] = this._curve[l - 1].subtract(this._curve[l - 2]);
    if (!this._raw) {
      this._tangents[l - 1].normalize();
    }
    const tg0 = this._tangents[0];
    const pp0 = this._normalVector(tg0, firstNormal);
    this._normals[0] = pp0;
    if (!this._raw) {
      this._normals[0].normalize();
    }
    this._binormals[0] = Vector3.Cross(tg0, this._normals[0]);
    if (!this._raw) {
      this._binormals[0].normalize();
    }
    this._distances[0] = 0;
    let prev;
    let cur;
    let curTang;
    let prevNor;
    let prevBinor;
    for (let i = 1; i < l; i++) {
      prev = this._getLastNonNullVector(i);
      if (i < l - 1) {
        cur = this._getFirstNonNullVector(i);
        this._tangents[i] = alignTangentsWithPath ? cur : prev.add(cur);
        this._tangents[i].normalize();
      }
      this._distances[i] = this._distances[i - 1] + this._curve[i].subtract(this._curve[i - 1]).length();
      curTang = this._tangents[i];
      prevBinor = this._binormals[i - 1];
      this._normals[i] = Vector3.Cross(prevBinor, curTang);
      if (!this._raw) {
        if (this._normals[i].length() === 0) {
          prevNor = this._normals[i - 1];
          this._normals[i] = prevNor.clone();
        } else {
          this._normals[i].normalize();
        }
      }
      this._binormals[i] = Vector3.Cross(curTang, this._normals[i]);
      if (!this._raw) {
        this._binormals[i].normalize();
      }
    }
    this._pointAtData.id = NaN;
  }
  // private function getFirstNonNullVector(index)
  // returns the first non null vector from index : curve[index + N].subtract(curve[index])
  _getFirstNonNullVector(index) {
    let i = 1;
    let nNVector = this._curve[index + i].subtract(this._curve[index]);
    while (nNVector.length() === 0 && index + i + 1 < this._curve.length) {
      i++;
      nNVector = this._curve[index + i].subtract(this._curve[index]);
    }
    return nNVector;
  }
  // private function getLastNonNullVector(index)
  // returns the last non null vector from index : curve[index].subtract(curve[index - N])
  _getLastNonNullVector(index) {
    let i = 1;
    let nLVector = this._curve[index].subtract(this._curve[index - i]);
    while (nLVector.length() === 0 && index > i + 1) {
      i++;
      nLVector = this._curve[index].subtract(this._curve[index - i]);
    }
    return nLVector;
  }
  // private function normalVector(v0, vt, va) :
  // returns an arbitrary point in the plane defined by the point v0 and the vector vt orthogonal to this plane
  // if va is passed, it returns the va projection on the plane orthogonal to vt at the point v0
  _normalVector(vt, va) {
    let normal0;
    let tgl = vt.length();
    if (tgl === 0) {
      tgl = 1;
    }
    if (va === void 0 || va === null) {
      let point;
      if (!Scalar.WithinEpsilon(Math.abs(vt.y) / tgl, 1, Epsilon)) {
        point = new Vector3(0, -1, 0);
      } else if (!Scalar.WithinEpsilon(Math.abs(vt.x) / tgl, 1, Epsilon)) {
        point = new Vector3(1, 0, 0);
      } else if (!Scalar.WithinEpsilon(Math.abs(vt.z) / tgl, 1, Epsilon)) {
        point = new Vector3(0, 0, 1);
      } else {
        point = Vector3.Zero();
      }
      normal0 = Vector3.Cross(vt, point);
    } else {
      normal0 = Vector3.Cross(vt, va);
      Vector3.CrossToRef(normal0, vt, normal0);
    }
    normal0.normalize();
    return normal0;
  }
  /**
   * Updates the point at data for an interpolated point along this curve
   * @param position the position of the point along this curve, from 0.0 to 1.0
   * @param interpolateTNB
   * @interpolateTNB whether to compute the interpolated tangent, normal and binormal
   * @returns the (updated) point at data
   */
  _updatePointAtData(position, interpolateTNB = false) {
    if (this._pointAtData.id === position) {
      if (!this._pointAtData.interpolateReady) {
        this._updateInterpolationMatrix();
      }
      return this._pointAtData;
    } else {
      this._pointAtData.id = position;
    }
    const curvePoints = this.getPoints();
    if (position <= 0) {
      return this._setPointAtData(0, 0, curvePoints[0], 0, interpolateTNB);
    } else if (position >= 1) {
      return this._setPointAtData(1, 1, curvePoints[curvePoints.length - 1], curvePoints.length - 1, interpolateTNB);
    }
    let previousPoint = curvePoints[0];
    let currentPoint;
    let currentLength = 0;
    const targetLength = position * this.length();
    for (let i = 1; i < curvePoints.length; i++) {
      currentPoint = curvePoints[i];
      const distance = Vector3.Distance(previousPoint, currentPoint);
      currentLength += distance;
      if (currentLength === targetLength) {
        return this._setPointAtData(position, 1, currentPoint, i, interpolateTNB);
      } else if (currentLength > targetLength) {
        const toLength = currentLength - targetLength;
        const diff = toLength / distance;
        const dir = previousPoint.subtract(currentPoint);
        const point = currentPoint.add(dir.scaleInPlace(diff));
        return this._setPointAtData(position, 1 - diff, point, i - 1, interpolateTNB);
      }
      previousPoint = currentPoint;
    }
    return this._pointAtData;
  }
  /**
   * Updates the point at data from the specified parameters
   * @param position where along the path the interpolated point is, from 0.0 to 1.0
   * @param subPosition
   * @param point the interpolated point
   * @param parentIndex the index of an existing curve point that is on, or else positionally the first behind, the interpolated point
   * @param interpolateTNB whether to compute the interpolated tangent, normal and binormal
   * @returns the (updated) point at data
   */
  _setPointAtData(position, subPosition, point, parentIndex, interpolateTNB) {
    this._pointAtData.point = point;
    this._pointAtData.position = position;
    this._pointAtData.subPosition = subPosition;
    this._pointAtData.previousPointArrayIndex = parentIndex;
    this._pointAtData.interpolateReady = interpolateTNB;
    if (interpolateTNB) {
      this._updateInterpolationMatrix();
    }
    return this._pointAtData;
  }
  /**
   * Updates the point at interpolation matrix for the tangents, normals and binormals
   */
  _updateInterpolationMatrix() {
    this._pointAtData.interpolationMatrix = Matrix.Identity();
    const parentIndex = this._pointAtData.previousPointArrayIndex;
    if (parentIndex !== this._tangents.length - 1) {
      const index = parentIndex + 1;
      const tangentFrom = this._tangents[parentIndex].clone();
      const normalFrom = this._normals[parentIndex].clone();
      const binormalFrom = this._binormals[parentIndex].clone();
      const tangentTo = this._tangents[index].clone();
      const normalTo = this._normals[index].clone();
      const binormalTo = this._binormals[index].clone();
      const quatFrom = Quaternion.RotationQuaternionFromAxis(normalFrom, binormalFrom, tangentFrom);
      const quatTo = Quaternion.RotationQuaternionFromAxis(normalTo, binormalTo, tangentTo);
      const quatAt = Quaternion.Slerp(quatFrom, quatTo, this._pointAtData.subPosition);
      quatAt.toRotationMatrix(this._pointAtData.interpolationMatrix);
    }
  }
};
var Curve3 = class _Curve3 {
  /**
   * Returns a Curve3 object along a Quadratic Bezier curve : https://doc.babylonjs.com/features/featuresDeepDive/mesh/drawCurves#quadratic-bezier-curve
   * @param v0 (Vector3) the origin point of the Quadratic Bezier
   * @param v1 (Vector3) the control point
   * @param v2 (Vector3) the end point of the Quadratic Bezier
   * @param nbPoints (integer) the wanted number of points in the curve
   * @returns the created Curve3
   */
  static CreateQuadraticBezier(v0, v1, v2, nbPoints) {
    nbPoints = nbPoints > 2 ? nbPoints : 3;
    const bez = [];
    const equation = (t, val0, val1, val2) => {
      const res = (1 - t) * (1 - t) * val0 + 2 * t * (1 - t) * val1 + t * t * val2;
      return res;
    };
    for (let i = 0; i <= nbPoints; i++) {
      bez.push(new Vector3(equation(i / nbPoints, v0.x, v1.x, v2.x), equation(i / nbPoints, v0.y, v1.y, v2.y), equation(i / nbPoints, v0.z, v1.z, v2.z)));
    }
    return new _Curve3(bez);
  }
  /**
   * Returns a Curve3 object along a Cubic Bezier curve : https://doc.babylonjs.com/features/featuresDeepDive/mesh/drawCurves#cubic-bezier-curve
   * @param v0 (Vector3) the origin point of the Cubic Bezier
   * @param v1 (Vector3) the first control point
   * @param v2 (Vector3) the second control point
   * @param v3 (Vector3) the end point of the Cubic Bezier
   * @param nbPoints (integer) the wanted number of points in the curve
   * @returns the created Curve3
   */
  static CreateCubicBezier(v0, v1, v2, v3, nbPoints) {
    nbPoints = nbPoints > 3 ? nbPoints : 4;
    const bez = [];
    const equation = (t, val0, val1, val2, val3) => {
      const res = (1 - t) * (1 - t) * (1 - t) * val0 + 3 * t * (1 - t) * (1 - t) * val1 + 3 * t * t * (1 - t) * val2 + t * t * t * val3;
      return res;
    };
    for (let i = 0; i <= nbPoints; i++) {
      bez.push(new Vector3(equation(i / nbPoints, v0.x, v1.x, v2.x, v3.x), equation(i / nbPoints, v0.y, v1.y, v2.y, v3.y), equation(i / nbPoints, v0.z, v1.z, v2.z, v3.z)));
    }
    return new _Curve3(bez);
  }
  /**
   * Returns a Curve3 object along a Hermite Spline curve : https://doc.babylonjs.com/features/featuresDeepDive/mesh/drawCurves#hermite-spline
   * @param p1 (Vector3) the origin point of the Hermite Spline
   * @param t1 (Vector3) the tangent vector at the origin point
   * @param p2 (Vector3) the end point of the Hermite Spline
   * @param t2 (Vector3) the tangent vector at the end point
   * @param nSeg (integer) the number of curve segments or nSeg + 1 points in the array
   * @returns the created Curve3
   */
  static CreateHermiteSpline(p1, t1, p2, t2, nSeg) {
    const hermite = [];
    const step = 1 / nSeg;
    for (let i = 0; i <= nSeg; i++) {
      hermite.push(Vector3.Hermite(p1, t1, p2, t2, i * step));
    }
    return new _Curve3(hermite);
  }
  /**
   * Returns a Curve3 object along a CatmullRom Spline curve :
   * @param points (array of Vector3) the points the spline must pass through. At least, four points required
   * @param nbPoints (integer) the wanted number of points between each curve control points
   * @param closed (boolean) optional with default false, when true forms a closed loop from the points
   * @returns the created Curve3
   */
  static CreateCatmullRomSpline(points, nbPoints, closed) {
    const catmullRom = [];
    const step = 1 / nbPoints;
    let amount = 0;
    if (closed) {
      const pointsCount = points.length;
      for (let i = 0; i < pointsCount; i++) {
        amount = 0;
        for (let c = 0; c < nbPoints; c++) {
          catmullRom.push(Vector3.CatmullRom(points[i % pointsCount], points[(i + 1) % pointsCount], points[(i + 2) % pointsCount], points[(i + 3) % pointsCount], amount));
          amount += step;
        }
      }
      catmullRom.push(catmullRom[0]);
    } else {
      const totalPoints = [];
      totalPoints.push(points[0].clone());
      Array.prototype.push.apply(totalPoints, points);
      totalPoints.push(points[points.length - 1].clone());
      let i = 0;
      for (; i < totalPoints.length - 3; i++) {
        amount = 0;
        for (let c = 0; c < nbPoints; c++) {
          catmullRom.push(Vector3.CatmullRom(totalPoints[i], totalPoints[i + 1], totalPoints[i + 2], totalPoints[i + 3], amount));
          amount += step;
        }
      }
      i--;
      catmullRom.push(Vector3.CatmullRom(totalPoints[i], totalPoints[i + 1], totalPoints[i + 2], totalPoints[i + 3], amount));
    }
    return new _Curve3(catmullRom);
  }
  /**
   * Returns a Curve3 object along an arc through three vector3 points:
   * The three points should not be colinear. When they are the Curve3 is empty.
   * @param first (Vector3) the first point the arc must pass through.
   * @param second (Vector3) the second point the arc must pass through.
   * @param third (Vector3) the third point the arc must pass through.
   * @param steps (number) the larger the number of steps the more detailed the arc.
   * @param closed (boolean) optional with default false, when true forms the chord from the first and third point
   * @param fullCircle Circle (boolean) optional with default false, when true forms the complete circle through the three points
   * @returns the created Curve3
   */
  static ArcThru3Points(first, second, third, steps = 32, closed = false, fullCircle = false) {
    const arc = [];
    const vec1 = second.subtract(first);
    const vec2 = third.subtract(second);
    const vec3 = first.subtract(third);
    const zAxis = Vector3.Cross(vec1, vec2);
    const len4 = zAxis.length();
    if (len4 < Math.pow(10, -8)) {
      return new _Curve3(arc);
    }
    const len1_sq = vec1.lengthSquared();
    const len2_sq = vec2.lengthSquared();
    const len3_sq = vec3.lengthSquared();
    const len4_sq = zAxis.lengthSquared();
    const len1 = vec1.length();
    const len2 = vec2.length();
    const len3 = vec3.length();
    const radius = 0.5 * len1 * len2 * len3 / len4;
    const dot1 = Vector3.Dot(vec1, vec3);
    const dot2 = Vector3.Dot(vec1, vec2);
    const dot3 = Vector3.Dot(vec2, vec3);
    const a = -0.5 * len2_sq * dot1 / len4_sq;
    const b = -0.5 * len3_sq * dot2 / len4_sq;
    const c = -0.5 * len1_sq * dot3 / len4_sq;
    const center = first.scale(a).add(second.scale(b)).add(third.scale(c));
    const radiusVec = first.subtract(center);
    const xAxis = radiusVec.normalize();
    const yAxis = Vector3.Cross(zAxis, xAxis).normalize();
    if (fullCircle) {
      const dStep = 2 * Math.PI / steps;
      for (let theta = 0; theta <= 2 * Math.PI; theta += dStep) {
        arc.push(center.add(xAxis.scale(radius * Math.cos(theta)).add(yAxis.scale(radius * Math.sin(theta)))));
      }
      arc.push(first);
    } else {
      const dStep = 1 / steps;
      let theta = 0;
      let point = Vector3.Zero();
      do {
        point = center.add(xAxis.scale(radius * Math.cos(theta)).add(yAxis.scale(radius * Math.sin(theta))));
        arc.push(point);
        theta += dStep;
      } while (!point.equalsWithEpsilon(third, radius * dStep * 1.1));
      arc.push(third);
      if (closed) {
        arc.push(first);
      }
    }
    return new _Curve3(arc);
  }
  /**
   * A Curve3 object is a logical object, so not a mesh, to handle curves in the 3D geometric space.
   * A Curve3 is designed from a series of successive Vector3.
   * Tuto : https://doc.babylonjs.com/features/featuresDeepDive/mesh/drawCurves#curve3-object
   * @param points points which make up the curve
   */
  constructor(points) {
    this._length = 0;
    this._points = points;
    this._length = this._computeLength(points);
  }
  /**
   * @returns the Curve3 stored array of successive Vector3
   */
  getPoints() {
    return this._points;
  }
  /**
   * @returns the computed length (float) of the curve.
   */
  length() {
    return this._length;
  }
  /**
   * Returns a new instance of Curve3 object : var curve = curveA.continue(curveB);
   * This new Curve3 is built by translating and sticking the curveB at the end of the curveA.
   * curveA and curveB keep unchanged.
   * @param curve the curve to continue from this curve
   * @returns the newly constructed curve
   */
  continue(curve) {
    const lastPoint = this._points[this._points.length - 1];
    const continuedPoints = this._points.slice();
    const curvePoints = curve.getPoints();
    for (let i = 1; i < curvePoints.length; i++) {
      continuedPoints.push(curvePoints[i].subtract(curvePoints[0]).add(lastPoint));
    }
    const continuedCurve = new _Curve3(continuedPoints);
    return continuedCurve;
  }
  _computeLength(path) {
    let l = 0;
    for (let i = 1; i < path.length; i++) {
      l += path[i].subtract(path[i - 1]).length();
    }
    return l;
  }
};

// node_modules/@babylonjs/core/Maths/math.viewport.js
var Viewport = class _Viewport {
  /**
   * Creates a Viewport object located at (x, y) and sized (width, height)
   * @param x defines viewport left coordinate
   * @param y defines viewport top coordinate
   * @param width defines the viewport width
   * @param height defines the viewport height
   */
  constructor(x, y, width, height) {
    this.x = x;
    this.y = y;
    this.width = width;
    this.height = height;
  }
  /**
   * Creates a new viewport using absolute sizing (from 0-> width, 0-> height instead of 0->1)
   * @param renderWidth defines the rendering width
   * @param renderHeight defines the rendering height
   * @returns a new Viewport
   */
  toGlobal(renderWidth, renderHeight) {
    return new _Viewport(this.x * renderWidth, this.y * renderHeight, this.width * renderWidth, this.height * renderHeight);
  }
  /**
   * Stores absolute viewport value into a target viewport (from 0-> width, 0-> height instead of 0->1)
   * @param renderWidth defines the rendering width
   * @param renderHeight defines the rendering height
   * @param ref defines the target viewport
   * @returns the current viewport
   */
  toGlobalToRef(renderWidth, renderHeight, ref) {
    ref.x = this.x * renderWidth;
    ref.y = this.y * renderHeight;
    ref.width = this.width * renderWidth;
    ref.height = this.height * renderHeight;
    return this;
  }
  /**
   * Returns a new Viewport copied from the current one
   * @returns a new Viewport
   */
  clone() {
    return new _Viewport(this.x, this.y, this.width, this.height);
  }
};

// node_modules/@babylonjs/core/Compat/compatibilityOptions.js
var CompatibilityOptions = class {
};
CompatibilityOptions.UseOpenGLOrientationForUV = false;

// node_modules/@babylonjs/core/Misc/performanceMonitor.js
var PerformanceMonitor = class {
  /**
   * constructor
   * @param frameSampleSize The number of samples required to saturate the sliding window
   */
  constructor(frameSampleSize = 30) {
    this._enabled = true;
    this._rollingFrameTime = new RollingAverage(frameSampleSize);
  }
  /**
   * Samples current frame
   * @param timeMs A timestamp in milliseconds of the current frame to compare with other frames
   */
  sampleFrame(timeMs = PrecisionDate.Now) {
    if (!this._enabled) {
      return;
    }
    if (this._lastFrameTimeMs != null) {
      const dt = timeMs - this._lastFrameTimeMs;
      this._rollingFrameTime.add(dt);
    }
    this._lastFrameTimeMs = timeMs;
  }
  /**
   * Returns the average frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
   */
  get averageFrameTime() {
    return this._rollingFrameTime.average;
  }
  /**
   * Returns the variance frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
   */
  get averageFrameTimeVariance() {
    return this._rollingFrameTime.variance;
  }
  /**
   * Returns the frame time of the most recent frame
   */
  get instantaneousFrameTime() {
    return this._rollingFrameTime.history(0);
  }
  /**
   * Returns the average framerate in frames per second over the sliding window (or the subset of frames sampled so far)
   */
  get averageFPS() {
    return 1e3 / this._rollingFrameTime.average;
  }
  /**
   * Returns the average framerate in frames per second using the most recent frame time
   */
  get instantaneousFPS() {
    const history = this._rollingFrameTime.history(0);
    if (history === 0) {
      return 0;
    }
    return 1e3 / history;
  }
  /**
   * Returns true if enough samples have been taken to completely fill the sliding window
   */
  get isSaturated() {
    return this._rollingFrameTime.isSaturated();
  }
  /**
   * Enables contributions to the sliding window sample set
   */
  enable() {
    this._enabled = true;
  }
  /**
   * Disables contributions to the sliding window sample set
   * Samples will not be interpolated over the disabled period
   */
  disable() {
    this._enabled = false;
    this._lastFrameTimeMs = null;
  }
  /**
   * Returns true if sampling is enabled
   */
  get isEnabled() {
    return this._enabled;
  }
  /**
   * Resets performance monitor
   */
  reset() {
    this._lastFrameTimeMs = null;
    this._rollingFrameTime.reset();
  }
};
var RollingAverage = class {
  /**
   * constructor
   * @param length The number of samples required to saturate the sliding window
   */
  constructor(length) {
    this._samples = new Array(length);
    this.reset();
  }
  /**
   * Adds a sample to the sample set
   * @param v The sample value
   */
  add(v) {
    let delta;
    if (this.isSaturated()) {
      const bottomValue = this._samples[this._pos];
      delta = bottomValue - this.average;
      this.average -= delta / (this._sampleCount - 1);
      this._m2 -= delta * (bottomValue - this.average);
    } else {
      this._sampleCount++;
    }
    delta = v - this.average;
    this.average += delta / this._sampleCount;
    this._m2 += delta * (v - this.average);
    this.variance = this._m2 / (this._sampleCount - 1);
    this._samples[this._pos] = v;
    this._pos++;
    this._pos %= this._samples.length;
  }
  /**
   * Returns previously added values or null if outside of history or outside the sliding window domain
   * @param i Index in history. For example, pass 0 for the most recent value and 1 for the value before that
   * @returns Value previously recorded with add() or null if outside of range
   */
  history(i) {
    if (i >= this._sampleCount || i >= this._samples.length) {
      return 0;
    }
    const i0 = this._wrapPosition(this._pos - 1);
    return this._samples[this._wrapPosition(i0 - i)];
  }
  /**
   * Returns true if enough samples have been taken to completely fill the sliding window
   * @returns true if sample-set saturated
   */
  isSaturated() {
    return this._sampleCount >= this._samples.length;
  }
  /**
   * Resets the rolling average (equivalent to 0 samples taken so far)
   */
  reset() {
    this.average = 0;
    this.variance = 0;
    this._sampleCount = 0;
    this._pos = 0;
    this._m2 = 0;
  }
  /**
   * Wraps a value around the sample range boundaries
   * @param i Position in sample range, for example if the sample length is 5, and i is -3, then 2 will be returned.
   * @returns Wrapped position in sample range
   */
  _wrapPosition(i) {
    const max = this._samples.length;
    return (i % max + max) % max;
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.readTexture.js
function allocateAndCopyTypedBuffer(type, sizeOrDstBuffer, sizeInBytes = false, copyBuffer) {
  switch (type) {
    case 3: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Int8Array(sizeOrDstBuffer) : new Int8Array(sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Int8Array(copyBuffer));
      }
      return buffer2;
    }
    case 0: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Uint8Array(sizeOrDstBuffer) : new Uint8Array(sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Uint8Array(copyBuffer));
      }
      return buffer2;
    }
    case 4: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Int16Array(sizeOrDstBuffer) : new Int16Array(sizeInBytes ? sizeOrDstBuffer / 2 : sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Int16Array(copyBuffer));
      }
      return buffer2;
    }
    case 5:
    case 8:
    case 9:
    case 10:
    case 2: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Uint16Array(sizeOrDstBuffer) : new Uint16Array(sizeInBytes ? sizeOrDstBuffer / 2 : sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Uint16Array(copyBuffer));
      }
      return buffer2;
    }
    case 6: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Int32Array(sizeOrDstBuffer) : new Int32Array(sizeInBytes ? sizeOrDstBuffer / 4 : sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Int32Array(copyBuffer));
      }
      return buffer2;
    }
    case 7:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Uint32Array(sizeOrDstBuffer) : new Uint32Array(sizeInBytes ? sizeOrDstBuffer / 4 : sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Uint32Array(copyBuffer));
      }
      return buffer2;
    }
    case 1: {
      const buffer2 = sizeOrDstBuffer instanceof ArrayBuffer ? new Float32Array(sizeOrDstBuffer) : new Float32Array(sizeInBytes ? sizeOrDstBuffer / 4 : sizeOrDstBuffer);
      if (copyBuffer) {
        buffer2.set(new Float32Array(copyBuffer));
      }
      return buffer2;
    }
  }
  const buffer = sizeOrDstBuffer instanceof ArrayBuffer ? new Uint8Array(sizeOrDstBuffer) : new Uint8Array(sizeOrDstBuffer);
  if (copyBuffer) {
    buffer.set(new Uint8Array(copyBuffer));
  }
  return buffer;
}
ThinEngine.prototype._readTexturePixelsSync = function(texture, width, height, faceIndex = -1, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0) {
  var _a, _b;
  const gl = this._gl;
  if (!gl) {
    throw new Error("Engine does not have gl rendering context.");
  }
  if (!this._dummyFramebuffer) {
    const dummy = gl.createFramebuffer();
    if (!dummy) {
      throw new Error("Unable to create dummy framebuffer");
    }
    this._dummyFramebuffer = dummy;
  }
  gl.bindFramebuffer(gl.FRAMEBUFFER, this._dummyFramebuffer);
  if (faceIndex > -1) {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, (_a = texture._hardwareTexture) == null ? void 0 : _a.underlyingResource, level);
  } else {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, (_b = texture._hardwareTexture) == null ? void 0 : _b.underlyingResource, level);
  }
  let readType = texture.type !== void 0 ? this._getWebGLTextureType(texture.type) : gl.UNSIGNED_BYTE;
  if (!noDataConversion) {
    switch (readType) {
      case gl.UNSIGNED_BYTE:
        if (!buffer) {
          buffer = new Uint8Array(4 * width * height);
        }
        readType = gl.UNSIGNED_BYTE;
        break;
      default:
        if (!buffer) {
          buffer = new Float32Array(4 * width * height);
        }
        readType = gl.FLOAT;
        break;
    }
  } else if (!buffer) {
    buffer = allocateAndCopyTypedBuffer(texture.type, 4 * width * height);
  }
  if (flushRenderer) {
    this.flushFramebuffer();
  }
  gl.readPixels(x, y, width, height, gl.RGBA, readType, buffer);
  gl.bindFramebuffer(gl.FRAMEBUFFER, this._currentFramebuffer);
  return buffer;
};
ThinEngine.prototype._readTexturePixels = function(texture, width, height, faceIndex = -1, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0) {
  return Promise.resolve(this._readTexturePixelsSync(texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion, x, y));
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.alpha.js
ThinEngine.prototype.setAlphaConstants = function(r, g, b, a) {
  this._alphaState.setAlphaBlendConstants(r, g, b, a);
};
ThinEngine.prototype.setAlphaMode = function(mode, noDepthWriteChange = false) {
  if (this._alphaMode === mode) {
    if (!noDepthWriteChange) {
      const depthMask = mode === 0;
      if (this.depthCullingState.depthMask !== depthMask) {
        this.depthCullingState.depthMask = depthMask;
      }
    }
    return;
  }
  switch (mode) {
    case 0:
      this._alphaState.alphaBlend = false;
      break;
    case 7:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 8:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 2:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 6:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 1:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 3:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ZERO, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 4:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.DST_COLOR, this._gl.ZERO, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 5:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 9:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.CONSTANT_COLOR, this._gl.ONE_MINUS_CONSTANT_COLOR, this._gl.CONSTANT_ALPHA, this._gl.ONE_MINUS_CONSTANT_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 10:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 11:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 12:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.DST_ALPHA, this._gl.ONE, this._gl.ZERO, this._gl.ZERO);
      this._alphaState.alphaBlend = true;
      break;
    case 13:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE_MINUS_DST_COLOR, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE_MINUS_DST_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 14:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 15:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ONE, this._gl.ZERO);
      this._alphaState.alphaBlend = true;
      break;
    case 16:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE_MINUS_DST_COLOR, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 17:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
  }
  if (!noDepthWriteChange) {
    this.depthCullingState.depthMask = mode === 0;
  }
  this._alphaMode = mode;
};
ThinEngine.prototype.getAlphaMode = function() {
  return this._alphaMode;
};
ThinEngine.prototype.setAlphaEquation = function(equation) {
  if (this._alphaEquation === equation) {
    return;
  }
  switch (equation) {
    case 0:
      this._alphaState.setAlphaEquationParameters(32774, 32774);
      break;
    case 1:
      this._alphaState.setAlphaEquationParameters(32778, 32778);
      break;
    case 2:
      this._alphaState.setAlphaEquationParameters(32779, 32779);
      break;
    case 3:
      this._alphaState.setAlphaEquationParameters(32776, 32776);
      break;
    case 4:
      this._alphaState.setAlphaEquationParameters(32775, 32775);
      break;
    case 5:
      this._alphaState.setAlphaEquationParameters(32775, 32774);
      break;
  }
  this._alphaEquation = equation;
};
ThinEngine.prototype.getAlphaEquation = function() {
  return this._alphaEquation;
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.dynamicBuffer.js
ThinEngine.prototype.updateDynamicIndexBuffer = function(indexBuffer, indices, offset = 0) {
  this._currentBoundBuffer[this._gl.ELEMENT_ARRAY_BUFFER] = null;
  this.bindIndexBuffer(indexBuffer);
  let view;
  if (indexBuffer.is32Bits) {
    view = indices instanceof Uint32Array ? indices : new Uint32Array(indices);
  } else {
    view = indices instanceof Uint16Array ? indices : new Uint16Array(indices);
  }
  this._gl.bufferData(this._gl.ELEMENT_ARRAY_BUFFER, view, this._gl.DYNAMIC_DRAW);
  this._resetIndexBufferBinding();
};
ThinEngine.prototype.updateDynamicVertexBuffer = function(vertexBuffer, data, byteOffset, byteLength) {
  this.bindArrayBuffer(vertexBuffer);
  if (byteOffset === void 0) {
    byteOffset = 0;
  }
  const dataLength = data.byteLength || data.length;
  if (byteLength === void 0 || byteLength >= dataLength && byteOffset === 0) {
    if (data instanceof Array) {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, new Float32Array(data));
    } else {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, data);
    }
  } else {
    if (data instanceof Array) {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, 0, new Float32Array(data).subarray(byteOffset, byteOffset + byteLength));
    } else {
      if (data instanceof ArrayBuffer) {
        data = new Uint8Array(data, byteOffset, byteLength);
      } else {
        data = new Uint8Array(data.buffer, data.byteOffset + byteOffset, byteLength);
      }
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, 0, data);
    }
  }
  this._resetVertexBufferBinding();
};

// node_modules/@babylonjs/core/Engines/engine.js
var Engine = class _Engine extends ThinEngine {
  /**
   * Returns the current npm package of the sdk
   */
  // Not mixed with Version for tooling purpose.
  static get NpmPackage() {
    return ThinEngine.NpmPackage;
  }
  /**
   * Returns the current version of the framework
   */
  static get Version() {
    return ThinEngine.Version;
  }
  /** Gets the list of created engines */
  static get Instances() {
    return EngineStore.Instances;
  }
  /**
   * Gets the latest created engine
   */
  static get LastCreatedEngine() {
    return EngineStore.LastCreatedEngine;
  }
  /**
   * Gets the latest created scene
   */
  static get LastCreatedScene() {
    return EngineStore.LastCreatedScene;
  }
  /** @internal */
  /**
   * Engine abstraction for loading and creating an image bitmap from a given source string.
   * @param imageSource source to load the image from.
   * @param options An object that sets options for the image's extraction.
   * @returns ImageBitmap.
   */
  _createImageBitmapFromSource(imageSource, options) {
    const promise = new Promise((resolve, reject) => {
      const image = new Image();
      image.onload = () => {
        image.decode().then(() => {
          this.createImageBitmap(image, options).then((imageBitmap) => {
            resolve(imageBitmap);
          });
        });
      };
      image.onerror = () => {
        reject(`Error loading image ${image.src}`);
      };
      image.src = imageSource;
    });
    return promise;
  }
  /**
   * Engine abstraction for createImageBitmap
   * @param image source for image
   * @param options An object that sets options for the image's extraction.
   * @returns ImageBitmap
   */
  createImageBitmap(image, options) {
    return createImageBitmap(image, options);
  }
  /**
   * Resize an image and returns the image data as an uint8array
   * @param image image to resize
   * @param bufferWidth destination buffer width
   * @param bufferHeight destination buffer height
   * @returns an uint8array containing RGBA values of bufferWidth * bufferHeight size
   */
  resizeImageBitmap(image, bufferWidth, bufferHeight) {
    const canvas = this.createCanvas(bufferWidth, bufferHeight);
    const context = canvas.getContext("2d");
    if (!context) {
      throw new Error("Unable to get 2d context for resizeImageBitmap");
    }
    context.drawImage(image, 0, 0);
    const buffer = context.getImageData(0, 0, bufferWidth, bufferHeight).data;
    return buffer;
  }
  /**
   * Will flag all materials in all scenes in all engines as dirty to trigger new shader compilation
   * @param flag defines which part of the materials must be marked as dirty
   * @param predicate defines a predicate used to filter which materials should be affected
   */
  static MarkAllMaterialsAsDirty(flag, predicate) {
    for (let engineIndex = 0; engineIndex < _Engine.Instances.length; engineIndex++) {
      const engine = _Engine.Instances[engineIndex];
      for (let sceneIndex = 0; sceneIndex < engine.scenes.length; sceneIndex++) {
        engine.scenes[sceneIndex].markAllMaterialsAsDirty(flag, predicate);
      }
    }
  }
  // eslint-disable-next-line jsdoc/require-returns-check
  /**
   * Method called to create the default loading screen.
   * This can be overridden in your own app.
   * @param canvas The rendering canvas element
   * @returns The loading screen
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  static DefaultLoadingScreenFactory(canvas) {
    throw _WarnImport("LoadingScreen");
  }
  get _supportsHardwareTextureRescaling() {
    return !!_Engine._RescalePostProcessFactory;
  }
  /**
   * Gets the performance monitor attached to this engine
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
   */
  get performanceMonitor() {
    return this._performanceMonitor;
  }
  /**
   * (WebGPU only) True (default) to be in compatibility mode, meaning rendering all existing scenes without artifacts (same rendering than WebGL).
   * Setting the property to false will improve performances but may not work in some scenes if some precautions are not taken.
   * See https://doc.babylonjs.com/setup/support/webGPU/webGPUOptimization/webGPUNonCompatibilityMode for more details
   */
  get compatibilityMode() {
    return this._compatibilityMode;
  }
  set compatibilityMode(mode) {
    this._compatibilityMode = true;
  }
  // Events
  /**
   * Gets the HTML element used to attach event listeners
   * @returns a HTML element
   */
  getInputElement() {
    return this._renderingCanvas;
  }
  /**
   * Creates a new engine
   * @param canvasOrContext defines the canvas or WebGL context to use for rendering. If you provide a WebGL context, Babylon.js will not hook events on the canvas (like pointers, keyboards, etc...) so no event observables will be available. This is mostly used when Babylon.js is used as a plugin on a system which already used the WebGL context
   * @param antialias defines enable antialiasing (default: false)
   * @param options defines further options to be sent to the getContext() function
   * @param adaptToDeviceRatio defines whether to adapt to the device's viewport characteristics (default: false)
   */
  constructor(canvasOrContext, antialias, options, adaptToDeviceRatio = false) {
    super(canvasOrContext, antialias, options, adaptToDeviceRatio);
    this.enableOfflineSupport = false;
    this.disableManifestCheck = false;
    this.disableContextMenu = true;
    this.scenes = [];
    this._virtualScenes = new Array();
    this.onNewSceneAddedObservable = new Observable();
    this.postProcesses = [];
    this.isPointerLock = false;
    this.onResizeObservable = new Observable();
    this.onCanvasBlurObservable = new Observable();
    this.onCanvasFocusObservable = new Observable();
    this.onCanvasPointerOutObservable = new Observable();
    this.onBeginFrameObservable = new Observable();
    this.customAnimationFrameRequester = null;
    this.onEndFrameObservable = new Observable();
    this.onBeforeShaderCompilationObservable = new Observable();
    this.onAfterShaderCompilationObservable = new Observable();
    this._deterministicLockstep = false;
    this._lockstepMaxSteps = 4;
    this._timeStep = 1 / 60;
    this._fps = 60;
    this._deltaTime = 0;
    this._drawCalls = new PerfCounter();
    this.canvasTabIndex = 1;
    this.disablePerformanceMonitorInBackground = false;
    this._performanceMonitor = new PerformanceMonitor();
    this._compatibilityMode = true;
    this.currentRenderPassId = 0;
    this._renderPassNames = ["main"];
    _Engine.Instances.push(this);
    if (!canvasOrContext) {
      return;
    }
    this._features.supportRenderPasses = true;
    options = this._creationOptions;
    if (canvasOrContext.getContext) {
      const canvas = canvasOrContext;
      this._sharedInit(canvas);
    }
  }
  _initGLContext() {
    super._initGLContext();
    this._rescalePostProcess = null;
  }
  /**
   * Shared initialization across engines types.
   * @param canvas The canvas associated with this instance of the engine.
   */
  _sharedInit(canvas) {
    super._sharedInit(canvas);
    this._onCanvasFocus = () => {
      this.onCanvasFocusObservable.notifyObservers(this);
    };
    this._onCanvasBlur = () => {
      this.onCanvasBlurObservable.notifyObservers(this);
    };
    this._onCanvasContextMenu = (evt) => {
      if (this.disableContextMenu) {
        evt.preventDefault();
      }
    };
    canvas.addEventListener("focus", this._onCanvasFocus);
    canvas.addEventListener("blur", this._onCanvasBlur);
    canvas.addEventListener("contextmenu", this._onCanvasContextMenu);
    this._onBlur = () => {
      if (this.disablePerformanceMonitorInBackground) {
        this._performanceMonitor.disable();
      }
      this._windowIsBackground = true;
    };
    this._onFocus = () => {
      if (this.disablePerformanceMonitorInBackground) {
        this._performanceMonitor.enable();
      }
      this._windowIsBackground = false;
    };
    this._onCanvasPointerOut = (ev) => {
      if (document.elementFromPoint(ev.clientX, ev.clientY) !== canvas) {
        this.onCanvasPointerOutObservable.notifyObservers(ev);
      }
    };
    const hostWindow = this.getHostWindow();
    if (hostWindow && typeof hostWindow.addEventListener === "function") {
      hostWindow.addEventListener("blur", this._onBlur);
      hostWindow.addEventListener("focus", this._onFocus);
    }
    canvas.addEventListener("pointerout", this._onCanvasPointerOut);
    if (!this._creationOptions.doNotHandleTouchAction) {
      this._disableTouchAction();
    }
    if (!_Engine.audioEngine && this._creationOptions.audioEngine && _Engine.AudioEngineFactory) {
      _Engine.audioEngine = _Engine.AudioEngineFactory(this.getRenderingCanvas(), this.getAudioContext(), this.getAudioDestination());
    }
    if (IsDocumentAvailable()) {
      this._onFullscreenChange = () => {
        this.isFullscreen = !!document.fullscreenElement;
        if (this.isFullscreen && this._pointerLockRequested && canvas) {
          _Engine._RequestPointerlock(canvas);
        }
      };
      document.addEventListener("fullscreenchange", this._onFullscreenChange, false);
      document.addEventListener("webkitfullscreenchange", this._onFullscreenChange, false);
      this._onPointerLockChange = () => {
        this.isPointerLock = document.pointerLockElement === canvas;
      };
      document.addEventListener("pointerlockchange", this._onPointerLockChange, false);
      document.addEventListener("webkitpointerlockchange", this._onPointerLockChange, false);
    }
    this.enableOfflineSupport = _Engine.OfflineProviderFactory !== void 0;
    this._deterministicLockstep = !!this._creationOptions.deterministicLockstep;
    this._lockstepMaxSteps = this._creationOptions.lockstepMaxSteps || 0;
    this._timeStep = this._creationOptions.timeStep || 1 / 60;
  }
  /** @internal */
  _verifyPointerLock() {
    var _a;
    (_a = this._onPointerLockChange) == null ? void 0 : _a.call(this);
  }
  /**
   * Gets current aspect ratio
   * @param viewportOwner defines the camera to use to get the aspect ratio
   * @param useScreen defines if screen size must be used (or the current render target if any)
   * @returns a number defining the aspect ratio
   */
  getAspectRatio(viewportOwner, useScreen = false) {
    const viewport = viewportOwner.viewport;
    return this.getRenderWidth(useScreen) * viewport.width / (this.getRenderHeight(useScreen) * viewport.height);
  }
  /**
   * Gets current screen aspect ratio
   * @returns a number defining the aspect ratio
   */
  getScreenAspectRatio() {
    return this.getRenderWidth(true) / this.getRenderHeight(true);
  }
  /**
   * Gets the client rect of the HTML canvas attached with the current webGL context
   * @returns a client rectangle
   */
  getRenderingCanvasClientRect() {
    if (!this._renderingCanvas) {
      return null;
    }
    return this._renderingCanvas.getBoundingClientRect();
  }
  /**
   * Gets the client rect of the HTML element used for events
   * @returns a client rectangle
   */
  getInputElementClientRect() {
    if (!this._renderingCanvas) {
      return null;
    }
    return this.getInputElement().getBoundingClientRect();
  }
  /**
   * Gets a boolean indicating that the engine is running in deterministic lock step mode
   * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
   * @returns true if engine is in deterministic lock step mode
   */
  isDeterministicLockStep() {
    return this._deterministicLockstep;
  }
  /**
   * Gets the max steps when engine is running in deterministic lock step
   * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
   * @returns the max steps
   */
  getLockstepMaxSteps() {
    return this._lockstepMaxSteps;
  }
  /**
   * Returns the time in ms between steps when using deterministic lock step.
   * @returns time step in (ms)
   */
  getTimeStep() {
    return this._timeStep * 1e3;
  }
  /**
   * Force the mipmap generation for the given render target texture
   * @param texture defines the render target texture to use
   * @param unbind defines whether or not to unbind the texture after generation. Defaults to true.
   */
  generateMipMapsForCubemap(texture, unbind = true) {
    if (texture.generateMipMaps) {
      const gl = this._gl;
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
      gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
      if (unbind) {
        this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
      }
    }
  }
  /** States */
  /**
   * Gets a boolean indicating if depth writing is enabled
   * @returns the current depth writing state
   */
  getDepthWrite() {
    return this._depthCullingState.depthMask;
  }
  /**
   * Enable or disable depth writing
   * @param enable defines the state to set
   */
  setDepthWrite(enable) {
    this._depthCullingState.depthMask = enable;
  }
  /**
   * Gets a boolean indicating if stencil buffer is enabled
   * @returns the current stencil buffer state
   */
  getStencilBuffer() {
    return this._stencilState.stencilTest;
  }
  /**
   * Enable or disable the stencil buffer
   * @param enable defines if the stencil buffer must be enabled or disabled
   */
  setStencilBuffer(enable) {
    this._stencilState.stencilTest = enable;
  }
  /**
   * Gets the current stencil mask
   * @returns a number defining the new stencil mask to use
   */
  getStencilMask() {
    return this._stencilState.stencilMask;
  }
  /**
   * Sets the current stencil mask
   * @param mask defines the new stencil mask to use
   */
  setStencilMask(mask) {
    this._stencilState.stencilMask = mask;
  }
  /**
   * Gets the current stencil function
   * @returns a number defining the stencil function to use
   */
  getStencilFunction() {
    return this._stencilState.stencilFunc;
  }
  /**
   * Gets the current stencil reference value
   * @returns a number defining the stencil reference value to use
   */
  getStencilFunctionReference() {
    return this._stencilState.stencilFuncRef;
  }
  /**
   * Gets the current stencil mask
   * @returns a number defining the stencil mask to use
   */
  getStencilFunctionMask() {
    return this._stencilState.stencilFuncMask;
  }
  /**
   * Sets the current stencil function
   * @param stencilFunc defines the new stencil function to use
   */
  setStencilFunction(stencilFunc) {
    this._stencilState.stencilFunc = stencilFunc;
  }
  /**
   * Sets the current stencil reference
   * @param reference defines the new stencil reference to use
   */
  setStencilFunctionReference(reference) {
    this._stencilState.stencilFuncRef = reference;
  }
  /**
   * Sets the current stencil mask
   * @param mask defines the new stencil mask to use
   */
  setStencilFunctionMask(mask) {
    this._stencilState.stencilFuncMask = mask;
  }
  /**
   * Gets the current stencil operation when stencil fails
   * @returns a number defining stencil operation to use when stencil fails
   */
  getStencilOperationFail() {
    return this._stencilState.stencilOpStencilFail;
  }
  /**
   * Gets the current stencil operation when depth fails
   * @returns a number defining stencil operation to use when depth fails
   */
  getStencilOperationDepthFail() {
    return this._stencilState.stencilOpDepthFail;
  }
  /**
   * Gets the current stencil operation when stencil passes
   * @returns a number defining stencil operation to use when stencil passes
   */
  getStencilOperationPass() {
    return this._stencilState.stencilOpStencilDepthPass;
  }
  /**
   * Sets the stencil operation to use when stencil fails
   * @param operation defines the stencil operation to use when stencil fails
   */
  setStencilOperationFail(operation) {
    this._stencilState.stencilOpStencilFail = operation;
  }
  /**
   * Sets the stencil operation to use when depth fails
   * @param operation defines the stencil operation to use when depth fails
   */
  setStencilOperationDepthFail(operation) {
    this._stencilState.stencilOpDepthFail = operation;
  }
  /**
   * Sets the stencil operation to use when stencil passes
   * @param operation defines the stencil operation to use when stencil passes
   */
  setStencilOperationPass(operation) {
    this._stencilState.stencilOpStencilDepthPass = operation;
  }
  /**
   * Sets a boolean indicating if the dithering state is enabled or disabled
   * @param value defines the dithering state
   */
  setDitheringState(value) {
    if (value) {
      this._gl.enable(this._gl.DITHER);
    } else {
      this._gl.disable(this._gl.DITHER);
    }
  }
  /**
   * Sets a boolean indicating if the rasterizer state is enabled or disabled
   * @param value defines the rasterizer state
   */
  setRasterizerState(value) {
    if (value) {
      this._gl.disable(this._gl.RASTERIZER_DISCARD);
    } else {
      this._gl.enable(this._gl.RASTERIZER_DISCARD);
    }
  }
  /**
   * Gets the current depth function
   * @returns a number defining the depth function
   */
  getDepthFunction() {
    return this._depthCullingState.depthFunc;
  }
  /**
   * Sets the current depth function
   * @param depthFunc defines the function to use
   */
  setDepthFunction(depthFunc) {
    this._depthCullingState.depthFunc = depthFunc;
  }
  /**
   * Sets the current depth function to GREATER
   */
  setDepthFunctionToGreater() {
    this.setDepthFunction(516);
  }
  /**
   * Sets the current depth function to GEQUAL
   */
  setDepthFunctionToGreaterOrEqual() {
    this.setDepthFunction(518);
  }
  /**
   * Sets the current depth function to LESS
   */
  setDepthFunctionToLess() {
    this.setDepthFunction(513);
  }
  /**
   * Sets the current depth function to LEQUAL
   */
  setDepthFunctionToLessOrEqual() {
    this.setDepthFunction(515);
  }
  /**
   * Caches the state of the stencil buffer
   */
  cacheStencilState() {
    this._cachedStencilBuffer = this.getStencilBuffer();
    this._cachedStencilFunction = this.getStencilFunction();
    this._cachedStencilMask = this.getStencilMask();
    this._cachedStencilOperationPass = this.getStencilOperationPass();
    this._cachedStencilOperationFail = this.getStencilOperationFail();
    this._cachedStencilOperationDepthFail = this.getStencilOperationDepthFail();
    this._cachedStencilReference = this.getStencilFunctionReference();
  }
  /**
   * Restores the state of the stencil buffer
   */
  restoreStencilState() {
    this.setStencilFunction(this._cachedStencilFunction);
    this.setStencilMask(this._cachedStencilMask);
    this.setStencilBuffer(this._cachedStencilBuffer);
    this.setStencilOperationPass(this._cachedStencilOperationPass);
    this.setStencilOperationFail(this._cachedStencilOperationFail);
    this.setStencilOperationDepthFail(this._cachedStencilOperationDepthFail);
    this.setStencilFunctionReference(this._cachedStencilReference);
  }
  /**
   * Directly set the WebGL Viewport
   * @param x defines the x coordinate of the viewport (in screen space)
   * @param y defines the y coordinate of the viewport (in screen space)
   * @param width defines the width of the viewport (in screen space)
   * @param height defines the height of the viewport (in screen space)
   * @returns the current viewport Object (if any) that is being replaced by this call. You can restore this viewport later on to go back to the original state
   */
  setDirectViewport(x, y, width, height) {
    const currentViewport = this._cachedViewport;
    this._cachedViewport = null;
    this._viewport(x, y, width, height);
    return currentViewport;
  }
  /**
   * Executes a scissor clear (ie. a clear on a specific portion of the screen)
   * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
   * @param y defines the y-coordinate of the corner of the clear rectangle
   * @param width defines the width of the clear rectangle
   * @param height defines the height of the clear rectangle
   * @param clearColor defines the clear color
   */
  scissorClear(x, y, width, height, clearColor) {
    this.enableScissor(x, y, width, height);
    this.clear(clearColor, true, true, true);
    this.disableScissor();
  }
  /**
   * Enable scissor test on a specific rectangle (ie. render will only be executed on a specific portion of the screen)
   * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
   * @param y defines the y-coordinate of the corner of the clear rectangle
   * @param width defines the width of the clear rectangle
   * @param height defines the height of the clear rectangle
   */
  enableScissor(x, y, width, height) {
    const gl = this._gl;
    gl.enable(gl.SCISSOR_TEST);
    gl.scissor(x, y, width, height);
  }
  /**
   * Disable previously set scissor test rectangle
   */
  disableScissor() {
    const gl = this._gl;
    gl.disable(gl.SCISSOR_TEST);
  }
  /**
   * @internal
   */
  _reportDrawCall(numDrawCalls = 1) {
    this._drawCalls.addCount(numDrawCalls, false);
  }
  /**
   * @internal
   */
  _loadFileAsync(url, offlineProvider, useArrayBuffer) {
    return new Promise((resolve, reject) => {
      this._loadFile(url, (data) => {
        resolve(data);
      }, void 0, offlineProvider, useArrayBuffer, (request, exception) => {
        reject(exception);
      });
    });
  }
  /**
   * Gets the source code of the vertex shader associated with a specific webGL program
   * @param program defines the program to use
   * @returns a string containing the source code of the vertex shader associated with the program
   */
  getVertexShaderSource(program) {
    const shaders = this._gl.getAttachedShaders(program);
    if (!shaders) {
      return null;
    }
    return this._gl.getShaderSource(shaders[0]);
  }
  /**
   * Gets the source code of the fragment shader associated with a specific webGL program
   * @param program defines the program to use
   * @returns a string containing the source code of the fragment shader associated with the program
   */
  getFragmentShaderSource(program) {
    const shaders = this._gl.getAttachedShaders(program);
    if (!shaders) {
      return null;
    }
    return this._gl.getShaderSource(shaders[1]);
  }
  /**
   * Sets a depth stencil texture from a render target to the according uniform.
   * @param channel The texture channel
   * @param uniform The uniform to set
   * @param texture The render target texture containing the depth stencil texture to apply
   * @param name The texture name
   */
  setDepthStencilTexture(channel, uniform, texture, name6) {
    if (channel === void 0) {
      return;
    }
    if (uniform) {
      this._boundUniforms[channel] = uniform;
    }
    if (!texture || !texture.depthStencilTexture) {
      this._setTexture(channel, null, void 0, void 0, name6);
    } else {
      this._setTexture(channel, texture, false, true, name6);
    }
  }
  /**
   * Sets a texture to the webGL context from a postprocess
   * @param channel defines the channel to use
   * @param postProcess defines the source postprocess
   * @param name name of the channel
   */
  setTextureFromPostProcess(channel, postProcess, name6) {
    let postProcessInput = null;
    if (postProcess) {
      if (postProcess._forcedOutputTexture) {
        postProcessInput = postProcess._forcedOutputTexture;
      } else if (postProcess._textures.data[postProcess._currentRenderTextureInd]) {
        postProcessInput = postProcess._textures.data[postProcess._currentRenderTextureInd];
      }
    }
    this._bindTexture(channel, (postProcessInput == null ? void 0 : postProcessInput.texture) ?? null, name6);
  }
  /**
   * Binds the output of the passed in post process to the texture channel specified
   * @param channel The channel the texture should be bound to
   * @param postProcess The post process which's output should be bound
   * @param name name of the channel
   */
  setTextureFromPostProcessOutput(channel, postProcess, name6) {
    var _a;
    this._bindTexture(channel, ((_a = postProcess == null ? void 0 : postProcess._outputTexture) == null ? void 0 : _a.texture) ?? null, name6);
  }
  /**
   * sets the object from which width and height will be taken from when getting render width and height
   * Will fallback to the gl object
   * @param dimensions the framebuffer width and height that will be used.
   */
  set framebufferDimensionsObject(dimensions) {
    this._framebufferDimensionsObject = dimensions;
    if (this._framebufferDimensionsObject) {
      this.onResizeObservable.notifyObservers(this);
    }
  }
  _rebuildBuffers() {
    for (const scene of this.scenes) {
      scene.resetCachedMaterial();
      scene._rebuildGeometries();
    }
    for (const scene of this._virtualScenes) {
      scene.resetCachedMaterial();
      scene._rebuildGeometries();
    }
    super._rebuildBuffers();
  }
  _rebuildTextures() {
    for (const scene of this.scenes) {
      scene._rebuildTextures();
    }
    for (const scene of this._virtualScenes) {
      scene._rebuildTextures();
    }
    super._rebuildTextures();
  }
  /** @internal */
  _renderFrame() {
    for (let index = 0; index < this._activeRenderLoops.length; index++) {
      const renderFunction = this._activeRenderLoops[index];
      renderFunction();
    }
  }
  _cancelFrame() {
    if (this.customAnimationFrameRequester) {
      if (this._frameHandler !== 0) {
        this._frameHandler = 0;
        const { cancelAnimationFrame } = this.customAnimationFrameRequester;
        if (cancelAnimationFrame) {
          cancelAnimationFrame(this.customAnimationFrameRequester.requestID);
        }
      }
    } else {
      super._cancelFrame();
    }
  }
  _renderLoop() {
    this._frameHandler = 0;
    if (!this._contextWasLost) {
      let shouldRender = true;
      if (this.isDisposed || !this.renderEvenInBackground && this._windowIsBackground) {
        shouldRender = false;
      }
      if (shouldRender) {
        this.beginFrame();
        if (!this._renderViews()) {
          this._renderFrame();
        }
        this.endFrame();
      }
    }
    if (this._frameHandler === 0) {
      if (this.customAnimationFrameRequester) {
        this.customAnimationFrameRequester.requestID = this._queueNewFrame(this.customAnimationFrameRequester.renderFunction || this._boundRenderFunction, this.customAnimationFrameRequester);
        this._frameHandler = this.customAnimationFrameRequester.requestID;
      } else {
        this._frameHandler = this._queueNewFrame(this._boundRenderFunction, this.getHostWindow());
      }
    }
  }
  /** @internal */
  _renderViews() {
    return false;
  }
  /**
   * Toggle full screen mode
   * @param requestPointerLock defines if a pointer lock should be requested from the user
   */
  switchFullscreen(requestPointerLock) {
    if (this.isFullscreen) {
      this.exitFullscreen();
    } else {
      this.enterFullscreen(requestPointerLock);
    }
  }
  /**
   * Enters full screen mode
   * @param requestPointerLock defines if a pointer lock should be requested from the user
   */
  enterFullscreen(requestPointerLock) {
    if (!this.isFullscreen) {
      this._pointerLockRequested = requestPointerLock;
      if (this._renderingCanvas) {
        _Engine._RequestFullscreen(this._renderingCanvas);
      }
    }
  }
  /**
   * Exits full screen mode
   */
  exitFullscreen() {
    if (this.isFullscreen) {
      _Engine._ExitFullscreen();
    }
  }
  /**
   * Enters Pointerlock mode
   */
  enterPointerlock() {
    if (this._renderingCanvas) {
      _Engine._RequestPointerlock(this._renderingCanvas);
    }
  }
  /**
   * Exits Pointerlock mode
   */
  exitPointerlock() {
    _Engine._ExitPointerlock();
  }
  /**
   * Begin a new frame
   */
  beginFrame() {
    this._measureFps();
    this.onBeginFrameObservable.notifyObservers(this);
    super.beginFrame();
  }
  /**
   * End the current frame
   */
  endFrame() {
    super.endFrame();
    this.onEndFrameObservable.notifyObservers(this);
  }
  /**
   * Force a specific size of the canvas
   * @param width defines the new canvas' width
   * @param height defines the new canvas' height
   * @param forceSetSize true to force setting the sizes of the underlying canvas
   * @returns true if the size was changed
   */
  setSize(width, height, forceSetSize = false) {
    if (!this._renderingCanvas) {
      return false;
    }
    if (!super.setSize(width, height, forceSetSize)) {
      return false;
    }
    if (this.scenes) {
      for (let index = 0; index < this.scenes.length; index++) {
        const scene = this.scenes[index];
        for (let camIndex = 0; camIndex < scene.cameras.length; camIndex++) {
          const cam = scene.cameras[camIndex];
          cam._currentRenderId = 0;
        }
      }
      if (this.onResizeObservable.hasObservers()) {
        this.onResizeObservable.notifyObservers(this);
      }
    }
    return true;
  }
  _deletePipelineContext(pipelineContext) {
    const webGLPipelineContext = pipelineContext;
    if (webGLPipelineContext && webGLPipelineContext.program) {
      if (webGLPipelineContext.transformFeedback) {
        this.deleteTransformFeedback(webGLPipelineContext.transformFeedback);
        webGLPipelineContext.transformFeedback = null;
      }
    }
    super._deletePipelineContext(pipelineContext);
  }
  createShaderProgram(pipelineContext, vertexCode, fragmentCode, defines, context, transformFeedbackVaryings = null) {
    context = context || this._gl;
    this.onBeforeShaderCompilationObservable.notifyObservers(this);
    const program = super.createShaderProgram(pipelineContext, vertexCode, fragmentCode, defines, context, transformFeedbackVaryings);
    this.onAfterShaderCompilationObservable.notifyObservers(this);
    return program;
  }
  _createShaderProgram(pipelineContext, vertexShader, fragmentShader, context, transformFeedbackVaryings = null) {
    const shaderProgram = context.createProgram();
    pipelineContext.program = shaderProgram;
    if (!shaderProgram) {
      throw new Error("Unable to create program");
    }
    context.attachShader(shaderProgram, vertexShader);
    context.attachShader(shaderProgram, fragmentShader);
    if (this.webGLVersion > 1 && transformFeedbackVaryings) {
      const transformFeedback = this.createTransformFeedback();
      this.bindTransformFeedback(transformFeedback);
      this.setTranformFeedbackVaryings(shaderProgram, transformFeedbackVaryings);
      pipelineContext.transformFeedback = transformFeedback;
    }
    context.linkProgram(shaderProgram);
    if (this.webGLVersion > 1 && transformFeedbackVaryings) {
      this.bindTransformFeedback(null);
    }
    pipelineContext.context = context;
    pipelineContext.vertexShader = vertexShader;
    pipelineContext.fragmentShader = fragmentShader;
    if (!pipelineContext.isParallelCompiled) {
      this._finalizePipelineContext(pipelineContext);
    }
    return shaderProgram;
  }
  /**
   * @internal
   */
  _releaseTexture(texture) {
    super._releaseTexture(texture);
  }
  /**
   * @internal
   */
  _releaseRenderTargetWrapper(rtWrapper) {
    super._releaseRenderTargetWrapper(rtWrapper);
    this.scenes.forEach((scene) => {
      scene.postProcesses.forEach((postProcess) => {
        if (postProcess._outputTexture === rtWrapper) {
          postProcess._outputTexture = null;
        }
      });
      scene.cameras.forEach((camera) => {
        camera._postProcesses.forEach((postProcess) => {
          if (postProcess) {
            if (postProcess._outputTexture === rtWrapper) {
              postProcess._outputTexture = null;
            }
          }
        });
      });
    });
  }
  /**
   * Gets the names of the render passes that are currently created
   * @returns list of the render pass names
   */
  getRenderPassNames() {
    return this._renderPassNames;
  }
  /**
   * Gets the name of the current render pass
   * @returns name of the current render pass
   */
  getCurrentRenderPassName() {
    return this._renderPassNames[this.currentRenderPassId];
  }
  /**
   * Creates a render pass id
   * @param name Name of the render pass (for debug purpose only)
   * @returns the id of the new render pass
   */
  createRenderPassId(name6) {
    const id = ++_Engine._RenderPassIdCounter;
    this._renderPassNames[id] = name6 ?? "NONAME";
    return id;
  }
  /**
   * Releases a render pass id
   * @param id id of the render pass to release
   */
  releaseRenderPassId(id) {
    this._renderPassNames[id] = void 0;
    for (let s = 0; s < this.scenes.length; ++s) {
      const scene = this.scenes[s];
      for (let m = 0; m < scene.meshes.length; ++m) {
        const mesh = scene.meshes[m];
        if (mesh.subMeshes) {
          for (let b = 0; b < mesh.subMeshes.length; ++b) {
            const subMesh = mesh.subMeshes[b];
            subMesh._removeDrawWrapper(id);
          }
        }
      }
    }
  }
  /**
   * @internal
   * Rescales a texture
   * @param source input texture
   * @param destination destination texture
   * @param scene scene to use to render the resize
   * @param internalFormat format to use when resizing
   * @param onComplete callback to be called when resize has completed
   */
  _rescaleTexture(source, destination, scene, internalFormat, onComplete) {
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MAG_FILTER, this._gl.LINEAR);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MIN_FILTER, this._gl.LINEAR);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_WRAP_S, this._gl.CLAMP_TO_EDGE);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_WRAP_T, this._gl.CLAMP_TO_EDGE);
    const rtt = this.createRenderTargetTexture({
      width: destination.width,
      height: destination.height
    }, {
      generateMipMaps: false,
      type: 0,
      samplingMode: 2,
      generateDepthBuffer: false,
      generateStencilBuffer: false
    });
    if (!this._rescalePostProcess && _Engine._RescalePostProcessFactory) {
      this._rescalePostProcess = _Engine._RescalePostProcessFactory(this);
    }
    if (this._rescalePostProcess) {
      this._rescalePostProcess.externalTextureSamplerBinding = true;
      this._rescalePostProcess.getEffect().executeWhenCompiled(() => {
        this._rescalePostProcess.onApply = function(effect) {
          effect._bindTexture("textureSampler", source);
        };
        let hostingScene = scene;
        if (!hostingScene) {
          hostingScene = this.scenes[this.scenes.length - 1];
        }
        hostingScene.postProcessManager.directRender([this._rescalePostProcess], rtt, true);
        this._bindTextureDirectly(this._gl.TEXTURE_2D, destination, true);
        this._gl.copyTexImage2D(this._gl.TEXTURE_2D, 0, internalFormat, 0, 0, destination.width, destination.height, 0);
        this.unBindFramebuffer(rtt);
        rtt.dispose();
        if (onComplete) {
          onComplete();
        }
      });
    }
  }
  // FPS
  /**
   * Gets the current framerate
   * @returns a number representing the framerate
   */
  getFps() {
    return this._fps;
  }
  /**
   * Gets the time spent between current and previous frame
   * @returns a number representing the delta time in ms
   */
  getDeltaTime() {
    return this._deltaTime;
  }
  _measureFps() {
    this._performanceMonitor.sampleFrame();
    this._fps = this._performanceMonitor.averageFPS;
    this._deltaTime = this._performanceMonitor.instantaneousFrameTime || 0;
  }
  /**
   * Wraps an external web gl texture in a Babylon texture.
   * @param texture defines the external texture
   * @param hasMipMaps defines whether the external texture has mip maps (default: false)
   * @param samplingMode defines the sampling mode for the external texture (default: 3)
   * @param width defines the width for the external texture (default: 0)
   * @param height defines the height for the external texture (default: 0)
   * @returns the babylon internal texture
   */
  wrapWebGLTexture(texture, hasMipMaps = false, samplingMode = 3, width = 0, height = 0) {
    const hardwareTexture = new WebGLHardwareTexture(texture, this._gl);
    const internalTexture = new InternalTexture(this, InternalTextureSource.Unknown, true);
    internalTexture._hardwareTexture = hardwareTexture;
    internalTexture.baseWidth = width;
    internalTexture.baseHeight = height;
    internalTexture.width = width;
    internalTexture.height = height;
    internalTexture.isReady = true;
    internalTexture.useMipMaps = hasMipMaps;
    this.updateTextureSamplingMode(samplingMode, internalTexture);
    return internalTexture;
  }
  /**
   * @internal
   */
  _uploadImageToTexture(texture, image, faceIndex = 0, lod = 0) {
    const gl = this._gl;
    const textureType = this._getWebGLTextureType(texture.type);
    const format = this._getInternalFormat(texture.format);
    const internalFormat = this._getRGBABufferInternalSizedFormat(texture.type, format);
    const bindTarget = texture.isCube ? gl.TEXTURE_CUBE_MAP : gl.TEXTURE_2D;
    this._bindTextureDirectly(bindTarget, texture, true);
    this._unpackFlipY(texture.invertY);
    let target = gl.TEXTURE_2D;
    if (texture.isCube) {
      target = gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex;
    }
    gl.texImage2D(target, lod, internalFormat, format, textureType, image);
    this._bindTextureDirectly(bindTarget, null, true);
  }
  /**
   * Updates a depth texture Comparison Mode and Function.
   * If the comparison Function is equal to 0, the mode will be set to none.
   * Otherwise, this only works in webgl 2 and requires a shadow sampler in the shader.
   * @param texture The texture to set the comparison function for
   * @param comparisonFunction The comparison function to set, 0 if no comparison required
   */
  updateTextureComparisonFunction(texture, comparisonFunction) {
    if (this.webGLVersion === 1) {
      Logger.Error("WebGL 1 does not support texture comparison.");
      return;
    }
    const gl = this._gl;
    if (texture.isCube) {
      this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, texture, true);
      if (comparisonFunction === 0) {
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_FUNC, 515);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_MODE, gl.NONE);
      } else {
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_FUNC, comparisonFunction);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_MODE, gl.COMPARE_REF_TO_TEXTURE);
      }
      this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, null);
    } else {
      this._bindTextureDirectly(this._gl.TEXTURE_2D, texture, true);
      if (comparisonFunction === 0) {
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_FUNC, 515);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_MODE, gl.NONE);
      } else {
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_FUNC, comparisonFunction);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_MODE, gl.COMPARE_REF_TO_TEXTURE);
      }
      this._bindTextureDirectly(this._gl.TEXTURE_2D, null);
    }
    texture._comparisonFunction = comparisonFunction;
  }
  /**
   * Creates a webGL buffer to use with instantiation
   * @param capacity defines the size of the buffer
   * @returns the webGL buffer
   */
  createInstancesBuffer(capacity) {
    const buffer = this._gl.createBuffer();
    if (!buffer) {
      throw new Error("Unable to create instance buffer");
    }
    const result = new WebGLDataBuffer(buffer);
    result.capacity = capacity;
    this.bindArrayBuffer(result);
    this._gl.bufferData(this._gl.ARRAY_BUFFER, capacity, this._gl.DYNAMIC_DRAW);
    result.references = 1;
    return result;
  }
  /**
   * Delete a webGL buffer used with instantiation
   * @param buffer defines the webGL buffer to delete
   */
  deleteInstancesBuffer(buffer) {
    this._gl.deleteBuffer(buffer);
  }
  _clientWaitAsync(sync, flags = 0, intervalms = 10) {
    const gl = this._gl;
    return new Promise((resolve, reject) => {
      const check = () => {
        const res = gl.clientWaitSync(sync, flags, 0);
        if (res == gl.WAIT_FAILED) {
          reject();
          return;
        }
        if (res == gl.TIMEOUT_EXPIRED) {
          setTimeout(check, intervalms);
          return;
        }
        resolve();
      };
      check();
    });
  }
  /**
   * @internal
   */
  _readPixelsAsync(x, y, w, h, format, type, outputBuffer) {
    if (this._webGLVersion < 2) {
      throw new Error("_readPixelsAsync only work on WebGL2+");
    }
    const gl = this._gl;
    const buf = gl.createBuffer();
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
    gl.bufferData(gl.PIXEL_PACK_BUFFER, outputBuffer.byteLength, gl.STREAM_READ);
    gl.readPixels(x, y, w, h, format, type, 0);
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
    const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
    if (!sync) {
      return null;
    }
    gl.flush();
    return this._clientWaitAsync(sync, 0, 10).then(() => {
      gl.deleteSync(sync);
      gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
      gl.getBufferSubData(gl.PIXEL_PACK_BUFFER, 0, outputBuffer);
      gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
      gl.deleteBuffer(buf);
      return outputBuffer;
    });
  }
  dispose() {
    this.hideLoadingUI();
    this.onNewSceneAddedObservable.clear();
    while (this.postProcesses.length) {
      this.postProcesses[0].dispose();
    }
    if (this._rescalePostProcess) {
      this._rescalePostProcess.dispose();
    }
    while (this.scenes.length) {
      this.scenes[0].dispose();
    }
    while (this._virtualScenes.length) {
      this._virtualScenes[0].dispose();
    }
    if (EngineStore.Instances.length === 1 && _Engine.audioEngine) {
      _Engine.audioEngine.dispose();
      _Engine.audioEngine = null;
    }
    const hostWindow = this.getHostWindow();
    if (hostWindow && typeof hostWindow.removeEventListener === "function") {
      hostWindow.removeEventListener("blur", this._onBlur);
      hostWindow.removeEventListener("focus", this._onFocus);
    }
    if (this._renderingCanvas) {
      this._renderingCanvas.removeEventListener("focus", this._onCanvasFocus);
      this._renderingCanvas.removeEventListener("blur", this._onCanvasBlur);
      this._renderingCanvas.removeEventListener("pointerout", this._onCanvasPointerOut);
      this._renderingCanvas.removeEventListener("contextmenu", this._onCanvasContextMenu);
    }
    if (IsDocumentAvailable()) {
      document.removeEventListener("fullscreenchange", this._onFullscreenChange);
      document.removeEventListener("mozfullscreenchange", this._onFullscreenChange);
      document.removeEventListener("webkitfullscreenchange", this._onFullscreenChange);
      document.removeEventListener("msfullscreenchange", this._onFullscreenChange);
      document.removeEventListener("pointerlockchange", this._onPointerLockChange);
      document.removeEventListener("mspointerlockchange", this._onPointerLockChange);
      document.removeEventListener("mozpointerlockchange", this._onPointerLockChange);
      document.removeEventListener("webkitpointerlockchange", this._onPointerLockChange);
    }
    super.dispose();
    const index = EngineStore.Instances.indexOf(this);
    if (index >= 0) {
      EngineStore.Instances.splice(index, 1);
    }
    if (!_Engine.Instances.length) {
      EngineStore.OnEnginesDisposedObservable.notifyObservers(this);
    }
    this.onResizeObservable.clear();
    this.onCanvasBlurObservable.clear();
    this.onCanvasFocusObservable.clear();
    this.onCanvasPointerOutObservable.clear();
    this.onBeginFrameObservable.clear();
    this.onEndFrameObservable.clear();
  }
  _disableTouchAction() {
    if (!this._renderingCanvas || !this._renderingCanvas.setAttribute) {
      return;
    }
    this._renderingCanvas.setAttribute("touch-action", "none");
    this._renderingCanvas.style.touchAction = "none";
    this._renderingCanvas.style.webkitTapHighlightColor = "transparent";
  }
  // Loading screen
  /**
   * Display the loading screen
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  displayLoadingUI() {
    if (!IsWindowObjectExist()) {
      return;
    }
    const loadingScreen = this.loadingScreen;
    if (loadingScreen) {
      loadingScreen.displayLoadingUI();
    }
  }
  /**
   * Hide the loading screen
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  hideLoadingUI() {
    if (!IsWindowObjectExist()) {
      return;
    }
    const loadingScreen = this._loadingScreen;
    if (loadingScreen) {
      loadingScreen.hideLoadingUI();
    }
  }
  /**
   * Gets the current loading screen object
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  get loadingScreen() {
    if (!this._loadingScreen && this._renderingCanvas) {
      this._loadingScreen = _Engine.DefaultLoadingScreenFactory(this._renderingCanvas);
    }
    return this._loadingScreen;
  }
  /**
   * Sets the current loading screen object
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  set loadingScreen(loadingScreen) {
    this._loadingScreen = loadingScreen;
  }
  /**
   * Sets the current loading screen text
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  set loadingUIText(text) {
    this.loadingScreen.loadingUIText = text;
  }
  /**
   * Sets the current loading screen background color
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
   */
  set loadingUIBackgroundColor(color) {
    this.loadingScreen.loadingUIBackgroundColor = color;
  }
  /**
   * creates and returns a new video element
   * @param constraints video constraints
   * @returns video element
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  createVideoElement(constraints) {
    return document.createElement("video");
  }
  /** Pointerlock and fullscreen */
  /**
   * Ask the browser to promote the current element to pointerlock mode
   * @param element defines the DOM element to promote
   */
  static _RequestPointerlock(element) {
    if (element.requestPointerLock) {
      const promise = element.requestPointerLock();
      if (promise instanceof Promise)
        promise.then(() => {
          element.focus();
        }).catch(() => {
        });
      else
        element.focus();
    }
  }
  /**
   * Asks the browser to exit pointerlock mode
   */
  static _ExitPointerlock() {
    if (document.exitPointerLock) {
      document.exitPointerLock();
    }
  }
  /**
   * Ask the browser to promote the current element to fullscreen rendering mode
   * @param element defines the DOM element to promote
   */
  static _RequestFullscreen(element) {
    const requestFunction = element.requestFullscreen || element.webkitRequestFullscreen;
    if (!requestFunction) {
      return;
    }
    requestFunction.call(element);
  }
  /**
   * Asks the browser to exit fullscreen mode
   */
  static _ExitFullscreen() {
    const anyDoc = document;
    if (document.exitFullscreen) {
      document.exitFullscreen();
    } else if (anyDoc.webkitCancelFullScreen) {
      anyDoc.webkitCancelFullScreen();
    }
  }
  /**
   * Get Font size information
   * @param font font name
   * @returns an object containing ascent, height and descent
   */
  getFontOffset(font) {
    const text = document.createElement("span");
    text.innerHTML = "Hg";
    text.setAttribute("style", `font: ${font} !important`);
    const block = document.createElement("div");
    block.style.display = "inline-block";
    block.style.width = "1px";
    block.style.height = "0px";
    block.style.verticalAlign = "bottom";
    const div = document.createElement("div");
    div.style.whiteSpace = "nowrap";
    div.appendChild(text);
    div.appendChild(block);
    document.body.appendChild(div);
    let fontAscent = 0;
    let fontHeight = 0;
    try {
      fontHeight = block.getBoundingClientRect().top - text.getBoundingClientRect().top;
      block.style.verticalAlign = "baseline";
      fontAscent = block.getBoundingClientRect().top - text.getBoundingClientRect().top;
    } finally {
      document.body.removeChild(div);
    }
    return { ascent: fontAscent, height: fontHeight, descent: fontHeight - fontAscent };
  }
};
Engine.ALPHA_DISABLE = 0;
Engine.ALPHA_ADD = 1;
Engine.ALPHA_COMBINE = 2;
Engine.ALPHA_SUBTRACT = 3;
Engine.ALPHA_MULTIPLY = 4;
Engine.ALPHA_MAXIMIZED = 5;
Engine.ALPHA_ONEONE = 6;
Engine.ALPHA_PREMULTIPLIED = 7;
Engine.ALPHA_PREMULTIPLIED_PORTERDUFF = 8;
Engine.ALPHA_INTERPOLATE = 9;
Engine.ALPHA_SCREENMODE = 10;
Engine.DELAYLOADSTATE_NONE = 0;
Engine.DELAYLOADSTATE_LOADED = 1;
Engine.DELAYLOADSTATE_LOADING = 2;
Engine.DELAYLOADSTATE_NOTLOADED = 4;
Engine.NEVER = 512;
Engine.ALWAYS = 519;
Engine.LESS = 513;
Engine.EQUAL = 514;
Engine.LEQUAL = 515;
Engine.GREATER = 516;
Engine.GEQUAL = 518;
Engine.NOTEQUAL = 517;
Engine.KEEP = 7680;
Engine.REPLACE = 7681;
Engine.INCR = 7682;
Engine.DECR = 7683;
Engine.INVERT = 5386;
Engine.INCR_WRAP = 34055;
Engine.DECR_WRAP = 34056;
Engine.TEXTURE_CLAMP_ADDRESSMODE = 0;
Engine.TEXTURE_WRAP_ADDRESSMODE = 1;
Engine.TEXTURE_MIRROR_ADDRESSMODE = 2;
Engine.TEXTUREFORMAT_ALPHA = 0;
Engine.TEXTUREFORMAT_LUMINANCE = 1;
Engine.TEXTUREFORMAT_LUMINANCE_ALPHA = 2;
Engine.TEXTUREFORMAT_RGB = 4;
Engine.TEXTUREFORMAT_RGBA = 5;
Engine.TEXTUREFORMAT_RED = 6;
Engine.TEXTUREFORMAT_R = 6;
Engine.TEXTUREFORMAT_RG = 7;
Engine.TEXTUREFORMAT_RED_INTEGER = 8;
Engine.TEXTUREFORMAT_R_INTEGER = 8;
Engine.TEXTUREFORMAT_RG_INTEGER = 9;
Engine.TEXTUREFORMAT_RGB_INTEGER = 10;
Engine.TEXTUREFORMAT_RGBA_INTEGER = 11;
Engine.TEXTURETYPE_UNSIGNED_BYTE = 0;
Engine.TEXTURETYPE_UNSIGNED_INT = 0;
Engine.TEXTURETYPE_FLOAT = 1;
Engine.TEXTURETYPE_HALF_FLOAT = 2;
Engine.TEXTURETYPE_BYTE = 3;
Engine.TEXTURETYPE_SHORT = 4;
Engine.TEXTURETYPE_UNSIGNED_SHORT = 5;
Engine.TEXTURETYPE_INT = 6;
Engine.TEXTURETYPE_UNSIGNED_INTEGER = 7;
Engine.TEXTURETYPE_UNSIGNED_SHORT_4_4_4_4 = 8;
Engine.TEXTURETYPE_UNSIGNED_SHORT_5_5_5_1 = 9;
Engine.TEXTURETYPE_UNSIGNED_SHORT_5_6_5 = 10;
Engine.TEXTURETYPE_UNSIGNED_INT_2_10_10_10_REV = 11;
Engine.TEXTURETYPE_UNSIGNED_INT_24_8 = 12;
Engine.TEXTURETYPE_UNSIGNED_INT_10F_11F_11F_REV = 13;
Engine.TEXTURETYPE_UNSIGNED_INT_5_9_9_9_REV = 14;
Engine.TEXTURETYPE_FLOAT_32_UNSIGNED_INT_24_8_REV = 15;
Engine.TEXTURE_NEAREST_SAMPLINGMODE = 1;
Engine.TEXTURE_BILINEAR_SAMPLINGMODE = 2;
Engine.TEXTURE_TRILINEAR_SAMPLINGMODE = 3;
Engine.TEXTURE_NEAREST_NEAREST_MIPLINEAR = 8;
Engine.TEXTURE_LINEAR_LINEAR_MIPNEAREST = 11;
Engine.TEXTURE_LINEAR_LINEAR_MIPLINEAR = 3;
Engine.TEXTURE_NEAREST_NEAREST_MIPNEAREST = 4;
Engine.TEXTURE_NEAREST_LINEAR_MIPNEAREST = 5;
Engine.TEXTURE_NEAREST_LINEAR_MIPLINEAR = 6;
Engine.TEXTURE_NEAREST_LINEAR = 7;
Engine.TEXTURE_NEAREST_NEAREST = 1;
Engine.TEXTURE_LINEAR_NEAREST_MIPNEAREST = 9;
Engine.TEXTURE_LINEAR_NEAREST_MIPLINEAR = 10;
Engine.TEXTURE_LINEAR_LINEAR = 2;
Engine.TEXTURE_LINEAR_NEAREST = 12;
Engine.TEXTURE_EXPLICIT_MODE = 0;
Engine.TEXTURE_SPHERICAL_MODE = 1;
Engine.TEXTURE_PLANAR_MODE = 2;
Engine.TEXTURE_CUBIC_MODE = 3;
Engine.TEXTURE_PROJECTION_MODE = 4;
Engine.TEXTURE_SKYBOX_MODE = 5;
Engine.TEXTURE_INVCUBIC_MODE = 6;
Engine.TEXTURE_EQUIRECTANGULAR_MODE = 7;
Engine.TEXTURE_FIXED_EQUIRECTANGULAR_MODE = 8;
Engine.TEXTURE_FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
Engine.SCALEMODE_FLOOR = 1;
Engine.SCALEMODE_NEAREST = 2;
Engine.SCALEMODE_CEILING = 3;
Engine._RescalePostProcessFactory = null;
Engine._RenderPassIdCounter = 0;

// node_modules/@babylonjs/core/Materials/Textures/thinTexture.js
var ThinTexture = class _ThinTexture {
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapU() {
    return this._wrapU;
  }
  set wrapU(value) {
    this._wrapU = value;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapV() {
    return this._wrapV;
  }
  set wrapV(value) {
    this._wrapV = value;
  }
  /**
   * How a texture is mapped.
   * Unused in thin texture mode.
   */
  get coordinatesMode() {
    return 0;
  }
  /**
   * Define if the texture is a cube texture or if false a 2d texture.
   */
  get isCube() {
    if (!this._texture) {
      return false;
    }
    return this._texture.isCube;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set isCube(value) {
    if (!this._texture) {
      return;
    }
    this._texture.isCube = value;
  }
  /**
   * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
   */
  get is3D() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is3D;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is3D(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is3D = value;
  }
  /**
   * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
   */
  get is2DArray() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is2DArray;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is2DArray(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is2DArray = value;
  }
  /**
   * Get the class name of the texture.
   * @returns "ThinTexture"
   */
  getClassName() {
    return "ThinTexture";
  }
  static _IsRenderTargetWrapper(texture) {
    return (texture == null ? void 0 : texture._shareDepth) !== void 0;
  }
  /**
   * Instantiates a new ThinTexture.
   * Base class of all the textures in babylon.
   * This can be used as an internal texture wrapper in ThinEngine to benefit from the cache
   * @param internalTexture Define the internalTexture to wrap. You can also pass a RenderTargetWrapper, in which case the texture will be the render target's texture
   */
  constructor(internalTexture) {
    this._wrapU = 1;
    this._wrapV = 1;
    this.wrapR = 1;
    this.anisotropicFilteringLevel = 4;
    this.delayLoadState = 0;
    this._texture = null;
    this._engine = null;
    this._cachedSize = Size.Zero();
    this._cachedBaseSize = Size.Zero();
    this._initialSamplingMode = 2;
    this._texture = _ThinTexture._IsRenderTargetWrapper(internalTexture) ? internalTexture.texture : internalTexture;
    if (this._texture) {
      this._engine = this._texture.getEngine();
    }
  }
  /**
   * Get if the texture is ready to be used (downloaded, converted, mip mapped...).
   * @returns true if fully ready
   */
  isReady() {
    if (this.delayLoadState === 4) {
      this.delayLoad();
      return false;
    }
    if (this._texture) {
      return this._texture.isReady;
    }
    return false;
  }
  /**
   * Triggers the load sequence in delayed load mode.
   */
  delayLoad() {
  }
  /**
   * Get the underlying lower level texture from Babylon.
   * @returns the internal texture
   */
  getInternalTexture() {
    return this._texture;
  }
  /**
   * Get the size of the texture.
   * @returns the texture size.
   */
  getSize() {
    if (this._texture) {
      if (this._texture.width) {
        this._cachedSize.width = this._texture.width;
        this._cachedSize.height = this._texture.height;
        return this._cachedSize;
      }
      if (this._texture._size) {
        this._cachedSize.width = this._texture._size;
        this._cachedSize.height = this._texture._size;
        return this._cachedSize;
      }
    }
    return this._cachedSize;
  }
  /**
   * Get the base size of the texture.
   * It can be different from the size if the texture has been resized for POT for instance
   * @returns the base size
   */
  getBaseSize() {
    if (!this.isReady() || !this._texture) {
      this._cachedBaseSize.width = 0;
      this._cachedBaseSize.height = 0;
      return this._cachedBaseSize;
    }
    if (this._texture._size) {
      this._cachedBaseSize.width = this._texture._size;
      this._cachedBaseSize.height = this._texture._size;
      return this._cachedBaseSize;
    }
    this._cachedBaseSize.width = this._texture.baseWidth;
    this._cachedBaseSize.height = this._texture.baseHeight;
    return this._cachedBaseSize;
  }
  /**
   * Get the current sampling mode associated with the texture.
   */
  get samplingMode() {
    if (!this._texture) {
      return this._initialSamplingMode;
    }
    return this._texture.samplingMode;
  }
  /**
   * Update the sampling mode of the texture.
   * Default is Trilinear mode.
   *
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 1     | NEAREST_SAMPLINGMODE or NEAREST_NEAREST_MIPLINEAR  | Nearest is: mag = nearest, min = nearest, mip = linear |
   * | 2     | BILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPNEAREST | Bilinear is: mag = linear, min = linear, mip = nearest |
   * | 3     | TRILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPLINEAR | Trilinear is: mag = linear, min = linear, mip = linear |
   * | 4     | NEAREST_NEAREST_MIPNEAREST |             |
   * | 5    | NEAREST_LINEAR_MIPNEAREST |             |
   * | 6    | NEAREST_LINEAR_MIPLINEAR |             |
   * | 7    | NEAREST_LINEAR |             |
   * | 8    | NEAREST_NEAREST |             |
   * | 9   | LINEAR_NEAREST_MIPNEAREST |             |
   * | 10   | LINEAR_NEAREST_MIPLINEAR |             |
   * | 11   | LINEAR_LINEAR |             |
   * | 12   | LINEAR_NEAREST |             |
   *
   *    > _mag_: magnification filter (close to the viewer)
   *    > _min_: minification filter (far from the viewer)
   *    > _mip_: filter used between mip map levels
   *@param samplingMode Define the new sampling mode of the texture
   */
  updateSamplingMode(samplingMode) {
    if (this._texture && this._engine) {
      this._engine.updateTextureSamplingMode(samplingMode, this._texture);
    }
  }
  /**
   * Release and destroy the underlying lower level texture aka internalTexture.
   */
  releaseInternalTexture() {
    if (this._texture) {
      this._texture.dispose();
      this._texture = null;
    }
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    if (this._texture) {
      this.releaseInternalTexture();
      this._engine = null;
    }
  }
};

// node_modules/@babylonjs/core/Materials/Textures/baseTexture.js
var BaseTexture = class _BaseTexture extends ThinTexture {
  /**
   * Define if the texture is having a usable alpha value (can be use for transparency or glossiness for instance).
   */
  set hasAlpha(value) {
    if (this._hasAlpha === value) {
      return;
    }
    this._hasAlpha = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get hasAlpha() {
    return this._hasAlpha;
  }
  /**
   * Defines if the alpha value should be determined via the rgb values.
   * If true the luminance of the pixel might be used to find the corresponding alpha value.
   */
  set getAlphaFromRGB(value) {
    if (this._getAlphaFromRGB === value) {
      return;
    }
    this._getAlphaFromRGB = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get getAlphaFromRGB() {
    return this._getAlphaFromRGB;
  }
  /**
   * Define the UV channel to use starting from 0 and defaulting to 0.
   * This is part of the texture as textures usually maps to one uv set.
   */
  set coordinatesIndex(value) {
    if (this._coordinatesIndex === value) {
      return;
    }
    this._coordinatesIndex = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get coordinatesIndex() {
    return this._coordinatesIndex;
  }
  /**
   * How a texture is mapped.
   *
   * | Value | Type                                | Description |
   * | ----- | ----------------------------------- | ----------- |
   * | 0     | EXPLICIT_MODE                       |             |
   * | 1     | SPHERICAL_MODE                      |             |
   * | 2     | PLANAR_MODE                         |             |
   * | 3     | CUBIC_MODE                          |             |
   * | 4     | PROJECTION_MODE                     |             |
   * | 5     | SKYBOX_MODE                         |             |
   * | 6     | INVCUBIC_MODE                       |             |
   * | 7     | EQUIRECTANGULAR_MODE                |             |
   * | 8     | FIXED_EQUIRECTANGULAR_MODE          |             |
   * | 9     | FIXED_EQUIRECTANGULAR_MIRRORED_MODE |             |
   */
  set coordinatesMode(value) {
    if (this._coordinatesMode === value) {
      return;
    }
    this._coordinatesMode = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get coordinatesMode() {
    return this._coordinatesMode;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapU() {
    return this._wrapU;
  }
  set wrapU(value) {
    this._wrapU = value;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapV() {
    return this._wrapV;
  }
  set wrapV(value) {
    this._wrapV = value;
  }
  /**
   * Define if the texture is a cube texture or if false a 2d texture.
   */
  get isCube() {
    if (!this._texture) {
      return this._isCube;
    }
    return this._texture.isCube;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set isCube(value) {
    if (!this._texture) {
      this._isCube = value;
    } else {
      this._texture.isCube = value;
    }
  }
  /**
   * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
   */
  get is3D() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is3D;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is3D(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is3D = value;
  }
  /**
   * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
   */
  get is2DArray() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is2DArray;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is2DArray(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is2DArray = value;
  }
  /**
   * Define if the texture contains data in gamma space (most of the png/jpg aside bump).
   * HDR texture are usually stored in linear space.
   * This only impacts the PBR and Background materials
   */
  get gammaSpace() {
    if (!this._texture) {
      return this._gammaSpace;
    } else {
      if (this._texture._gammaSpace === null) {
        this._texture._gammaSpace = this._gammaSpace;
      }
    }
    return this._texture._gammaSpace && !this._texture._useSRGBBuffer;
  }
  set gammaSpace(gamma) {
    var _a;
    if (!this._texture) {
      if (this._gammaSpace === gamma) {
        return;
      }
      this._gammaSpace = gamma;
    } else {
      if (this._texture._gammaSpace === gamma) {
        return;
      }
      this._texture._gammaSpace = gamma;
    }
    (_a = this.getScene()) == null ? void 0 : _a.markAllMaterialsAsDirty(1, (mat) => {
      return mat.hasTexture(this);
    });
  }
  /**
   * Gets or sets whether or not the texture contains RGBD data.
   */
  get isRGBD() {
    return this._texture != null && this._texture._isRGBD;
  }
  set isRGBD(value) {
    var _a;
    if (value === this.isRGBD) {
      return;
    }
    if (this._texture) {
      this._texture._isRGBD = value;
    }
    (_a = this.getScene()) == null ? void 0 : _a.markAllMaterialsAsDirty(1, (mat) => {
      return mat.hasTexture(this);
    });
  }
  /**
   * Are mip maps generated for this texture or not.
   */
  get noMipmap() {
    return false;
  }
  /**
   * With prefiltered texture, defined the offset used during the prefiltering steps.
   */
  get lodGenerationOffset() {
    if (this._texture) {
      return this._texture._lodGenerationOffset;
    }
    return 0;
  }
  set lodGenerationOffset(value) {
    if (this._texture) {
      this._texture._lodGenerationOffset = value;
    }
  }
  /**
   * With prefiltered texture, defined the scale used during the prefiltering steps.
   */
  get lodGenerationScale() {
    if (this._texture) {
      return this._texture._lodGenerationScale;
    }
    return 0;
  }
  set lodGenerationScale(value) {
    if (this._texture) {
      this._texture._lodGenerationScale = value;
    }
  }
  /**
   * With prefiltered texture, defined if the specular generation is based on a linear ramp.
   * By default we are using a log2 of the linear roughness helping to keep a better resolution for
   * average roughness values.
   */
  get linearSpecularLOD() {
    if (this._texture) {
      return this._texture._linearSpecularLOD;
    }
    return false;
  }
  set linearSpecularLOD(value) {
    if (this._texture) {
      this._texture._linearSpecularLOD = value;
    }
  }
  /**
   * In case a better definition than spherical harmonics is required for the diffuse part of the environment.
   * You can set the irradiance texture to rely on a texture instead of the spherical approach.
   * This texture need to have the same characteristics than its parent (Cube vs 2d, coordinates mode, Gamma/Linear, RGBD).
   */
  get irradianceTexture() {
    if (this._texture) {
      return this._texture._irradianceTexture;
    }
    return null;
  }
  set irradianceTexture(value) {
    if (this._texture) {
      this._texture._irradianceTexture = value;
    }
  }
  /**
   * Define the unique id of the texture in the scene.
   */
  get uid() {
    if (!this._uid) {
      this._uid = RandomGUID();
    }
    return this._uid;
  }
  /**
   * Return a string representation of the texture.
   * @returns the texture as a string
   */
  toString() {
    return this.name;
  }
  /**
   * Get the class name of the texture.
   * @returns "BaseTexture"
   */
  getClassName() {
    return "BaseTexture";
  }
  /**
   * Callback triggered when the texture has been disposed.
   * Kept for back compatibility, you can use the onDisposeObservable instead.
   */
  set onDispose(callback) {
    if (this._onDisposeObserver) {
      this.onDisposeObservable.remove(this._onDisposeObserver);
    }
    this._onDisposeObserver = this.onDisposeObservable.add(callback);
  }
  /**
   * Define if the texture is preventing a material to render or not.
   * If not and the texture is not ready, the engine will use a default black texture instead.
   */
  get isBlocking() {
    return true;
  }
  /**
   * Was there any loading error?
   */
  get loadingError() {
    return this._loadingError;
  }
  /**
   * If a loading error occurred this object will be populated with information about the error.
   */
  get errorObject() {
    return this._errorObject;
  }
  /**
   * Instantiates a new BaseTexture.
   * Base class of all the textures in babylon.
   * It groups all the common properties the materials, post process, lights... might need
   * in order to make a correct use of the texture.
   * @param sceneOrEngine Define the scene or engine the texture belongs to
   * @param internalTexture Define the internal texture associated with the texture
   */
  constructor(sceneOrEngine, internalTexture = null) {
    super(null);
    this.metadata = null;
    this.reservedDataStore = null;
    this._hasAlpha = false;
    this._getAlphaFromRGB = false;
    this.level = 1;
    this._coordinatesIndex = 0;
    this.optimizeUVAllocation = true;
    this._coordinatesMode = 0;
    this.wrapR = 1;
    this.anisotropicFilteringLevel = _BaseTexture.DEFAULT_ANISOTROPIC_FILTERING_LEVEL;
    this._isCube = false;
    this._gammaSpace = true;
    this.invertZ = false;
    this.lodLevelInAlpha = false;
    this.isRenderTarget = false;
    this._prefiltered = false;
    this._forceSerialize = false;
    this.animations = [];
    this.onDisposeObservable = new Observable();
    this._onDisposeObserver = null;
    this._scene = null;
    this._uid = null;
    this._parentContainer = null;
    this._loadingError = false;
    if (sceneOrEngine) {
      if (_BaseTexture._IsScene(sceneOrEngine)) {
        this._scene = sceneOrEngine;
      } else {
        this._engine = sceneOrEngine;
      }
    } else {
      this._scene = EngineStore.LastCreatedScene;
    }
    if (this._scene) {
      this.uniqueId = this._scene.getUniqueId();
      this._scene.addTexture(this);
      this._engine = this._scene.getEngine();
    }
    this._texture = internalTexture;
    this._uid = null;
  }
  /**
   * Get the scene the texture belongs to.
   * @returns the scene or null if undefined
   */
  getScene() {
    return this._scene;
  }
  /** @internal */
  _getEngine() {
    return this._engine;
  }
  /**
   * Checks if the texture has the same transform matrix than another texture
   * @param texture texture to check against
   * @returns true if the transforms are the same, else false
   */
  checkTransformsAreIdentical(texture) {
    return texture !== null;
  }
  /**
   * Get the texture transform matrix used to offset tile the texture for instance.
   * @returns the transformation matrix
   */
  getTextureMatrix() {
    return Matrix.IdentityReadOnly;
  }
  /**
   * Get the texture reflection matrix used to rotate/transform the reflection.
   * @returns the reflection matrix
   */
  getReflectionTextureMatrix() {
    return Matrix.IdentityReadOnly;
  }
  /**
   * Gets a suitable rotate/transform matrix when the texture is used for refraction.
   * There's a separate function from getReflectionTextureMatrix because refraction requires a special configuration of the matrix in right-handed mode.
   * @returns The refraction matrix
   */
  getRefractionTextureMatrix() {
    return this.getReflectionTextureMatrix();
  }
  /**
   * Get if the texture is ready to be consumed (either it is ready or it is not blocking)
   * @returns true if ready, not blocking or if there was an error loading the texture
   */
  isReadyOrNotBlocking() {
    return !this.isBlocking || this.isReady() || this.loadingError;
  }
  /**
   * Scales the texture if is `canRescale()`
   * @param ratio the resize factor we want to use to rescale
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  scale(ratio) {
  }
  /**
   * Get if the texture can rescale.
   */
  get canRescale() {
    return false;
  }
  /**
   * @internal
   */
  _getFromCache(url, noMipmap, sampling, invertY, useSRGBBuffer, isCube) {
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    const correctedUseSRGBBuffer = engine._getUseSRGBBuffer(!!useSRGBBuffer, noMipmap);
    const texturesCache = engine.getLoadedTexturesCache();
    for (let index = 0; index < texturesCache.length; index++) {
      const texturesCacheEntry = texturesCache[index];
      if (useSRGBBuffer === void 0 || correctedUseSRGBBuffer === texturesCacheEntry._useSRGBBuffer) {
        if (invertY === void 0 || invertY === texturesCacheEntry.invertY) {
          if (texturesCacheEntry.url === url && texturesCacheEntry.generateMipMaps === !noMipmap) {
            if (!sampling || sampling === texturesCacheEntry.samplingMode) {
              if (isCube === void 0 || isCube === texturesCacheEntry.isCube) {
                texturesCacheEntry.incrementReferences();
                return texturesCacheEntry;
              }
            }
          }
        }
      }
    }
    return null;
  }
  /** @internal */
  _rebuild(_fromContextLost = false) {
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    return null;
  }
  /**
   * Get the texture underlying type (INT, FLOAT...)
   */
  get textureType() {
    if (!this._texture) {
      return 0;
    }
    return this._texture.type !== void 0 ? this._texture.type : 0;
  }
  /**
   * Get the texture underlying format (RGB, RGBA...)
   */
  get textureFormat() {
    if (!this._texture) {
      return 5;
    }
    return this._texture.format !== void 0 ? this._texture.format : 5;
  }
  /**
   * Indicates that textures need to be re-calculated for all materials
   */
  _markAllSubMeshesAsTexturesDirty() {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    scene.markAllMaterialsAsDirty(1);
  }
  /**
   * Reads the pixels stored in the webgl texture and returns them as an ArrayBuffer.
   * This will returns an RGBA array buffer containing either in values (0-255) or
   * float values (0-1) depending of the underlying buffer type.
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @param buffer defines a user defined buffer to fill with data (can be null)
   * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
   * @param noDataConversion false to convert the data to Uint8Array (if texture type is UNSIGNED_BYTE) or to Float32Array (if texture type is anything but UNSIGNED_BYTE). If true, the type of the generated buffer (if buffer==null) will depend on the type of the texture
   * @param x defines the region x coordinates to start reading from (default to 0)
   * @param y defines the region y coordinates to start reading from (default to 0)
   * @param width defines the region width to read from (default to the texture size at level)
   * @param height defines the region width to read from (default to the texture size at level)
   * @returns The Array buffer promise containing the pixels data.
   */
  readPixels(faceIndex = 0, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0, width = Number.MAX_VALUE, height = Number.MAX_VALUE) {
    if (!this._texture) {
      return null;
    }
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    const size = this.getSize();
    let maxWidth = size.width;
    let maxHeight = size.height;
    if (level !== 0) {
      maxWidth = maxWidth / Math.pow(2, level);
      maxHeight = maxHeight / Math.pow(2, level);
      maxWidth = Math.round(maxWidth);
      maxHeight = Math.round(maxHeight);
    }
    width = Math.min(maxWidth, width);
    height = Math.min(maxHeight, height);
    try {
      if (this._texture.isCube) {
        return engine._readTexturePixels(this._texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion, x, y);
      }
      return engine._readTexturePixels(this._texture, width, height, -1, level, buffer, flushRenderer, noDataConversion, x, y);
    } catch (e) {
      return null;
    }
  }
  /**
   * @internal
   */
  _readPixelsSync(faceIndex = 0, level = 0, buffer = null, flushRenderer = true, noDataConversion = false) {
    if (!this._texture) {
      return null;
    }
    const size = this.getSize();
    let width = size.width;
    let height = size.height;
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    if (level != 0) {
      width = width / Math.pow(2, level);
      height = height / Math.pow(2, level);
      width = Math.round(width);
      height = Math.round(height);
    }
    try {
      if (this._texture.isCube) {
        return engine._readTexturePixelsSync(this._texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion);
      }
      return engine._readTexturePixelsSync(this._texture, width, height, -1, level, buffer, flushRenderer, noDataConversion);
    } catch (e) {
      return null;
    }
  }
  /** @internal */
  get _lodTextureHigh() {
    if (this._texture) {
      return this._texture._lodTextureHigh;
    }
    return null;
  }
  /** @internal */
  get _lodTextureMid() {
    if (this._texture) {
      return this._texture._lodTextureMid;
    }
    return null;
  }
  /** @internal */
  get _lodTextureLow() {
    if (this._texture) {
      return this._texture._lodTextureLow;
    }
    return null;
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    if (this._scene) {
      if (this._scene.stopAnimation) {
        this._scene.stopAnimation(this);
      }
      this._scene.removePendingData(this);
      const index = this._scene.textures.indexOf(this);
      if (index >= 0) {
        this._scene.textures.splice(index, 1);
      }
      this._scene.onTextureRemovedObservable.notifyObservers(this);
      this._scene = null;
      if (this._parentContainer) {
        const index2 = this._parentContainer.textures.indexOf(this);
        if (index2 > -1) {
          this._parentContainer.textures.splice(index2, 1);
        }
        this._parentContainer = null;
      }
    }
    this.onDisposeObservable.notifyObservers(this);
    this.onDisposeObservable.clear();
    this.metadata = null;
    super.dispose();
  }
  /**
   * Serialize the texture into a JSON representation that can be parsed later on.
   * @param allowEmptyName True to force serialization even if name is empty. Default: false
   * @returns the JSON representation of the texture
   */
  serialize(allowEmptyName = false) {
    if (!this.name && !allowEmptyName) {
      return null;
    }
    const serializationObject = SerializationHelper.Serialize(this);
    SerializationHelper.AppendSerializedAnimations(this, serializationObject);
    return serializationObject;
  }
  /**
   * Helper function to be called back once a list of texture contains only ready textures.
   * @param textures Define the list of textures to wait for
   * @param callback Define the callback triggered once the entire list will be ready
   */
  static WhenAllReady(textures, callback) {
    let numRemaining = textures.length;
    if (numRemaining === 0) {
      callback();
      return;
    }
    for (let i = 0; i < textures.length; i++) {
      const texture = textures[i];
      if (texture.isReady()) {
        if (--numRemaining === 0) {
          callback();
        }
      } else {
        const onLoadObservable = texture.onLoadObservable;
        if (onLoadObservable) {
          onLoadObservable.addOnce(() => {
            if (--numRemaining === 0) {
              callback();
            }
          });
        } else {
          if (--numRemaining === 0) {
            callback();
          }
        }
      }
    }
  }
  static _IsScene(sceneOrEngine) {
    return sceneOrEngine.getClassName() === "Scene";
  }
};
BaseTexture.DEFAULT_ANISOTROPIC_FILTERING_LEVEL = 4;
__decorate([
  serialize()
], BaseTexture.prototype, "uniqueId", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "name", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "metadata", void 0);
__decorate([
  serialize("hasAlpha")
], BaseTexture.prototype, "_hasAlpha", void 0);
__decorate([
  serialize("getAlphaFromRGB")
], BaseTexture.prototype, "_getAlphaFromRGB", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "level", void 0);
__decorate([
  serialize("coordinatesIndex")
], BaseTexture.prototype, "_coordinatesIndex", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "optimizeUVAllocation", void 0);
__decorate([
  serialize("coordinatesMode")
], BaseTexture.prototype, "_coordinatesMode", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapU", null);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapV", null);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapR", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "anisotropicFilteringLevel", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "isCube", null);
__decorate([
  serialize()
], BaseTexture.prototype, "is3D", null);
__decorate([
  serialize()
], BaseTexture.prototype, "is2DArray", null);
__decorate([
  serialize()
], BaseTexture.prototype, "gammaSpace", null);
__decorate([
  serialize()
], BaseTexture.prototype, "invertZ", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "lodLevelInAlpha", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "lodGenerationOffset", null);
__decorate([
  serialize()
], BaseTexture.prototype, "lodGenerationScale", null);
__decorate([
  serialize()
], BaseTexture.prototype, "linearSpecularLOD", null);
__decorate([
  serializeAsTexture()
], BaseTexture.prototype, "irradianceTexture", null);
__decorate([
  serialize()
], BaseTexture.prototype, "isRenderTarget", void 0);

// node_modules/@babylonjs/core/Misc/copyTools.js
function GenerateBase64StringFromPixelData(pixels, size, invertY = false) {
  const width = size.width;
  const height = size.height;
  if (pixels instanceof Float32Array) {
    let len = pixels.byteLength / pixels.BYTES_PER_ELEMENT;
    const npixels = new Uint8Array(len);
    while (--len >= 0) {
      let val = pixels[len];
      if (val < 0) {
        val = 0;
      } else if (val > 1) {
        val = 1;
      }
      npixels[len] = val * 255;
    }
    pixels = npixels;
  }
  const canvas = document.createElement("canvas");
  canvas.width = width;
  canvas.height = height;
  const ctx = canvas.getContext("2d");
  if (!ctx) {
    return null;
  }
  const imageData = ctx.createImageData(width, height);
  const castData = imageData.data;
  castData.set(pixels);
  ctx.putImageData(imageData, 0, 0);
  if (invertY) {
    const canvas2 = document.createElement("canvas");
    canvas2.width = width;
    canvas2.height = height;
    const ctx2 = canvas2.getContext("2d");
    if (!ctx2) {
      return null;
    }
    ctx2.translate(0, height);
    ctx2.scale(1, -1);
    ctx2.drawImage(canvas, 0, 0);
    return canvas2.toDataURL("image/png");
  }
  return canvas.toDataURL("image/png");
}
function GenerateBase64StringFromTexture(texture, faceIndex = 0, level = 0) {
  const internalTexture = texture.getInternalTexture();
  if (!internalTexture) {
    return null;
  }
  const pixels = texture._readPixelsSync(faceIndex, level);
  if (!pixels) {
    return null;
  }
  return GenerateBase64StringFromPixelData(pixels, texture.getSize(), internalTexture.invertY);
}
async function GenerateBase64StringFromTextureAsync(texture, faceIndex = 0, level = 0) {
  const internalTexture = texture.getInternalTexture();
  if (!internalTexture) {
    return null;
  }
  const pixels = await texture.readPixels(faceIndex, level);
  if (!pixels) {
    return null;
  }
  return GenerateBase64StringFromPixelData(pixels, texture.getSize(), internalTexture.invertY);
}
var CopyTools = {
  /**
   * Transform some pixel data to a base64 string
   * @param pixels defines the pixel data to transform to base64
   * @param size defines the width and height of the (texture) data
   * @param invertY true if the data must be inverted for the Y coordinate during the conversion
   * @returns The base64 encoded string or null
   */
  GenerateBase64StringFromPixelData,
  /**
   * Reads the pixels stored in the webgl texture and returns them as a base64 string
   * @param texture defines the texture to read pixels from
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @returns The base64 encoded string or null
   */
  GenerateBase64StringFromTexture,
  /**
   * Reads the pixels stored in the webgl texture and returns them as a base64 string
   * @param texture defines the texture to read pixels from
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @returns The base64 encoded string or null wrapped in a promise
   */
  GenerateBase64StringFromTextureAsync
};

// node_modules/@babylonjs/core/Materials/Textures/texture.js
var Texture = class _Texture extends BaseTexture {
  /**
   * @internal
   */
  static _CreateVideoTexture(name6, src, scene, generateMipMaps = false, invertY = false, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, settings = {}, onError, format = 5) {
    throw _WarnImport("VideoTexture");
  }
  /**
   * Are mip maps generated for this texture or not.
   */
  get noMipmap() {
    return this._noMipmap;
  }
  /** Returns the texture mime type if it was defined by a loader (undefined else) */
  get mimeType() {
    return this._mimeType;
  }
  /**
   * Is the texture preventing material to render while loading.
   * If false, a default texture will be used instead of the loading one during the preparation step.
   */
  set isBlocking(value) {
    this._isBlocking = value;
  }
  get isBlocking() {
    return this._isBlocking;
  }
  /**
   * Gets a boolean indicating if the texture needs to be inverted on the y axis during loading
   */
  get invertY() {
    return this._invertY;
  }
  /**
   * Instantiates a new texture.
   * This represents a texture in babylon. It can be easily loaded from a network, base64 or html input.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#texture
   * @param url defines the url of the picture to load as a texture
   * @param sceneOrEngine defines the scene or engine the texture will belong to
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY defines if the texture needs to be inverted on the y axis during loading
   * @param samplingMode defines the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad defines a callback triggered when the texture has been loaded
   * @param onError defines a callback triggered when an error occurred during the loading session
   * @param buffer defines the buffer to load the texture from in case the texture is loaded from a buffer representation
   * @param deleteBuffer defines if the buffer we are loading the texture from should be deleted after load
   * @param format defines the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param mimeType defines an optional mime type information
   * @param loaderOptions options to be passed to the loader
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @param forcedExtension defines the extension to use to pick the right loader
   */
  constructor(url, sceneOrEngine, noMipmapOrOptions, invertY, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, buffer = null, deleteBuffer = false, format, mimeType, loaderOptions, creationFlags, forcedExtension) {
    super(sceneOrEngine);
    this.url = null;
    this.uOffset = 0;
    this.vOffset = 0;
    this.uScale = 1;
    this.vScale = 1;
    this.uAng = 0;
    this.vAng = 0;
    this.wAng = 0;
    this.uRotationCenter = 0.5;
    this.vRotationCenter = 0.5;
    this.wRotationCenter = 0.5;
    this.homogeneousRotationInUVTransform = false;
    this.inspectableCustomProperties = null;
    this._noMipmap = false;
    this._invertY = false;
    this._rowGenerationMatrix = null;
    this._cachedTextureMatrix = null;
    this._projectionModeMatrix = null;
    this._t0 = null;
    this._t1 = null;
    this._t2 = null;
    this._cachedUOffset = -1;
    this._cachedVOffset = -1;
    this._cachedUScale = 0;
    this._cachedVScale = 0;
    this._cachedUAng = -1;
    this._cachedVAng = -1;
    this._cachedWAng = -1;
    this._cachedReflectionProjectionMatrixId = -1;
    this._cachedURotationCenter = -1;
    this._cachedVRotationCenter = -1;
    this._cachedWRotationCenter = -1;
    this._cachedHomogeneousRotationInUVTransform = false;
    this._cachedReflectionTextureMatrix = null;
    this._cachedReflectionUOffset = -1;
    this._cachedReflectionVOffset = -1;
    this._cachedReflectionUScale = 0;
    this._cachedReflectionVScale = 0;
    this._cachedReflectionCoordinatesMode = -1;
    this._buffer = null;
    this._deleteBuffer = false;
    this._format = null;
    this._delayedOnLoad = null;
    this._delayedOnError = null;
    this.onLoadObservable = new Observable();
    this._isBlocking = true;
    this.name = url || "";
    this.url = url;
    let noMipmap;
    let useSRGBBuffer = false;
    let internalTexture = null;
    let gammaSpace = true;
    if (typeof noMipmapOrOptions === "object" && noMipmapOrOptions !== null) {
      noMipmap = noMipmapOrOptions.noMipmap ?? false;
      invertY = noMipmapOrOptions.invertY ?? (CompatibilityOptions.UseOpenGLOrientationForUV ? false : true);
      samplingMode = noMipmapOrOptions.samplingMode ?? _Texture.TRILINEAR_SAMPLINGMODE;
      onLoad = noMipmapOrOptions.onLoad ?? null;
      onError = noMipmapOrOptions.onError ?? null;
      buffer = noMipmapOrOptions.buffer ?? null;
      deleteBuffer = noMipmapOrOptions.deleteBuffer ?? false;
      format = noMipmapOrOptions.format;
      mimeType = noMipmapOrOptions.mimeType;
      loaderOptions = noMipmapOrOptions.loaderOptions;
      creationFlags = noMipmapOrOptions.creationFlags;
      useSRGBBuffer = noMipmapOrOptions.useSRGBBuffer ?? false;
      internalTexture = noMipmapOrOptions.internalTexture ?? null;
      gammaSpace = noMipmapOrOptions.gammaSpace ?? gammaSpace;
    } else {
      noMipmap = !!noMipmapOrOptions;
    }
    this._gammaSpace = gammaSpace;
    this._noMipmap = noMipmap;
    this._invertY = invertY === void 0 ? CompatibilityOptions.UseOpenGLOrientationForUV ? false : true : invertY;
    this._initialSamplingMode = samplingMode;
    this._buffer = buffer;
    this._deleteBuffer = deleteBuffer;
    this._mimeType = mimeType;
    this._loaderOptions = loaderOptions;
    this._creationFlags = creationFlags;
    this._useSRGBBuffer = useSRGBBuffer;
    this._forcedExtension = forcedExtension;
    if (format) {
      this._format = format;
    }
    const scene = this.getScene();
    const engine = this._getEngine();
    if (!engine) {
      return;
    }
    engine.onBeforeTextureInitObservable.notifyObservers(this);
    const load = () => {
      if (this._texture) {
        if (this._texture._invertVScale) {
          this.vScale *= -1;
          this.vOffset += 1;
        }
        if (this._texture._cachedWrapU !== null) {
          this.wrapU = this._texture._cachedWrapU;
          this._texture._cachedWrapU = null;
        }
        if (this._texture._cachedWrapV !== null) {
          this.wrapV = this._texture._cachedWrapV;
          this._texture._cachedWrapV = null;
        }
        if (this._texture._cachedWrapR !== null) {
          this.wrapR = this._texture._cachedWrapR;
          this._texture._cachedWrapR = null;
        }
      }
      if (this.onLoadObservable.hasObservers()) {
        this.onLoadObservable.notifyObservers(this);
      }
      if (onLoad) {
        onLoad();
      }
      if (!this.isBlocking && scene) {
        scene.resetCachedMaterial();
      }
    };
    const errorHandler = (message, exception) => {
      this._loadingError = true;
      this._errorObject = { message, exception };
      if (onError) {
        onError(message, exception);
      }
      _Texture.OnTextureLoadErrorObservable.notifyObservers(this);
    };
    if (!this.url && !internalTexture) {
      this._delayedOnLoad = load;
      this._delayedOnError = errorHandler;
      return;
    }
    this._texture = internalTexture ?? this._getFromCache(this.url, noMipmap, samplingMode, this._invertY, useSRGBBuffer, this.isCube);
    if (!this._texture) {
      if (!scene || !scene.useDelayedTextureLoading) {
        try {
          this._texture = engine.createTexture(this.url, noMipmap, this._invertY, scene, samplingMode, load, errorHandler, this._buffer, void 0, this._format, this._forcedExtension, mimeType, loaderOptions, creationFlags, useSRGBBuffer);
        } catch (e) {
          errorHandler("error loading", e);
          throw e;
        }
        if (deleteBuffer) {
          this._buffer = null;
        }
      } else {
        this.delayLoadState = 4;
        this._delayedOnLoad = load;
        this._delayedOnError = errorHandler;
      }
    } else {
      if (this._texture.isReady) {
        TimingTools.SetImmediate(() => load());
      } else {
        const loadObserver = this._texture.onLoadedObservable.add(load);
        this._texture.onErrorObservable.add((e) => {
          var _a;
          errorHandler(e.message, e.exception);
          (_a = this._texture) == null ? void 0 : _a.onLoadedObservable.remove(loadObserver);
        });
      }
    }
  }
  /**
   * Update the url (and optional buffer) of this texture if url was null during construction.
   * @param url the url of the texture
   * @param buffer the buffer of the texture (defaults to null)
   * @param onLoad callback called when the texture is loaded  (defaults to null)
   * @param forcedExtension defines the extension to use to pick the right loader
   */
  updateURL(url, buffer = null, onLoad, forcedExtension) {
    if (this.url) {
      this.releaseInternalTexture();
      this.getScene().markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    if (!this.name || this.name.startsWith("data:")) {
      this.name = url;
    }
    this.url = url;
    this._buffer = buffer;
    this._forcedExtension = forcedExtension;
    this.delayLoadState = 4;
    if (onLoad) {
      this._delayedOnLoad = onLoad;
    }
    this.delayLoad();
  }
  /**
   * Finish the loading sequence of a texture flagged as delayed load.
   * @internal
   */
  delayLoad() {
    if (this.delayLoadState !== 4) {
      return;
    }
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this.delayLoadState = 1;
    this._texture = this._getFromCache(this.url, this._noMipmap, this.samplingMode, this._invertY, this._useSRGBBuffer, this.isCube);
    if (!this._texture) {
      this._texture = scene.getEngine().createTexture(this.url, this._noMipmap, this._invertY, scene, this.samplingMode, this._delayedOnLoad, this._delayedOnError, this._buffer, null, this._format, this._forcedExtension, this._mimeType, this._loaderOptions, this._creationFlags, this._useSRGBBuffer);
      if (this._deleteBuffer) {
        this._buffer = null;
      }
    } else {
      if (this._delayedOnLoad) {
        if (this._texture.isReady) {
          TimingTools.SetImmediate(this._delayedOnLoad);
        } else {
          this._texture.onLoadedObservable.add(this._delayedOnLoad);
        }
      }
    }
    this._delayedOnLoad = null;
    this._delayedOnError = null;
  }
  _prepareRowForTextureGeneration(x, y, z, t) {
    x *= this._cachedUScale;
    y *= this._cachedVScale;
    x -= this.uRotationCenter * this._cachedUScale;
    y -= this.vRotationCenter * this._cachedVScale;
    z -= this.wRotationCenter;
    Vector3.TransformCoordinatesFromFloatsToRef(x, y, z, this._rowGenerationMatrix, t);
    t.x += this.uRotationCenter * this._cachedUScale + this._cachedUOffset;
    t.y += this.vRotationCenter * this._cachedVScale + this._cachedVOffset;
    t.z += this.wRotationCenter;
  }
  /**
   * Checks if the texture has the same transform matrix than another texture
   * @param texture texture to check against
   * @returns true if the transforms are the same, else false
   */
  checkTransformsAreIdentical(texture) {
    return texture !== null && this.uOffset === texture.uOffset && this.vOffset === texture.vOffset && this.uScale === texture.uScale && this.vScale === texture.vScale && this.uAng === texture.uAng && this.vAng === texture.vAng && this.wAng === texture.wAng;
  }
  /**
   * Get the current texture matrix which includes the requested offsetting, tiling and rotation components.
   * @param uBase The horizontal base offset multiplier (1 by default)
   * @returns the transform matrix of the texture.
   */
  getTextureMatrix(uBase = 1) {
    if (this.uOffset === this._cachedUOffset && this.vOffset === this._cachedVOffset && this.uScale * uBase === this._cachedUScale && this.vScale === this._cachedVScale && this.uAng === this._cachedUAng && this.vAng === this._cachedVAng && this.wAng === this._cachedWAng && this.uRotationCenter === this._cachedURotationCenter && this.vRotationCenter === this._cachedVRotationCenter && this.wRotationCenter === this._cachedWRotationCenter && this.homogeneousRotationInUVTransform === this._cachedHomogeneousRotationInUVTransform) {
      return this._cachedTextureMatrix;
    }
    this._cachedUOffset = this.uOffset;
    this._cachedVOffset = this.vOffset;
    this._cachedUScale = this.uScale * uBase;
    this._cachedVScale = this.vScale;
    this._cachedUAng = this.uAng;
    this._cachedVAng = this.vAng;
    this._cachedWAng = this.wAng;
    this._cachedURotationCenter = this.uRotationCenter;
    this._cachedVRotationCenter = this.vRotationCenter;
    this._cachedWRotationCenter = this.wRotationCenter;
    this._cachedHomogeneousRotationInUVTransform = this.homogeneousRotationInUVTransform;
    if (!this._cachedTextureMatrix || !this._rowGenerationMatrix) {
      this._cachedTextureMatrix = Matrix.Zero();
      this._rowGenerationMatrix = new Matrix();
      this._t0 = Vector3.Zero();
      this._t1 = Vector3.Zero();
      this._t2 = Vector3.Zero();
    }
    Matrix.RotationYawPitchRollToRef(this.vAng, this.uAng, this.wAng, this._rowGenerationMatrix);
    if (this.homogeneousRotationInUVTransform) {
      Matrix.TranslationToRef(-this._cachedURotationCenter, -this._cachedVRotationCenter, -this._cachedWRotationCenter, TmpVectors.Matrix[0]);
      Matrix.TranslationToRef(this._cachedURotationCenter, this._cachedVRotationCenter, this._cachedWRotationCenter, TmpVectors.Matrix[1]);
      Matrix.ScalingToRef(this._cachedUScale, this._cachedVScale, 0, TmpVectors.Matrix[2]);
      Matrix.TranslationToRef(this._cachedUOffset, this._cachedVOffset, 0, TmpVectors.Matrix[3]);
      TmpVectors.Matrix[0].multiplyToRef(this._rowGenerationMatrix, this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[1], this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[2], this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[3], this._cachedTextureMatrix);
      this._cachedTextureMatrix.setRowFromFloats(2, this._cachedTextureMatrix.m[12], this._cachedTextureMatrix.m[13], this._cachedTextureMatrix.m[14], 1);
    } else {
      this._prepareRowForTextureGeneration(0, 0, 0, this._t0);
      this._prepareRowForTextureGeneration(1, 0, 0, this._t1);
      this._prepareRowForTextureGeneration(0, 1, 0, this._t2);
      this._t1.subtractInPlace(this._t0);
      this._t2.subtractInPlace(this._t0);
      Matrix.FromValuesToRef(this._t1.x, this._t1.y, this._t1.z, 0, this._t2.x, this._t2.y, this._t2.z, 0, this._t0.x, this._t0.y, this._t0.z, 0, 0, 0, 0, 1, this._cachedTextureMatrix);
    }
    const scene = this.getScene();
    if (!scene) {
      return this._cachedTextureMatrix;
    }
    if (this.optimizeUVAllocation) {
      scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    return this._cachedTextureMatrix;
  }
  /**
   * Get the current matrix used to apply reflection. This is useful to rotate an environment texture for instance.
   * @returns The reflection texture transform
   */
  getReflectionTextureMatrix() {
    const scene = this.getScene();
    if (!scene) {
      return this._cachedReflectionTextureMatrix;
    }
    if (this.uOffset === this._cachedReflectionUOffset && this.vOffset === this._cachedReflectionVOffset && this.uScale === this._cachedReflectionUScale && this.vScale === this._cachedReflectionVScale && this.coordinatesMode === this._cachedReflectionCoordinatesMode) {
      if (this.coordinatesMode === _Texture.PROJECTION_MODE) {
        if (this._cachedReflectionProjectionMatrixId === scene.getProjectionMatrix().updateFlag) {
          return this._cachedReflectionTextureMatrix;
        }
      } else {
        return this._cachedReflectionTextureMatrix;
      }
    }
    if (!this._cachedReflectionTextureMatrix) {
      this._cachedReflectionTextureMatrix = Matrix.Zero();
    }
    if (!this._projectionModeMatrix) {
      this._projectionModeMatrix = Matrix.Zero();
    }
    const flagMaterialsAsTextureDirty = this._cachedReflectionCoordinatesMode !== this.coordinatesMode;
    this._cachedReflectionUOffset = this.uOffset;
    this._cachedReflectionVOffset = this.vOffset;
    this._cachedReflectionUScale = this.uScale;
    this._cachedReflectionVScale = this.vScale;
    this._cachedReflectionCoordinatesMode = this.coordinatesMode;
    switch (this.coordinatesMode) {
      case _Texture.PLANAR_MODE: {
        Matrix.IdentityToRef(this._cachedReflectionTextureMatrix);
        this._cachedReflectionTextureMatrix[0] = this.uScale;
        this._cachedReflectionTextureMatrix[5] = this.vScale;
        this._cachedReflectionTextureMatrix[12] = this.uOffset;
        this._cachedReflectionTextureMatrix[13] = this.vOffset;
        break;
      }
      case _Texture.PROJECTION_MODE: {
        Matrix.FromValuesToRef(0.5, 0, 0, 0, 0, -0.5, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, this._projectionModeMatrix);
        const projectionMatrix = scene.getProjectionMatrix();
        this._cachedReflectionProjectionMatrixId = projectionMatrix.updateFlag;
        projectionMatrix.multiplyToRef(this._projectionModeMatrix, this._cachedReflectionTextureMatrix);
        break;
      }
      default:
        Matrix.IdentityToRef(this._cachedReflectionTextureMatrix);
        break;
    }
    if (flagMaterialsAsTextureDirty) {
      scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    return this._cachedReflectionTextureMatrix;
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    const options = {
      noMipmap: this._noMipmap,
      invertY: this._invertY,
      samplingMode: this.samplingMode,
      onLoad: void 0,
      onError: void 0,
      buffer: this._texture ? this._texture._buffer : void 0,
      deleteBuffer: this._deleteBuffer,
      format: this.textureFormat,
      mimeType: this.mimeType,
      loaderOptions: this._loaderOptions,
      creationFlags: this._creationFlags,
      useSRGBBuffer: this._useSRGBBuffer
    };
    return SerializationHelper.Clone(() => {
      return new _Texture(this._texture ? this._texture.url : null, this.getScene(), options);
    }, this);
  }
  /**
   * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
   * @returns The JSON representation of the texture
   */
  serialize() {
    var _a;
    const savedName = this.name;
    if (!_Texture.SerializeBuffers) {
      if (this.name.startsWith("data:")) {
        this.name = "";
      }
    }
    if (this.name.startsWith("data:") && this.url === this.name) {
      this.url = "";
    }
    const serializationObject = super.serialize(_Texture._SerializeInternalTextureUniqueId);
    if (!serializationObject) {
      return null;
    }
    if (_Texture.SerializeBuffers || _Texture.ForceSerializeBuffers) {
      if (typeof this._buffer === "string" && this._buffer.substr(0, 5) === "data:") {
        serializationObject.base64String = this._buffer;
        serializationObject.name = serializationObject.name.replace("data:", "");
      } else if (this.url && this.url.startsWith("data:") && this._buffer instanceof Uint8Array) {
        serializationObject.base64String = "data:image/png;base64," + EncodeArrayBufferToBase64(this._buffer);
      } else if (_Texture.ForceSerializeBuffers || this.url && this.url.startsWith("blob:") || this._forceSerialize) {
        serializationObject.base64String = !this._engine || this._engine._features.supportSyncTextureRead ? GenerateBase64StringFromTexture(this) : GenerateBase64StringFromTextureAsync(this);
      }
    }
    serializationObject.invertY = this._invertY;
    serializationObject.samplingMode = this.samplingMode;
    serializationObject._creationFlags = this._creationFlags;
    serializationObject._useSRGBBuffer = this._useSRGBBuffer;
    if (_Texture._SerializeInternalTextureUniqueId) {
      serializationObject.internalTextureUniqueId = ((_a = this._texture) == null ? void 0 : _a.uniqueId) ?? void 0;
    }
    serializationObject.noMipmap = this._noMipmap;
    this.name = savedName;
    return serializationObject;
  }
  /**
   * Get the current class name of the texture useful for serialization or dynamic coding.
   * @returns "Texture"
   */
  getClassName() {
    return "Texture";
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    super.dispose();
    this.onLoadObservable.clear();
    this._delayedOnLoad = null;
    this._delayedOnError = null;
    this._buffer = null;
  }
  /**
   * Parse the JSON representation of a texture in order to recreate the texture in the given scene.
   * @param parsedTexture Define the JSON representation of the texture
   * @param scene Define the scene the parsed texture should be instantiated in
   * @param rootUrl Define the root url of the parsing sequence in the case of relative dependencies
   * @returns The parsed texture if successful
   */
  static Parse(parsedTexture, scene, rootUrl) {
    if (parsedTexture.customType) {
      const customTexture = InstantiationTools.Instantiate(parsedTexture.customType);
      const parsedCustomTexture = customTexture.Parse(parsedTexture, scene, rootUrl);
      if (parsedTexture.samplingMode && parsedCustomTexture.updateSamplingMode && parsedCustomTexture._samplingMode) {
        if (parsedCustomTexture._samplingMode !== parsedTexture.samplingMode) {
          parsedCustomTexture.updateSamplingMode(parsedTexture.samplingMode);
        }
      }
      return parsedCustomTexture;
    }
    if (parsedTexture.isCube && !parsedTexture.isRenderTarget) {
      return _Texture._CubeTextureParser(parsedTexture, scene, rootUrl);
    }
    const hasInternalTextureUniqueId = parsedTexture.internalTextureUniqueId !== void 0;
    if (!parsedTexture.name && !parsedTexture.isRenderTarget && !hasInternalTextureUniqueId) {
      return null;
    }
    let internalTexture;
    if (hasInternalTextureUniqueId) {
      const cache = scene.getEngine().getLoadedTexturesCache();
      for (const texture2 of cache) {
        if (texture2.uniqueId === parsedTexture.internalTextureUniqueId) {
          internalTexture = texture2;
          break;
        }
      }
    }
    const onLoaded = (texture2) => {
      var _a;
      if (texture2 && texture2._texture) {
        texture2._texture._cachedWrapU = null;
        texture2._texture._cachedWrapV = null;
        texture2._texture._cachedWrapR = null;
      }
      if (parsedTexture.samplingMode) {
        const sampling = parsedTexture.samplingMode;
        if (texture2 && texture2.samplingMode !== sampling) {
          texture2.updateSamplingMode(sampling);
        }
      }
      if (texture2 && parsedTexture.animations) {
        for (let animationIndex = 0; animationIndex < parsedTexture.animations.length; animationIndex++) {
          const parsedAnimation = parsedTexture.animations[animationIndex];
          const internalClass = GetClass("BABYLON.Animation");
          if (internalClass) {
            texture2.animations.push(internalClass.Parse(parsedAnimation));
          }
        }
      }
      if (hasInternalTextureUniqueId && !internalTexture) {
        (_a = texture2 == null ? void 0 : texture2._texture) == null ? void 0 : _a._setUniqueId(parsedTexture.internalTextureUniqueId);
      }
    };
    const texture = SerializationHelper.Parse(() => {
      let generateMipMaps = true;
      if (parsedTexture.noMipmap) {
        generateMipMaps = false;
      }
      if (parsedTexture.mirrorPlane) {
        const mirrorTexture = _Texture._CreateMirror(parsedTexture.name, parsedTexture.renderTargetSize, scene, generateMipMaps);
        mirrorTexture._waitingRenderList = parsedTexture.renderList;
        mirrorTexture.mirrorPlane = Plane.FromArray(parsedTexture.mirrorPlane);
        onLoaded(mirrorTexture);
        return mirrorTexture;
      } else if (parsedTexture.isRenderTarget) {
        let renderTargetTexture = null;
        if (parsedTexture.isCube) {
          if (scene.reflectionProbes) {
            for (let index = 0; index < scene.reflectionProbes.length; index++) {
              const probe = scene.reflectionProbes[index];
              if (probe.name === parsedTexture.name) {
                return probe.cubeTexture;
              }
            }
          }
        } else {
          renderTargetTexture = _Texture._CreateRenderTargetTexture(parsedTexture.name, parsedTexture.renderTargetSize, scene, generateMipMaps, parsedTexture._creationFlags ?? 0);
          renderTargetTexture._waitingRenderList = parsedTexture.renderList;
        }
        onLoaded(renderTargetTexture);
        return renderTargetTexture;
      } else if (parsedTexture.isVideo) {
        const texture2 = _Texture._CreateVideoTexture(rootUrl + (parsedTexture.url || parsedTexture.name), rootUrl + (parsedTexture.src || parsedTexture.url), scene, generateMipMaps, parsedTexture.invertY, parsedTexture.samplingMode, parsedTexture.settings || {});
        onLoaded(texture2);
        return texture2;
      } else {
        let texture2;
        if (parsedTexture.base64String && !internalTexture) {
          texture2 = _Texture.CreateFromBase64String(parsedTexture.base64String, parsedTexture.base64String, scene, !generateMipMaps, parsedTexture.invertY, parsedTexture.samplingMode, () => {
            onLoaded(texture2);
          }, parsedTexture._creationFlags ?? 0, parsedTexture._useSRGBBuffer ?? false);
          texture2.name = parsedTexture.name;
        } else {
          let url;
          if (parsedTexture.name && (parsedTexture.name.indexOf("://") > 0 || parsedTexture.name.startsWith("data:"))) {
            url = parsedTexture.name;
          } else {
            url = rootUrl + parsedTexture.name;
          }
          if (parsedTexture.url && (parsedTexture.url.startsWith("data:") || _Texture.UseSerializedUrlIfAny)) {
            url = parsedTexture.url;
          }
          const options = {
            noMipmap: !generateMipMaps,
            invertY: parsedTexture.invertY,
            samplingMode: parsedTexture.samplingMode,
            onLoad: () => {
              onLoaded(texture2);
            },
            internalTexture
          };
          texture2 = new _Texture(url, scene, options);
        }
        return texture2;
      }
    }, parsedTexture, scene);
    return texture;
  }
  /**
   * Creates a texture from its base 64 representation.
   * @param data Define the base64 payload without the data: prefix
   * @param name Define the name of the texture in the scene useful fo caching purpose for instance
   * @param scene Define the scene the texture should belong to
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY define if the texture needs to be inverted on the y axis during loading
   * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad define a callback triggered when the texture has been loaded
   * @param onError define a callback triggered when an error occurred during the loading session
   * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @returns the created texture
   */
  static CreateFromBase64String(data, name6, scene, noMipmapOrOptions, invertY, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, format = 5, creationFlags) {
    return new _Texture("data:" + name6, scene, noMipmapOrOptions, invertY, samplingMode, onLoad, onError, data, false, format, void 0, void 0, creationFlags);
  }
  /**
   * Creates a texture from its data: representation. (data: will be added in case only the payload has been passed in)
   * @param name Define the name of the texture in the scene useful fo caching purpose for instance
   * @param buffer define the buffer to load the texture from in case the texture is loaded from a buffer representation
   * @param scene Define the scene the texture should belong to
   * @param deleteBuffer define if the buffer we are loading the texture from should be deleted after load
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY define if the texture needs to be inverted on the y axis during loading
   * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad define a callback triggered when the texture has been loaded
   * @param onError define a callback triggered when an error occurred during the loading session
   * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @returns the created texture
   */
  static LoadFromDataString(name6, buffer, scene, deleteBuffer = false, noMipmapOrOptions, invertY = true, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, format = 5, creationFlags) {
    if (name6.substr(0, 5) !== "data:") {
      name6 = "data:" + name6;
    }
    return new _Texture(name6, scene, noMipmapOrOptions, invertY, samplingMode, onLoad, onError, buffer, deleteBuffer, format, void 0, void 0, creationFlags);
  }
};
Texture.SerializeBuffers = true;
Texture.ForceSerializeBuffers = false;
Texture.OnTextureLoadErrorObservable = new Observable();
Texture._SerializeInternalTextureUniqueId = false;
Texture._CubeTextureParser = (jsonTexture, scene, rootUrl) => {
  throw _WarnImport("CubeTexture");
};
Texture._CreateMirror = (name6, renderTargetSize, scene, generateMipMaps) => {
  throw _WarnImport("MirrorTexture");
};
Texture._CreateRenderTargetTexture = (name6, renderTargetSize, scene, generateMipMaps, creationFlags) => {
  throw _WarnImport("RenderTargetTexture");
};
Texture.NEAREST_SAMPLINGMODE = 1;
Texture.NEAREST_NEAREST_MIPLINEAR = 8;
Texture.BILINEAR_SAMPLINGMODE = 2;
Texture.LINEAR_LINEAR_MIPNEAREST = 11;
Texture.TRILINEAR_SAMPLINGMODE = 3;
Texture.LINEAR_LINEAR_MIPLINEAR = 3;
Texture.NEAREST_NEAREST_MIPNEAREST = 4;
Texture.NEAREST_LINEAR_MIPNEAREST = 5;
Texture.NEAREST_LINEAR_MIPLINEAR = 6;
Texture.NEAREST_LINEAR = 7;
Texture.NEAREST_NEAREST = 1;
Texture.LINEAR_NEAREST_MIPNEAREST = 9;
Texture.LINEAR_NEAREST_MIPLINEAR = 10;
Texture.LINEAR_LINEAR = 2;
Texture.LINEAR_NEAREST = 12;
Texture.EXPLICIT_MODE = 0;
Texture.SPHERICAL_MODE = 1;
Texture.PLANAR_MODE = 2;
Texture.CUBIC_MODE = 3;
Texture.PROJECTION_MODE = 4;
Texture.SKYBOX_MODE = 5;
Texture.INVCUBIC_MODE = 6;
Texture.EQUIRECTANGULAR_MODE = 7;
Texture.FIXED_EQUIRECTANGULAR_MODE = 8;
Texture.FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
Texture.CLAMP_ADDRESSMODE = 0;
Texture.WRAP_ADDRESSMODE = 1;
Texture.MIRROR_ADDRESSMODE = 2;
Texture.UseSerializedUrlIfAny = false;
__decorate([
  serialize()
], Texture.prototype, "url", void 0);
__decorate([
  serialize()
], Texture.prototype, "uOffset", void 0);
__decorate([
  serialize()
], Texture.prototype, "vOffset", void 0);
__decorate([
  serialize()
], Texture.prototype, "uScale", void 0);
__decorate([
  serialize()
], Texture.prototype, "vScale", void 0);
__decorate([
  serialize()
], Texture.prototype, "uAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "vAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "wAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "uRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "vRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "wRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "homogeneousRotationInUVTransform", void 0);
__decorate([
  serialize()
], Texture.prototype, "isBlocking", null);
RegisterClass("BABYLON.Texture", Texture);
SerializationHelper._TextureParser = Texture.Parse;

// node_modules/@babylonjs/core/Maths/math.vertexFormat.js
var PositionNormalVertex = class _PositionNormalVertex {
  /**
   * Creates a PositionNormalVertex
   * @param position the position of the vertex (defaut: 0,0,0)
   * @param normal the normal of the vertex (defaut: 0,1,0)
   */
  constructor(position = Vector3.Zero(), normal = Vector3.Up()) {
    this.position = position;
    this.normal = normal;
  }
  /**
   * Clones the PositionNormalVertex
   * @returns the cloned PositionNormalVertex
   */
  clone() {
    return new _PositionNormalVertex(this.position.clone(), this.normal.clone());
  }
};
var PositionNormalTextureVertex = class _PositionNormalTextureVertex {
  /**
   * Creates a PositionNormalTextureVertex
   * @param position the position of the vertex (defaut: 0,0,0)
   * @param normal the normal of the vertex (defaut: 0,1,0)
   * @param uv the uv of the vertex (default: 0,0)
   */
  constructor(position = Vector3.Zero(), normal = Vector3.Up(), uv = Vector2.Zero()) {
    this.position = position;
    this.normal = normal;
    this.uv = uv;
  }
  /**
   * Clones the PositionNormalTextureVertex
   * @returns the cloned PositionNormalTextureVertex
   */
  clone() {
    return new _PositionNormalTextureVertex(this.position.clone(), this.normal.clone(), this.uv.clone());
  }
};

// node_modules/@babylonjs/core/Engines/renderTargetWrapper.js
var RenderTargetWrapper = class {
  /**
   * Gets the depth/stencil texture (if created by a createDepthStencilTexture() call)
   */
  get depthStencilTexture() {
    return this._depthStencilTexture;
  }
  /**
   * Indicates if the depth/stencil texture has a stencil aspect
   */
  get depthStencilTextureWithStencil() {
    return this._depthStencilTextureWithStencil;
  }
  /**
   * Defines if the render target wrapper is for a cube texture or if false a 2d texture
   */
  get isCube() {
    return this._isCube;
  }
  /**
   * Defines if the render target wrapper is for a single or multi target render wrapper
   */
  get isMulti() {
    return this._isMulti;
  }
  /**
   * Defines if the render target wrapper is for a single or an array of textures
   */
  get is2DArray() {
    return this.layers > 0;
  }
  /**
   * Gets the size of the render target wrapper (used for cubes, as width=height in this case)
   */
  get size() {
    return this.width;
  }
  /**
   * Gets the width of the render target wrapper
   */
  get width() {
    return this._size.width || this._size;
  }
  /**
   * Gets the height of the render target wrapper
   */
  get height() {
    return this._size.height || this._size;
  }
  /**
   * Gets the number of layers of the render target wrapper (only used if is2DArray is true and wrapper is not a multi render target)
   */
  get layers() {
    return this._size.layers || 0;
  }
  /**
   * Gets the render texture. If this is a multi render target, gets the first texture
   */
  get texture() {
    var _a;
    return ((_a = this._textures) == null ? void 0 : _a[0]) ?? null;
  }
  /**
   * Gets the list of render textures. If we are not in a multi render target, the list will be null (use the texture getter instead)
   */
  get textures() {
    return this._textures;
  }
  /**
   * Gets the face indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
   */
  get faceIndices() {
    return this._faceIndices;
  }
  /**
   * Gets the layer indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
   */
  get layerIndices() {
    return this._layerIndices;
  }
  /**
   * Gets the sample count of the render target
   */
  get samples() {
    return this._samples;
  }
  /**
   * Sets the sample count of the render target
   * @param value sample count
   * @param initializeBuffers If set to true, the engine will make an initializing call to drawBuffers (only used when isMulti=true).
   * @param force true to force calling the update sample count engine function even if the current sample count is equal to value
   * @returns the sample count that has been set
   */
  setSamples(value, initializeBuffers = true, force = false) {
    if (this.samples === value && !force) {
      return value;
    }
    const result = this._isMulti ? this._engine.updateMultipleRenderTargetTextureSampleCount(this, value, initializeBuffers) : this._engine.updateRenderTargetTextureSampleCount(this, value);
    this._samples = value;
    return result;
  }
  /**
   * Initializes the render target wrapper
   * @param isMulti true if the wrapper is a multi render target
   * @param isCube true if the wrapper should render to a cube texture
   * @param size size of the render target (width/height/layers)
   * @param engine engine used to create the render target
   * @param label defines the label to use for the wrapper (for debugging purpose only)
   */
  constructor(isMulti, isCube, size, engine, label) {
    this._textures = null;
    this._faceIndices = null;
    this._layerIndices = null;
    this._samples = 1;
    this._attachments = null;
    this._generateStencilBuffer = false;
    this._generateDepthBuffer = false;
    this._depthStencilTextureWithStencil = false;
    this._isMulti = isMulti;
    this._isCube = isCube;
    this._size = size;
    this._engine = engine;
    this._depthStencilTexture = null;
    this.label = label;
  }
  /**
   * Sets the render target texture(s)
   * @param textures texture(s) to set
   */
  setTextures(textures) {
    if (Array.isArray(textures)) {
      this._textures = textures;
    } else if (textures) {
      this._textures = [textures];
    } else {
      this._textures = null;
    }
  }
  /**
   * Set a texture in the textures array
   * @param texture The texture to set
   * @param index The index in the textures array to set
   * @param disposePrevious If this function should dispose the previous texture
   */
  setTexture(texture, index = 0, disposePrevious = true) {
    if (!this._textures) {
      this._textures = [];
    }
    if (this._textures[index] === texture) {
      return;
    }
    if (this._textures[index] && disposePrevious) {
      this._textures[index].dispose();
    }
    this._textures[index] = texture;
  }
  /**
   * Sets the layer and face indices of every render target texture bound to each color attachment
   * @param layers The layers of each texture to be set
   * @param faces The faces of each texture to be set
   */
  setLayerAndFaceIndices(layers, faces) {
    this._layerIndices = layers;
    this._faceIndices = faces;
  }
  /**
   * Sets the layer and face indices of a texture in the textures array that should be bound to each color attachment
   * @param index The index of the texture in the textures array to modify
   * @param layer The layer of the texture to be set
   * @param face The face of the texture to be set
   */
  setLayerAndFaceIndex(index = 0, layer, face) {
    if (!this._layerIndices) {
      this._layerIndices = [];
    }
    if (!this._faceIndices) {
      this._faceIndices = [];
    }
    if (layer !== void 0 && layer >= 0) {
      this._layerIndices[index] = layer;
    }
    if (face !== void 0 && face >= 0) {
      this._faceIndices[index] = face;
    }
  }
  /**
   * Creates the depth/stencil texture
   * @param comparisonFunction Comparison function to use for the texture
   * @param bilinearFiltering true if bilinear filtering should be used when sampling the texture
   * @param generateStencil true if the stencil aspect should also be created
   * @param samples sample count to use when creating the texture
   * @param format format of the depth texture
   * @param label defines the label to use for the texture (for debugging purpose only)
   * @returns the depth/stencil created texture
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    var _a;
    (_a = this._depthStencilTexture) == null ? void 0 : _a.dispose();
    this._depthStencilTextureWithStencil = generateStencil;
    this._depthStencilTextureLabel = label;
    this._depthStencilTexture = this._engine.createDepthStencilTexture(this._size, {
      bilinearFiltering,
      comparisonFunction,
      generateStencil,
      isCube: this._isCube,
      samples,
      depthTextureFormat: format,
      label
    }, this);
    return this._depthStencilTexture;
  }
  /**
   * Shares the depth buffer of this render target with another render target.
   * @internal
   * @param renderTarget Destination renderTarget
   */
  _shareDepth(renderTarget) {
    if (this._depthStencilTexture) {
      if (renderTarget._depthStencilTexture) {
        renderTarget._depthStencilTexture.dispose();
      }
      renderTarget._depthStencilTexture = this._depthStencilTexture;
      this._depthStencilTexture.incrementReferences();
    }
  }
  /**
   * @internal
   */
  _swapAndDie(target) {
    if (this.texture) {
      this.texture._swapAndDie(target);
    }
    this._textures = null;
    this.dispose(true);
  }
  _cloneRenderTargetWrapper() {
    var _a, _b, _c, _d, _e;
    let rtw = null;
    if (this._isMulti) {
      const textureArray = this.textures;
      if (textureArray && textureArray.length > 0) {
        let generateDepthTexture = false;
        let textureCount = textureArray.length;
        let depthTextureFormat = -1;
        const lastTextureSource = textureArray[textureArray.length - 1]._source;
        if (lastTextureSource === InternalTextureSource.Depth || lastTextureSource === InternalTextureSource.DepthStencil) {
          generateDepthTexture = true;
          depthTextureFormat = textureArray[textureArray.length - 1].format;
          textureCount--;
        }
        const samplingModes = [];
        const types = [];
        const formats = [];
        const targetTypes = [];
        const faceIndex = [];
        const layerIndex = [];
        const layerCounts = [];
        const internalTexture2Index = {};
        for (let i = 0; i < textureCount; ++i) {
          const texture = textureArray[i];
          samplingModes.push(texture.samplingMode);
          types.push(texture.type);
          formats.push(texture.format);
          const index = internalTexture2Index[texture.uniqueId];
          if (index !== void 0) {
            targetTypes.push(-1);
            layerCounts.push(0);
          } else {
            internalTexture2Index[texture.uniqueId] = i;
            if (texture.is2DArray) {
              targetTypes.push(35866);
              layerCounts.push(texture.depth);
            } else if (texture.isCube) {
              targetTypes.push(34067);
              layerCounts.push(0);
            } else if (texture.is3D) {
              targetTypes.push(32879);
              layerCounts.push(texture.depth);
            } else {
              targetTypes.push(3553);
              layerCounts.push(0);
            }
          }
          if (this._faceIndices) {
            faceIndex.push(this._faceIndices[i] ?? 0);
          }
          if (this._layerIndices) {
            layerIndex.push(this._layerIndices[i] ?? 0);
          }
        }
        const optionsMRT = {
          samplingModes,
          generateMipMaps: textureArray[0].generateMipMaps,
          generateDepthBuffer: this._generateDepthBuffer,
          generateStencilBuffer: this._generateStencilBuffer,
          generateDepthTexture,
          depthTextureFormat,
          types,
          formats,
          textureCount,
          targetTypes,
          faceIndex,
          layerIndex,
          layerCounts,
          label: this.label
        };
        const size = {
          width: this.width,
          height: this.height
        };
        rtw = this._engine.createMultipleRenderTarget(size, optionsMRT);
        for (let i = 0; i < textureCount; ++i) {
          if (targetTypes[i] !== -1) {
            continue;
          }
          const index = internalTexture2Index[textureArray[i].uniqueId];
          rtw.setTexture(rtw.textures[index], i);
        }
      }
    } else {
      const options = {};
      options.generateDepthBuffer = this._generateDepthBuffer;
      options.generateMipMaps = ((_a = this.texture) == null ? void 0 : _a.generateMipMaps) ?? false;
      options.generateStencilBuffer = this._generateStencilBuffer;
      options.samplingMode = (_b = this.texture) == null ? void 0 : _b.samplingMode;
      options.type = (_c = this.texture) == null ? void 0 : _c.type;
      options.format = (_d = this.texture) == null ? void 0 : _d.format;
      options.noColorAttachment = !this._textures;
      options.label = this.label;
      if (this.isCube) {
        rtw = this._engine.createRenderTargetCubeTexture(this.width, options);
      } else {
        const size = {
          width: this.width,
          height: this.height,
          layers: this.is2DArray ? (_e = this.texture) == null ? void 0 : _e.depth : void 0
        };
        rtw = this._engine.createRenderTargetTexture(size, options);
      }
      if (rtw.texture) {
        rtw.texture.isReady = true;
      }
    }
    return rtw;
  }
  _swapRenderTargetWrapper(target) {
    if (this._textures && target._textures) {
      for (let i = 0; i < this._textures.length; ++i) {
        this._textures[i]._swapAndDie(target._textures[i], false);
        target._textures[i].isReady = true;
      }
    }
    if (this._depthStencilTexture && target._depthStencilTexture) {
      this._depthStencilTexture._swapAndDie(target._depthStencilTexture);
      target._depthStencilTexture.isReady = true;
    }
    this._textures = null;
    this._depthStencilTexture = null;
  }
  /** @internal */
  _rebuild() {
    const rtw = this._cloneRenderTargetWrapper();
    if (!rtw) {
      return;
    }
    if (this._depthStencilTexture) {
      const samplingMode = this._depthStencilTexture.samplingMode;
      const format = this._depthStencilTexture.format;
      const bilinear = samplingMode === 2 || samplingMode === 3 || samplingMode === 11;
      rtw.createDepthStencilTexture(this._depthStencilTexture._comparisonFunction, bilinear, this._depthStencilTextureWithStencil, this._depthStencilTexture.samples, format, this._depthStencilTextureLabel);
    }
    if (this.samples > 1) {
      rtw.setSamples(this.samples);
    }
    rtw._swapRenderTargetWrapper(this);
    rtw.dispose();
  }
  /**
   * Releases the internal render textures
   */
  releaseTextures() {
    var _a;
    if (this._textures) {
      for (let i = 0; i < ((_a = this._textures) == null ? void 0 : _a.length); ++i) {
        this._textures[i].dispose();
      }
    }
    this._textures = null;
  }
  /**
   * Disposes the whole render target wrapper
   * @param disposeOnlyFramebuffers true if only the frame buffers should be released (used for the WebGL engine). If false, all the textures will also be released
   */
  dispose(disposeOnlyFramebuffers = false) {
    var _a;
    if (!disposeOnlyFramebuffers) {
      (_a = this._depthStencilTexture) == null ? void 0 : _a.dispose();
      this._depthStencilTexture = null;
      this.releaseTextures();
    }
    this._engine._releaseRenderTargetWrapper(this);
  }
};

// node_modules/@babylonjs/core/Shaders/postprocess.vertex.js
var name = "postprocessVertexShader";
var shader = `attribute vec2 position;uniform vec2 scale;varying vec2 vUV;const vec2 madd=vec2(0.5,0.5);
#define CUSTOM_VERTEX_DEFINITIONS
void main(void) {
#define CUSTOM_VERTEX_MAIN_BEGIN
vUV=(position*madd+madd)*scale;gl_Position=vec4(position,0.0,1.0);
#define CUSTOM_VERTEX_MAIN_END
}`;
ShaderStore.ShadersStore[name] = shader;

// node_modules/@babylonjs/core/Engines/WebGL/webGLRenderTargetWrapper.js
var WebGLRenderTargetWrapper = class extends RenderTargetWrapper {
  constructor(isMulti, isCube, size, engine, context) {
    super(isMulti, isCube, size, engine);
    this._framebuffer = null;
    this._depthStencilBuffer = null;
    this._MSAAFramebuffer = null;
    this._colorTextureArray = null;
    this._depthStencilTextureArray = null;
    this._disposeOnlyFramebuffers = false;
    this._currentLOD = 0;
    this._context = context;
  }
  _cloneRenderTargetWrapper() {
    let rtw = null;
    if (this._colorTextureArray && this._depthStencilTextureArray) {
      rtw = this._engine.createMultiviewRenderTargetTexture(this.width, this.height);
      rtw.texture.isReady = true;
    } else {
      rtw = super._cloneRenderTargetWrapper();
    }
    return rtw;
  }
  _swapRenderTargetWrapper(target) {
    super._swapRenderTargetWrapper(target);
    target._framebuffer = this._framebuffer;
    target._depthStencilBuffer = this._depthStencilBuffer;
    target._MSAAFramebuffer = this._MSAAFramebuffer;
    target._colorTextureArray = this._colorTextureArray;
    target._depthStencilTextureArray = this._depthStencilTextureArray;
    this._framebuffer = this._depthStencilBuffer = this._MSAAFramebuffer = this._colorTextureArray = this._depthStencilTextureArray = null;
  }
  /**
   * Creates the depth/stencil texture
   * @param comparisonFunction Comparison function to use for the texture
   * @param bilinearFiltering true if bilinear filtering should be used when sampling the texture
   * @param generateStencil true if the stencil aspect should also be created
   * @param samples sample count to use when creating the texture
   * @param format format of the depth texture
   * @param label defines the label to use for the texture (for debugging purpose only)
   * @returns the depth/stencil created texture
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    if (this._depthStencilBuffer) {
      const currentFrameBuffer = this._engine._currentFramebuffer;
      const gl = this._context;
      this._engine._bindUnboundFramebuffer(this._framebuffer);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_STENCIL_ATTACHMENT, gl.RENDERBUFFER, null);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.RENDERBUFFER, null);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.STENCIL_ATTACHMENT, gl.RENDERBUFFER, null);
      this._engine._bindUnboundFramebuffer(currentFrameBuffer);
      gl.deleteRenderbuffer(this._depthStencilBuffer);
      this._depthStencilBuffer = null;
    }
    return super.createDepthStencilTexture(comparisonFunction, bilinearFiltering, generateStencil, samples, format, label);
  }
  /**
   * Shares the depth buffer of this render target with another render target.
   * @internal
   * @param renderTarget Destination renderTarget
   */
  _shareDepth(renderTarget) {
    super._shareDepth(renderTarget);
    const gl = this._context;
    const depthbuffer = this._depthStencilBuffer;
    const framebuffer = renderTarget._MSAAFramebuffer || renderTarget._framebuffer;
    if (renderTarget._depthStencilBuffer && renderTarget._depthStencilBuffer !== depthbuffer) {
      gl.deleteRenderbuffer(renderTarget._depthStencilBuffer);
    }
    renderTarget._depthStencilBuffer = depthbuffer;
    const attachment = renderTarget._generateStencilBuffer ? gl.DEPTH_STENCIL_ATTACHMENT : gl.DEPTH_ATTACHMENT;
    this._engine._bindUnboundFramebuffer(framebuffer);
    gl.framebufferRenderbuffer(gl.FRAMEBUFFER, attachment, gl.RENDERBUFFER, depthbuffer);
    this._engine._bindUnboundFramebuffer(null);
  }
  /**
   * Binds a texture to this render target on a specific attachment
   * @param texture The texture to bind to the framebuffer
   * @param attachmentIndex Index of the attachment
   * @param faceIndexOrLayer The face or layer of the texture to render to in case of cube texture or array texture
   * @param lodLevel defines the lod level to bind to the frame buffer
   */
  _bindTextureRenderTarget(texture, attachmentIndex = 0, faceIndexOrLayer, lodLevel = 0) {
    var _a, _b;
    if (!texture._hardwareTexture) {
      return;
    }
    const framebuffer = this._framebuffer;
    const currentFB = this._engine._currentFramebuffer;
    this._engine._bindUnboundFramebuffer(framebuffer);
    if (this._engine.webGLVersion > 1) {
      const gl = this._context;
      const attachment = gl["COLOR_ATTACHMENT" + attachmentIndex];
      if (texture.is2DArray || texture.is3D) {
        faceIndexOrLayer = faceIndexOrLayer ?? ((_a = this.layerIndices) == null ? void 0 : _a[attachmentIndex]) ?? 0;
        gl.framebufferTextureLayer(gl.FRAMEBUFFER, attachment, texture._hardwareTexture.underlyingResource, lodLevel, faceIndexOrLayer);
      } else if (texture.isCube) {
        faceIndexOrLayer = faceIndexOrLayer ?? ((_b = this.faceIndices) == null ? void 0 : _b[attachmentIndex]) ?? 0;
        gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndexOrLayer, texture._hardwareTexture.underlyingResource, lodLevel);
      } else {
        gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, gl.TEXTURE_2D, texture._hardwareTexture.underlyingResource, lodLevel);
      }
    } else {
      const gl = this._context;
      const attachment = gl["COLOR_ATTACHMENT" + attachmentIndex + "_WEBGL"];
      const target = faceIndexOrLayer !== void 0 ? gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndexOrLayer : gl.TEXTURE_2D;
      gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, target, texture._hardwareTexture.underlyingResource, lodLevel);
    }
    this._engine._bindUnboundFramebuffer(currentFB);
  }
  /**
   * Set a texture in the textures array
   * @param texture the texture to set
   * @param index the index in the textures array to set
   * @param disposePrevious If this function should dispose the previous texture
   */
  setTexture(texture, index = 0, disposePrevious = true) {
    super.setTexture(texture, index, disposePrevious);
    this._bindTextureRenderTarget(texture, index);
  }
  /**
   * Sets the layer and face indices of every render target texture
   * @param layers The layer of the texture to be set (make negative to not modify)
   * @param faces The face of the texture to be set (make negative to not modify)
   */
  setLayerAndFaceIndices(layers, faces) {
    var _a;
    super.setLayerAndFaceIndices(layers, faces);
    if (!this.textures || !this.layerIndices || !this.faceIndices) {
      return;
    }
    const textureCount = ((_a = this._attachments) == null ? void 0 : _a.length) ?? this.textures.length;
    for (let index = 0; index < textureCount; index++) {
      const texture = this.textures[index];
      if (!texture) {
        continue;
      }
      if (texture.is2DArray || texture.is3D) {
        this._bindTextureRenderTarget(texture, index, this.layerIndices[index]);
      } else if (texture.isCube) {
        this._bindTextureRenderTarget(texture, index, this.faceIndices[index]);
      } else {
        this._bindTextureRenderTarget(texture, index);
      }
    }
  }
  /**
   * Set the face and layer indices of a texture in the textures array
   * @param index The index of the texture in the textures array to modify
   * @param layer The layer of the texture to be set
   * @param face The face of the texture to be set
   */
  setLayerAndFaceIndex(index = 0, layer, face) {
    super.setLayerAndFaceIndex(index, layer, face);
    if (!this.textures || !this.layerIndices || !this.faceIndices) {
      return;
    }
    const texture = this.textures[index];
    if (texture.is2DArray || texture.is3D) {
      this._bindTextureRenderTarget(this.textures[index], index, this.layerIndices[index]);
    } else if (texture.isCube) {
      this._bindTextureRenderTarget(this.textures[index], index, this.faceIndices[index]);
    }
  }
  dispose(disposeOnlyFramebuffers = this._disposeOnlyFramebuffers) {
    const gl = this._context;
    if (!disposeOnlyFramebuffers) {
      if (this._colorTextureArray) {
        this._context.deleteTexture(this._colorTextureArray);
        this._colorTextureArray = null;
      }
      if (this._depthStencilTextureArray) {
        this._context.deleteTexture(this._depthStencilTextureArray);
        this._depthStencilTextureArray = null;
      }
    }
    if (this._framebuffer) {
      gl.deleteFramebuffer(this._framebuffer);
      this._framebuffer = null;
    }
    if (this._depthStencilBuffer) {
      gl.deleteRenderbuffer(this._depthStencilBuffer);
      this._depthStencilBuffer = null;
    }
    if (this._MSAAFramebuffer) {
      gl.deleteFramebuffer(this._MSAAFramebuffer);
      this._MSAAFramebuffer = null;
    }
    super.dispose(disposeOnlyFramebuffers);
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.renderTarget.js
ThinEngine.prototype._createHardwareRenderTargetWrapper = function(isMulti, isCube, size) {
  const rtWrapper = new WebGLRenderTargetWrapper(isMulti, isCube, size, this, this._gl);
  this._renderTargetWrapperCache.push(rtWrapper);
  return rtWrapper;
};
ThinEngine.prototype.createRenderTargetTexture = function(size, options) {
  const rtWrapper = this._createHardwareRenderTargetWrapper(false, false, size);
  let generateDepthBuffer = true;
  let generateStencilBuffer = false;
  let noColorAttachment = false;
  let colorAttachment = void 0;
  let samples = 1;
  let label = void 0;
  if (options !== void 0 && typeof options === "object") {
    generateDepthBuffer = options.generateDepthBuffer ?? true;
    generateStencilBuffer = !!options.generateStencilBuffer;
    noColorAttachment = !!options.noColorAttachment;
    colorAttachment = options.colorAttachment;
    samples = options.samples ?? 1;
    label = options.label;
  }
  const texture = colorAttachment || (noColorAttachment ? null : this._createInternalTexture(size, options, true, InternalTextureSource.RenderTarget));
  const width = size.width || size;
  const height = size.height || size;
  const currentFrameBuffer = this._currentFramebuffer;
  const gl = this._gl;
  const framebuffer = gl.createFramebuffer();
  this._bindUnboundFramebuffer(framebuffer);
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(generateStencilBuffer, generateDepthBuffer, width, height);
  if (texture && !texture.is2DArray) {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture._hardwareTexture.underlyingResource, 0);
  }
  this._bindUnboundFramebuffer(currentFrameBuffer);
  rtWrapper.label = label ?? "RenderTargetWrapper";
  rtWrapper._framebuffer = framebuffer;
  rtWrapper._generateDepthBuffer = generateDepthBuffer;
  rtWrapper._generateStencilBuffer = generateStencilBuffer;
  rtWrapper.setTextures(texture);
  this.updateRenderTargetTextureSampleCount(rtWrapper, samples);
  return rtWrapper;
};
ThinEngine.prototype.createDepthStencilTexture = function(size, options, rtWrapper) {
  if (options.isCube) {
    const width = size.width || size;
    return this._createDepthStencilCubeTexture(width, options);
  } else {
    return this._createDepthStencilTexture(size, options, rtWrapper);
  }
};
ThinEngine.prototype._createDepthStencilTexture = function(size, options) {
  const gl = this._gl;
  const layers = size.layers || 0;
  const target = layers !== 0 ? gl.TEXTURE_2D_ARRAY : gl.TEXTURE_2D;
  const internalTexture = new InternalTexture(this, InternalTextureSource.DepthStencil);
  internalTexture.label = options.label;
  if (!this._caps.depthTextureExtension) {
    Logger.Error("Depth texture is not supported by your browser or hardware.");
    return internalTexture;
  }
  const internalOptions = {
    bilinearFiltering: false,
    comparisonFunction: 0,
    generateStencil: false,
    ...options
  };
  this._bindTextureDirectly(target, internalTexture, true);
  this._setupDepthStencilTexture(internalTexture, size, internalOptions.generateStencil, internalOptions.comparisonFunction === 0 ? false : internalOptions.bilinearFiltering, internalOptions.comparisonFunction, internalOptions.samples);
  if (internalOptions.depthTextureFormat !== void 0) {
    if (internalOptions.depthTextureFormat !== 15 && internalOptions.depthTextureFormat !== 16 && internalOptions.depthTextureFormat !== 17 && internalOptions.depthTextureFormat !== 13 && internalOptions.depthTextureFormat !== 14 && internalOptions.depthTextureFormat !== 18) {
      Logger.Error("Depth texture format is not supported.");
      return internalTexture;
    }
    internalTexture.format = internalOptions.depthTextureFormat;
  } else {
    internalTexture.format = internalOptions.generateStencil ? 13 : 16;
  }
  const hasStencil = internalTexture.format === 17 || internalTexture.format === 13 || internalTexture.format === 18;
  let type = gl.UNSIGNED_INT;
  if (internalTexture.format === 15) {
    type = gl.UNSIGNED_SHORT;
  } else if (internalTexture.format === 17 || internalTexture.format === 13) {
    type = gl.UNSIGNED_INT_24_8;
  } else if (internalTexture.format === 14) {
    type = gl.FLOAT;
  } else if (internalTexture.format === 18) {
    type = gl.FLOAT_32_UNSIGNED_INT_24_8_REV;
  }
  const format = hasStencil ? gl.DEPTH_STENCIL : gl.DEPTH_COMPONENT;
  let internalFormat = format;
  if (this.webGLVersion > 1) {
    if (internalTexture.format === 15) {
      internalFormat = gl.DEPTH_COMPONENT16;
    } else if (internalTexture.format === 16) {
      internalFormat = gl.DEPTH_COMPONENT24;
    } else if (internalTexture.format === 17 || internalTexture.format === 13) {
      internalFormat = gl.DEPTH24_STENCIL8;
    } else if (internalTexture.format === 14) {
      internalFormat = gl.DEPTH_COMPONENT32F;
    } else if (internalTexture.format === 18) {
      internalFormat = gl.DEPTH32F_STENCIL8;
    }
  }
  if (internalTexture.is2DArray) {
    gl.texImage3D(target, 0, internalFormat, internalTexture.width, internalTexture.height, layers, 0, format, type, null);
  } else {
    gl.texImage2D(target, 0, internalFormat, internalTexture.width, internalTexture.height, 0, format, type, null);
  }
  this._bindTextureDirectly(target, null);
  this._internalTexturesCache.push(internalTexture);
  return internalTexture;
};
ThinEngine.prototype.updateRenderTargetTextureSampleCount = function(rtWrapper, samples) {
  if (this.webGLVersion < 2 || !rtWrapper || !rtWrapper.texture) {
    return 1;
  }
  if (rtWrapper.samples === samples) {
    return samples;
  }
  const gl = this._gl;
  samples = Math.min(samples, this.getCaps().maxMSAASamples);
  if (rtWrapper._depthStencilBuffer) {
    gl.deleteRenderbuffer(rtWrapper._depthStencilBuffer);
    rtWrapper._depthStencilBuffer = null;
  }
  if (rtWrapper._MSAAFramebuffer) {
    gl.deleteFramebuffer(rtWrapper._MSAAFramebuffer);
    rtWrapper._MSAAFramebuffer = null;
  }
  const hardwareTexture = rtWrapper.texture._hardwareTexture;
  hardwareTexture.releaseMSAARenderBuffers();
  if (samples > 1 && typeof gl.renderbufferStorageMultisample === "function") {
    const framebuffer = gl.createFramebuffer();
    if (!framebuffer) {
      throw new Error("Unable to create multi sampled framebuffer");
    }
    rtWrapper._MSAAFramebuffer = framebuffer;
    this._bindUnboundFramebuffer(rtWrapper._MSAAFramebuffer);
    const colorRenderbuffer = this._createRenderBuffer(rtWrapper.texture.width, rtWrapper.texture.height, samples, -1, this._getRGBABufferInternalSizedFormat(rtWrapper.texture.type, rtWrapper.texture.format, rtWrapper.texture._useSRGBBuffer), gl.COLOR_ATTACHMENT0, false);
    if (!colorRenderbuffer) {
      throw new Error("Unable to create multi sampled framebuffer");
    }
    hardwareTexture.addMSAARenderBuffer(colorRenderbuffer);
  } else {
    this._bindUnboundFramebuffer(rtWrapper._framebuffer);
  }
  rtWrapper.texture.samples = samples;
  rtWrapper._samples = samples;
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(rtWrapper._generateStencilBuffer, rtWrapper._generateDepthBuffer, rtWrapper.texture.width, rtWrapper.texture.height, samples);
  this._bindUnboundFramebuffer(null);
  return samples;
};

// node_modules/@babylonjs/core/PostProcesses/postProcess.js
var PostProcess = class _PostProcess {
  /**
   * Registers a shader code processing with a post process name.
   * @param postProcessName name of the post process. Use null for the fallback shader code processing. This is the shader code processing that will be used in case no specific shader code processing has been associated to a post process name
   * @param customShaderCodeProcessing shader code processing to associate to the post process name
   */
  static RegisterShaderCodeProcessing(postProcessName, customShaderCodeProcessing) {
    if (!customShaderCodeProcessing) {
      delete _PostProcess._CustomShaderCodeProcessing[postProcessName ?? ""];
      return;
    }
    _PostProcess._CustomShaderCodeProcessing[postProcessName ?? ""] = customShaderCodeProcessing;
  }
  static _GetShaderCodeProcessing(postProcessName) {
    return _PostProcess._CustomShaderCodeProcessing[postProcessName] ?? _PostProcess._CustomShaderCodeProcessing[""];
  }
  /**
   * Number of sample textures (default: 1)
   */
  get samples() {
    return this._samples;
  }
  set samples(n) {
    this._samples = Math.min(n, this._engine.getCaps().maxMSAASamples);
    this._textures.forEach((texture) => {
      texture.setSamples(this._samples);
    });
  }
  /**
   * Returns the fragment url or shader name used in the post process.
   * @returns the fragment url or name in the shader store.
   */
  getEffectName() {
    return this._fragmentUrl;
  }
  /**
   * A function that is added to the onActivateObservable
   */
  set onActivate(callback) {
    if (this._onActivateObserver) {
      this.onActivateObservable.remove(this._onActivateObserver);
    }
    if (callback) {
      this._onActivateObserver = this.onActivateObservable.add(callback);
    }
  }
  /**
   * A function that is added to the onSizeChangedObservable
   */
  set onSizeChanged(callback) {
    if (this._onSizeChangedObserver) {
      this.onSizeChangedObservable.remove(this._onSizeChangedObserver);
    }
    this._onSizeChangedObserver = this.onSizeChangedObservable.add(callback);
  }
  /**
   * A function that is added to the onApplyObservable
   */
  set onApply(callback) {
    if (this._onApplyObserver) {
      this.onApplyObservable.remove(this._onApplyObserver);
    }
    this._onApplyObserver = this.onApplyObservable.add(callback);
  }
  /**
   * A function that is added to the onBeforeRenderObservable
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * A function that is added to the onAfterRenderObservable
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * The input texture for this post process and the output texture of the previous post process. When added to a pipeline the previous post process will
   * render it's output into this texture and this texture will be used as textureSampler in the fragment shader of this post process.
   */
  get inputTexture() {
    return this._textures.data[this._currentRenderTextureInd];
  }
  set inputTexture(value) {
    this._forcedOutputTexture = value;
  }
  /**
   * Since inputTexture should always be defined, if we previously manually set `inputTexture`,
   * the only way to unset it is to use this function to restore its internal state
   */
  restoreDefaultInputTexture() {
    if (this._forcedOutputTexture) {
      this._forcedOutputTexture = null;
      this.markTextureDirty();
    }
  }
  /**
   * Gets the camera which post process is applied to.
   * @returns The camera the post process is applied to.
   */
  getCamera() {
    return this._camera;
  }
  /**
   * Gets the texel size of the postprocess.
   * See https://en.wikipedia.org/wiki/Texel_(graphics)
   */
  get texelSize() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.texelSize;
    }
    if (this._forcedOutputTexture) {
      this._texelSize.copyFromFloats(1 / this._forcedOutputTexture.width, 1 / this._forcedOutputTexture.height);
    }
    return this._texelSize;
  }
  /** @internal */
  constructor(name6, fragmentUrl, parameters, samplers, _size, camera, samplingMode = 1, engine, reusable, defines = null, textureType = 0, vertexUrl = "postprocess", indexParameters, blockCompilation = false, textureFormat = 5, shaderLanguage = ShaderLanguage.GLSL) {
    this._parentContainer = null;
    this.width = -1;
    this.height = -1;
    this.nodeMaterialSource = null;
    this._outputTexture = null;
    this.autoClear = true;
    this.forceAutoClearInAlphaMode = false;
    this.alphaMode = 0;
    this.animations = [];
    this.enablePixelPerfectMode = false;
    this.forceFullscreenViewport = true;
    this.scaleMode = 1;
    this.alwaysForcePOT = false;
    this._samples = 1;
    this.adaptScaleToCurrentViewport = false;
    this._reusable = false;
    this._renderId = 0;
    this.externalTextureSamplerBinding = false;
    this._textures = new SmartArray(2);
    this._textureCache = [];
    this._currentRenderTextureInd = 0;
    this._scaleRatio = new Vector2(1, 1);
    this._texelSize = Vector2.Zero();
    this.onActivateObservable = new Observable();
    this.onSizeChangedObservable = new Observable();
    this.onApplyObservable = new Observable();
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this.name = name6;
    let size = 1;
    let uniformBuffers = null;
    if (parameters && !Array.isArray(parameters)) {
      const options = parameters;
      parameters = options.uniforms ?? null;
      samplers = options.samplers ?? null;
      size = options.size ?? 1;
      camera = options.camera ?? null;
      samplingMode = options.samplingMode ?? 1;
      engine = options.engine;
      reusable = options.reusable;
      defines = options.defines ?? null;
      textureType = options.textureType ?? 0;
      vertexUrl = options.vertexUrl ?? "postprocess";
      indexParameters = options.indexParameters;
      blockCompilation = options.blockCompilation ?? false;
      textureFormat = options.textureFormat ?? 5;
      shaderLanguage = options.shaderLanguage ?? ShaderLanguage.GLSL;
      uniformBuffers = options.uniformBuffers ?? null;
    } else if (_size) {
      if (typeof _size === "number") {
        size = _size;
      } else {
        size = { width: _size.width, height: _size.height };
      }
    }
    if (camera != null) {
      this._camera = camera;
      this._scene = camera.getScene();
      camera.attachPostProcess(this);
      this._engine = this._scene.getEngine();
      this._scene.postProcesses.push(this);
      this.uniqueId = this._scene.getUniqueId();
    } else if (engine) {
      this._engine = engine;
      this._engine.postProcesses.push(this);
    }
    this._options = size;
    this.renderTargetSamplingMode = samplingMode ? samplingMode : 1;
    this._reusable = reusable || false;
    this._textureType = textureType;
    this._textureFormat = textureFormat;
    this._shaderLanguage = shaderLanguage;
    this._samplers = samplers || [];
    this._samplers.push("textureSampler");
    this._fragmentUrl = fragmentUrl;
    this._vertexUrl = vertexUrl;
    this._parameters = parameters || [];
    this._parameters.push("scale");
    this._uniformBuffers = uniformBuffers || [];
    this._indexParameters = indexParameters;
    this._drawWrapper = new DrawWrapper(this._engine);
    if (!blockCompilation) {
      this.updateEffect(defines);
    }
  }
  /**
   * Gets a string identifying the name of the class
   * @returns "PostProcess" string
   */
  getClassName() {
    return "PostProcess";
  }
  /**
   * Gets the engine which this post process belongs to.
   * @returns The engine the post process was enabled with.
   */
  getEngine() {
    return this._engine;
  }
  /**
   * The effect that is created when initializing the post process.
   * @returns The created effect corresponding the postprocess.
   */
  getEffect() {
    return this._drawWrapper.effect;
  }
  /**
   * To avoid multiple redundant textures for multiple post process, the output the output texture for this post process can be shared with another.
   * @param postProcess The post process to share the output with.
   * @returns This post process.
   */
  shareOutputWith(postProcess) {
    this._disposeTextures();
    this._shareOutputWithPostProcess = postProcess;
    return this;
  }
  /**
   * Reverses the effect of calling shareOutputWith and returns the post process back to its original state.
   * This should be called if the post process that shares output with this post process is disabled/disposed.
   */
  useOwnOutput() {
    if (this._textures.length == 0) {
      this._textures = new SmartArray(2);
    }
    this._shareOutputWithPostProcess = null;
  }
  /**
   * Updates the effect with the current post process compile time values and recompiles the shader.
   * @param defines Define statements that should be added at the beginning of the shader. (default: null)
   * @param uniforms Set of uniform variables that will be passed to the shader. (default: null)
   * @param samplers Set of Texture2D variables that will be passed to the shader. (default: null)
   * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
   * @param onCompiled Called when the shader has been compiled.
   * @param onError Called if there is an error when compiling a shader.
   * @param vertexUrl The url of the vertex shader to be used (default: the one given at construction time)
   * @param fragmentUrl The url of the fragment shader to be used (default: the one given at construction time)
   */
  updateEffect(defines = null, uniforms = null, samplers = null, indexParameters, onCompiled, onError, vertexUrl, fragmentUrl) {
    const customShaderCodeProcessing = _PostProcess._GetShaderCodeProcessing(this.name);
    if (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.defineCustomBindings) {
      const newUniforms = (uniforms == null ? void 0 : uniforms.slice()) ?? [];
      newUniforms.push(...this._parameters);
      const newSamplers = (samplers == null ? void 0 : samplers.slice()) ?? [];
      newSamplers.push(...this._samplers);
      defines = customShaderCodeProcessing.defineCustomBindings(this.name, defines, newUniforms, newSamplers);
      uniforms = newUniforms;
      samplers = newSamplers;
    }
    this._postProcessDefines = defines;
    this._drawWrapper.effect = this._engine.createEffect({ vertex: vertexUrl ?? this._vertexUrl, fragment: fragmentUrl ?? this._fragmentUrl }, {
      attributes: ["position"],
      uniformsNames: uniforms || this._parameters,
      uniformBuffersNames: this._uniformBuffers,
      samplers: samplers || this._samplers,
      defines: defines !== null ? defines : "",
      fallbacks: null,
      onCompiled: onCompiled ?? null,
      onError: onError ?? null,
      indexParameters: indexParameters || this._indexParameters,
      processCodeAfterIncludes: (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.processCodeAfterIncludes) ? (shaderType, code) => customShaderCodeProcessing.processCodeAfterIncludes(this.name, shaderType, code) : null,
      processFinalCode: (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.processFinalCode) ? (shaderType, code) => customShaderCodeProcessing.processFinalCode(this.name, shaderType, code) : null,
      shaderLanguage: this._shaderLanguage
    }, this._engine);
  }
  /**
   * The post process is reusable if it can be used multiple times within one frame.
   * @returns If the post process is reusable
   */
  isReusable() {
    return this._reusable;
  }
  /** invalidate frameBuffer to hint the postprocess to create a depth buffer */
  markTextureDirty() {
    this.width = -1;
  }
  _createRenderTargetTexture(textureSize, textureOptions, channel = 0) {
    for (let i = 0; i < this._textureCache.length; i++) {
      if (this._textureCache[i].texture.width === textureSize.width && this._textureCache[i].texture.height === textureSize.height && this._textureCache[i].postProcessChannel === channel && this._textureCache[i].texture._generateDepthBuffer === textureOptions.generateDepthBuffer && this._textureCache[i].texture.samples === textureOptions.samples) {
        return this._textureCache[i].texture;
      }
    }
    const tex = this._engine.createRenderTargetTexture(textureSize, textureOptions);
    this._textureCache.push({ texture: tex, postProcessChannel: channel, lastUsedRenderId: -1 });
    return tex;
  }
  _flushTextureCache() {
    const currentRenderId = this._renderId;
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      if (currentRenderId - this._textureCache[i].lastUsedRenderId > 100) {
        let currentlyUsed = false;
        for (let j = 0; j < this._textures.length; j++) {
          if (this._textures.data[j] === this._textureCache[i].texture) {
            currentlyUsed = true;
            break;
          }
        }
        if (!currentlyUsed) {
          this._textureCache[i].texture.dispose();
          this._textureCache.splice(i, 1);
        }
      }
    }
  }
  /**
   * Resizes the post-process texture
   * @param width Width of the texture
   * @param height Height of the texture
   * @param camera The camera this post-process is applied to. Pass null if the post-process is used outside the context of a camera post-process chain (default: null)
   * @param needMipMaps True if mip maps need to be generated after render (default: false)
   * @param forceDepthStencil True to force post-process texture creation with stencil depth and buffer (default: false)
   */
  resize(width, height, camera = null, needMipMaps = false, forceDepthStencil = false) {
    if (this._textures.length > 0) {
      this._textures.reset();
    }
    this.width = width;
    this.height = height;
    let firstPP = null;
    if (camera) {
      for (let i = 0; i < camera._postProcesses.length; i++) {
        if (camera._postProcesses[i] !== null) {
          firstPP = camera._postProcesses[i];
          break;
        }
      }
    }
    const textureSize = { width: this.width, height: this.height };
    const textureOptions = {
      generateMipMaps: needMipMaps,
      generateDepthBuffer: forceDepthStencil || firstPP === this,
      generateStencilBuffer: (forceDepthStencil || firstPP === this) && this._engine.isStencilEnable,
      samplingMode: this.renderTargetSamplingMode,
      type: this._textureType,
      format: this._textureFormat,
      samples: this._samples,
      label: "PostProcessRTT-" + this.name
    };
    this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 0));
    if (this._reusable) {
      this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 1));
    }
    this._texelSize.copyFromFloats(1 / this.width, 1 / this.height);
    this.onSizeChangedObservable.notifyObservers(this);
  }
  _getTarget() {
    let target;
    if (this._shareOutputWithPostProcess) {
      target = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      target = this._forcedOutputTexture;
      this.width = this._forcedOutputTexture.width;
      this.height = this._forcedOutputTexture.height;
    } else {
      target = this.inputTexture;
      let cache;
      for (let i = 0; i < this._textureCache.length; i++) {
        if (this._textureCache[i].texture === target) {
          cache = this._textureCache[i];
          break;
        }
      }
      if (cache) {
        cache.lastUsedRenderId = this._renderId;
      }
    }
    return target;
  }
  /**
   * Activates the post process by intializing the textures to be used when executed. Notifies onActivateObservable.
   * When this post process is used in a pipeline, this is call will bind the input texture of this post process to the output of the previous.
   * @param camera The camera that will be used in the post process. This camera will be used when calling onActivateObservable.
   * @param sourceTexture The source texture to be inspected to get the width and height if not specified in the post process constructor. (default: null)
   * @param forceDepthStencil If true, a depth and stencil buffer will be generated. (default: false)
   * @returns The render target wrapper that was bound to be written to.
   */
  activate(camera, sourceTexture = null, forceDepthStencil) {
    var _a, _b;
    camera = camera || this._camera;
    const scene = camera.getScene();
    const engine = scene.getEngine();
    const maxSize = engine.getCaps().maxTextureSize;
    const requiredWidth = (sourceTexture ? sourceTexture.width : this._engine.getRenderWidth(true)) * this._options | 0;
    const requiredHeight = (sourceTexture ? sourceTexture.height : this._engine.getRenderHeight(true)) * this._options | 0;
    let desiredWidth = this._options.width || requiredWidth;
    let desiredHeight = this._options.height || requiredHeight;
    const needMipMaps = this.renderTargetSamplingMode !== 7 && this.renderTargetSamplingMode !== 1 && this.renderTargetSamplingMode !== 2;
    let target = null;
    if (!this._shareOutputWithPostProcess && !this._forcedOutputTexture) {
      if (this.adaptScaleToCurrentViewport) {
        const currentViewport = engine.currentViewport;
        if (currentViewport) {
          desiredWidth *= currentViewport.width;
          desiredHeight *= currentViewport.height;
        }
      }
      if (needMipMaps || this.alwaysForcePOT) {
        if (!this._options.width) {
          desiredWidth = engine.needPOTTextures ? Engine.GetExponentOfTwo(desiredWidth, maxSize, this.scaleMode) : desiredWidth;
        }
        if (!this._options.height) {
          desiredHeight = engine.needPOTTextures ? Engine.GetExponentOfTwo(desiredHeight, maxSize, this.scaleMode) : desiredHeight;
        }
      }
      if (this.width !== desiredWidth || this.height !== desiredHeight || !(target = this._getTarget())) {
        this.resize(desiredWidth, desiredHeight, camera, needMipMaps, forceDepthStencil);
      }
      this._textures.forEach((texture) => {
        if (texture.samples !== this.samples) {
          this._engine.updateRenderTargetTextureSampleCount(texture, this.samples);
        }
      });
      this._flushTextureCache();
      this._renderId++;
    }
    if (!target) {
      target = this._getTarget();
    }
    if (this.enablePixelPerfectMode) {
      this._scaleRatio.copyFromFloats(requiredWidth / desiredWidth, requiredHeight / desiredHeight);
      this._engine.bindFramebuffer(target, 0, requiredWidth, requiredHeight, this.forceFullscreenViewport);
    } else {
      this._scaleRatio.copyFromFloats(1, 1);
      this._engine.bindFramebuffer(target, 0, void 0, void 0, this.forceFullscreenViewport);
    }
    (_b = (_a = this._engine)._debugInsertMarker) == null ? void 0 : _b.call(_a, `post process ${this.name} input`);
    this.onActivateObservable.notifyObservers(camera);
    if (this.autoClear && (this.alphaMode === 0 || this.forceAutoClearInAlphaMode)) {
      this._engine.clear(this.clearColor ? this.clearColor : scene.clearColor, scene._allowPostProcessClearColor, true, true);
    }
    if (this._reusable) {
      this._currentRenderTextureInd = (this._currentRenderTextureInd + 1) % 2;
    }
    return target;
  }
  /**
   * If the post process is supported.
   */
  get isSupported() {
    return this._drawWrapper.effect.isSupported;
  }
  /**
   * The aspect ratio of the output texture.
   */
  get aspectRatio() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.aspectRatio;
    }
    if (this._forcedOutputTexture) {
      return this._forcedOutputTexture.width / this._forcedOutputTexture.height;
    }
    return this.width / this.height;
  }
  /**
   * Get a value indicating if the post-process is ready to be used
   * @returns true if the post-process is ready (shader is compiled)
   */
  isReady() {
    var _a;
    return ((_a = this._drawWrapper.effect) == null ? void 0 : _a.isReady()) ?? false;
  }
  /**
   * Binds all textures and uniforms to the shader, this will be run on every pass.
   * @returns the effect corresponding to this post process. Null if not compiled or not ready.
   */
  apply() {
    var _a, _b, _c;
    if (!((_a = this._drawWrapper.effect) == null ? void 0 : _a.isReady())) {
      return null;
    }
    this._engine.enableEffect(this._drawWrapper);
    this._engine.setState(false);
    this._engine.setDepthBuffer(false);
    this._engine.setDepthWrite(false);
    this._engine.setAlphaMode(this.alphaMode);
    if (this.alphaConstants) {
      this.getEngine().setAlphaConstants(this.alphaConstants.r, this.alphaConstants.g, this.alphaConstants.b, this.alphaConstants.a);
    }
    let source;
    if (this._shareOutputWithPostProcess) {
      source = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      source = this._forcedOutputTexture;
    } else {
      source = this.inputTexture;
    }
    if (!this.externalTextureSamplerBinding) {
      this._drawWrapper.effect._bindTexture("textureSampler", source == null ? void 0 : source.texture);
    }
    this._drawWrapper.effect.setVector2("scale", this._scaleRatio);
    this.onApplyObservable.notifyObservers(this._drawWrapper.effect);
    (_c = (_b = _PostProcess._GetShaderCodeProcessing(this.name)) == null ? void 0 : _b.bindCustomBindings) == null ? void 0 : _c.call(_b, this.name, this._drawWrapper.effect);
    return this._drawWrapper.effect;
  }
  _disposeTextures() {
    if (this._shareOutputWithPostProcess || this._forcedOutputTexture) {
      this._disposeTextureCache();
      return;
    }
    this._disposeTextureCache();
    this._textures.dispose();
  }
  _disposeTextureCache() {
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      this._textureCache[i].texture.dispose();
    }
    this._textureCache.length = 0;
  }
  /**
   * Sets the required values to the prepass renderer.
   * @param prePassRenderer defines the prepass renderer to setup.
   * @returns true if the pre pass is needed.
   */
  setPrePassRenderer(prePassRenderer) {
    if (this._prePassEffectConfiguration) {
      this._prePassEffectConfiguration = prePassRenderer.addEffectConfiguration(this._prePassEffectConfiguration);
      this._prePassEffectConfiguration.enabled = true;
      return true;
    }
    return false;
  }
  /**
   * Disposes the post process.
   * @param camera The camera to dispose the post process on.
   */
  dispose(camera) {
    camera = camera || this._camera;
    this._disposeTextures();
    let index;
    if (this._scene) {
      index = this._scene.postProcesses.indexOf(this);
      if (index !== -1) {
        this._scene.postProcesses.splice(index, 1);
      }
    }
    if (this._parentContainer) {
      const index2 = this._parentContainer.postProcesses.indexOf(this);
      if (index2 > -1) {
        this._parentContainer.postProcesses.splice(index2, 1);
      }
      this._parentContainer = null;
    }
    index = this._engine.postProcesses.indexOf(this);
    if (index !== -1) {
      this._engine.postProcesses.splice(index, 1);
    }
    if (!camera) {
      return;
    }
    camera.detachPostProcess(this);
    index = camera._postProcesses.indexOf(this);
    if (index === 0 && camera._postProcesses.length > 0) {
      const firstPostProcess = this._camera._getFirstPostProcess();
      if (firstPostProcess) {
        firstPostProcess.markTextureDirty();
      }
    }
    this.onActivateObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onApplyObservable.clear();
    this.onBeforeRenderObservable.clear();
    this.onSizeChangedObservable.clear();
  }
  /**
   * Serializes the post process to a JSON object
   * @returns the JSON object
   */
  serialize() {
    const serializationObject = SerializationHelper.Serialize(this);
    const camera = this.getCamera() || this._scene && this._scene.activeCamera;
    serializationObject.customType = "BABYLON." + this.getClassName();
    serializationObject.cameraId = camera ? camera.id : null;
    serializationObject.reusable = this._reusable;
    serializationObject.textureType = this._textureType;
    serializationObject.fragmentUrl = this._fragmentUrl;
    serializationObject.parameters = this._parameters;
    serializationObject.samplers = this._samplers;
    serializationObject.options = this._options;
    serializationObject.defines = this._postProcessDefines;
    serializationObject.textureFormat = this._textureFormat;
    serializationObject.vertexUrl = this._vertexUrl;
    serializationObject.indexParameters = this._indexParameters;
    return serializationObject;
  }
  /**
   * Clones this post process
   * @returns a new post process similar to this one
   */
  clone() {
    const serializationObject = this.serialize();
    serializationObject._engine = this._engine;
    serializationObject.cameraId = null;
    const result = _PostProcess.Parse(serializationObject, this._scene, "");
    if (!result) {
      return null;
    }
    result.onActivateObservable = this.onActivateObservable.clone();
    result.onSizeChangedObservable = this.onSizeChangedObservable.clone();
    result.onApplyObservable = this.onApplyObservable.clone();
    result.onBeforeRenderObservable = this.onBeforeRenderObservable.clone();
    result.onAfterRenderObservable = this.onAfterRenderObservable.clone();
    result._prePassEffectConfiguration = this._prePassEffectConfiguration;
    return result;
  }
  /**
   * Creates a material from parsed material data
   * @param parsedPostProcess defines parsed post process data
   * @param scene defines the hosting scene
   * @param rootUrl defines the root URL to use to load textures
   * @returns a new post process
   */
  static Parse(parsedPostProcess, scene, rootUrl) {
    const postProcessType = GetClass(parsedPostProcess.customType);
    if (!postProcessType || !postProcessType._Parse) {
      return null;
    }
    const camera = scene ? scene.getCameraById(parsedPostProcess.cameraId) : null;
    return postProcessType._Parse(parsedPostProcess, camera, scene, rootUrl);
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PostProcess(parsedPostProcess.name, parsedPostProcess.fragmentUrl, parsedPostProcess.parameters, parsedPostProcess.samplers, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable, parsedPostProcess.defines, parsedPostProcess.textureType, parsedPostProcess.vertexUrl, parsedPostProcess.indexParameters, false, parsedPostProcess.textureFormat);
    }, parsedPostProcess, scene, rootUrl);
  }
};
PostProcess._CustomShaderCodeProcessing = {};
__decorate([
  serialize()
], PostProcess.prototype, "uniqueId", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "name", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "width", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "height", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "renderTargetSamplingMode", void 0);
__decorate([
  serializeAsColor4()
], PostProcess.prototype, "clearColor", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "autoClear", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceAutoClearInAlphaMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alphaMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alphaConstants", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "enablePixelPerfectMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceFullscreenViewport", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "scaleMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alwaysForcePOT", void 0);
__decorate([
  serialize("samples")
], PostProcess.prototype, "_samples", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "adaptScaleToCurrentViewport", void 0);
RegisterClass("BABYLON.PostProcess", PostProcess);

// node_modules/@babylonjs/core/Materials/effectRenderer.js
var defaultOptions = {
  positions: [1, 1, -1, 1, -1, -1, 1, -1],
  indices: [0, 1, 2, 0, 2, 3]
};
var EffectRenderer = class {
  /**
   * Creates an effect renderer
   * @param engine the engine to use for rendering
   * @param options defines the options of the effect renderer
   */
  constructor(engine, options = defaultOptions) {
    this._fullscreenViewport = new Viewport(0, 0, 1, 1);
    const positions = options.positions ?? defaultOptions.positions;
    const indices = options.indices ?? defaultOptions.indices;
    this.engine = engine;
    this._vertexBuffers = {
      [VertexBuffer.PositionKind]: new VertexBuffer(engine, positions, VertexBuffer.PositionKind, false, false, 2)
    };
    this._indexBuffer = engine.createIndexBuffer(indices);
    this._onContextRestoredObserver = engine.onContextRestoredObservable.add(() => {
      this._indexBuffer = engine.createIndexBuffer(indices);
      for (const key in this._vertexBuffers) {
        const vertexBuffer = this._vertexBuffers[key];
        vertexBuffer._rebuild();
      }
    });
  }
  /**
   * Sets the current viewport in normalized coordinates 0-1
   * @param viewport Defines the viewport to set (defaults to 0 0 1 1)
   */
  setViewport(viewport = this._fullscreenViewport) {
    this.engine.setViewport(viewport);
  }
  /**
   * Binds the embedded attributes buffer to the effect.
   * @param effect Defines the effect to bind the attributes for
   */
  bindBuffers(effect) {
    this.engine.bindBuffers(this._vertexBuffers, this._indexBuffer, effect);
  }
  /**
   * Sets the current effect wrapper to use during draw.
   * The effect needs to be ready before calling this api.
   * This also sets the default full screen position attribute.
   * @param effectWrapper Defines the effect to draw with
   */
  applyEffectWrapper(effectWrapper) {
    this.engine.setState(true);
    this.engine.depthCullingState.depthTest = false;
    this.engine.stencilState.stencilTest = false;
    this.engine.enableEffect(effectWrapper._drawWrapper);
    this.bindBuffers(effectWrapper.effect);
    effectWrapper.onApplyObservable.notifyObservers({});
  }
  /**
   * Saves engine states
   */
  saveStates() {
    this._savedStateDepthTest = this.engine.depthCullingState.depthTest;
    this._savedStateStencilTest = this.engine.stencilState.stencilTest;
  }
  /**
   * Restores engine states
   */
  restoreStates() {
    this.engine.depthCullingState.depthTest = this._savedStateDepthTest;
    this.engine.stencilState.stencilTest = this._savedStateStencilTest;
  }
  /**
   * Draws a full screen quad.
   */
  draw() {
    this.engine.drawElementsType(0, 0, 6);
  }
  _isRenderTargetTexture(texture) {
    return texture.renderTarget !== void 0;
  }
  /**
   * renders one or more effects to a specified texture
   * @param effectWrapper the effect to renderer
   * @param outputTexture texture to draw to, if null it will render to the screen.
   */
  render(effectWrapper, outputTexture = null) {
    if (!effectWrapper.effect.isReady()) {
      return;
    }
    this.saveStates();
    this.setViewport();
    const out = outputTexture === null ? null : this._isRenderTargetTexture(outputTexture) ? outputTexture.renderTarget : outputTexture;
    if (out) {
      this.engine.bindFramebuffer(out);
    }
    this.applyEffectWrapper(effectWrapper);
    this.draw();
    if (out) {
      this.engine.unBindFramebuffer(out);
    }
    this.restoreStates();
  }
  /**
   * Disposes of the effect renderer
   */
  dispose() {
    const vertexBuffer = this._vertexBuffers[VertexBuffer.PositionKind];
    if (vertexBuffer) {
      vertexBuffer.dispose();
      delete this._vertexBuffers[VertexBuffer.PositionKind];
    }
    if (this._indexBuffer) {
      this.engine._releaseBuffer(this._indexBuffer);
    }
    if (this._onContextRestoredObserver) {
      this.engine.onContextRestoredObservable.remove(this._onContextRestoredObserver);
      this._onContextRestoredObserver = null;
    }
  }
};
var EffectWrapper = class {
  /**
   * The underlying effect
   */
  get effect() {
    return this._drawWrapper.effect;
  }
  set effect(effect) {
    this._drawWrapper.effect = effect;
  }
  /**
   * Creates an effect to be renderer
   * @param creationOptions options to create the effect
   */
  constructor(creationOptions) {
    this.onApplyObservable = new Observable();
    let effectCreationOptions;
    const uniformNames = creationOptions.uniformNames || [];
    if (creationOptions.vertexShader) {
      effectCreationOptions = {
        fragmentSource: creationOptions.fragmentShader,
        vertexSource: creationOptions.vertexShader,
        spectorName: creationOptions.name || "effectWrapper"
      };
    } else {
      uniformNames.push("scale");
      effectCreationOptions = {
        fragmentSource: creationOptions.fragmentShader,
        vertex: "postprocess",
        spectorName: creationOptions.name || "effectWrapper"
      };
      this.onApplyObservable.add(() => {
        this.effect.setFloat2("scale", 1, 1);
      });
    }
    const defines = creationOptions.defines ? creationOptions.defines.join("\n") : "";
    this._drawWrapper = new DrawWrapper(creationOptions.engine);
    if (creationOptions.useShaderStore) {
      effectCreationOptions.fragment = effectCreationOptions.fragmentSource;
      if (!effectCreationOptions.vertex) {
        effectCreationOptions.vertex = effectCreationOptions.vertexSource;
      }
      delete effectCreationOptions.fragmentSource;
      delete effectCreationOptions.vertexSource;
      this.effect = creationOptions.engine.createEffect(effectCreationOptions, creationOptions.attributeNames || ["position"], uniformNames, creationOptions.samplerNames, defines, void 0, creationOptions.onCompiled, void 0, void 0, creationOptions.shaderLanguage);
    } else {
      this.effect = new Effect(effectCreationOptions, creationOptions.attributeNames || ["position"], uniformNames, creationOptions.samplerNames, creationOptions.engine, defines, void 0, creationOptions.onCompiled, void 0, void 0, void 0, creationOptions.shaderLanguage);
      this._onContextRestoredObserver = creationOptions.engine.onContextRestoredObservable.add(() => {
        this.effect._pipelineContext = null;
        this.effect._prepareEffect();
      });
    }
  }
  /**
   * Disposes of the effect wrapper
   */
  dispose() {
    if (this._onContextRestoredObserver) {
      this.effect.getEngine().onContextRestoredObservable.remove(this._onContextRestoredObserver);
      this._onContextRestoredObserver = null;
    }
    this.effect.dispose();
  }
};

// node_modules/@babylonjs/core/Shaders/pass.fragment.js
var name2 = "passPixelShader";
var shader2 = `varying vec2 vUV;uniform sampler2D textureSampler;
#define CUSTOM_FRAGMENT_DEFINITIONS
void main(void) 
{gl_FragColor=texture2D(textureSampler,vUV);}`;
ShaderStore.ShadersStore[name2] = shader2;
var passPixelShader = { name: name2, shader: shader2 };

// node_modules/@babylonjs/core/Misc/dumpTools.js
var DumpTools = class _DumpTools {
  static _CreateDumpRenderer() {
    if (!_DumpTools._DumpToolsEngine) {
      let canvas;
      let engine = null;
      const options = {
        preserveDrawingBuffer: true,
        depth: false,
        stencil: false,
        alpha: true,
        premultipliedAlpha: false,
        antialias: false,
        failIfMajorPerformanceCaveat: false
      };
      try {
        canvas = new OffscreenCanvas(100, 100);
        engine = new ThinEngine(canvas, false, options);
      } catch (e) {
        canvas = document.createElement("canvas");
        engine = new ThinEngine(canvas, false, options);
      }
      engine.getCaps().parallelShaderCompile = void 0;
      const renderer = new EffectRenderer(engine);
      const wrapper = new EffectWrapper({
        engine,
        name: passPixelShader.name,
        fragmentShader: passPixelShader.shader,
        samplerNames: ["textureSampler"]
      });
      _DumpTools._DumpToolsEngine = {
        canvas,
        engine,
        renderer,
        wrapper
      };
    }
    return _DumpTools._DumpToolsEngine;
  }
  /**
   * Dumps the current bound framebuffer
   * @param width defines the rendering width
   * @param height defines the rendering height
   * @param engine defines the hosting engine
   * @param successCallback defines the callback triggered once the data are available
   * @param mimeType defines the mime type of the result
   * @param fileName defines the filename to download. If present, the result will automatically be downloaded
   * @param quality The quality of the image if lossy mimeType is used (e.g. image/jpeg, image/webp). See {@link https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toBlob | HTMLCanvasElement.toBlob()}'s `quality` parameter.
   * @returns a void promise
   */
  static async DumpFramebuffer(width, height, engine, successCallback, mimeType = "image/png", fileName, quality) {
    const bufferView = await engine.readPixels(0, 0, width, height);
    const data = new Uint8Array(bufferView.buffer);
    _DumpTools.DumpData(width, height, data, successCallback, mimeType, fileName, true, void 0, quality);
  }
  /**
   * Dumps an array buffer
   * @param width defines the rendering width
   * @param height defines the rendering height
   * @param data the data array
   * @param mimeType defines the mime type of the result
   * @param fileName defines the filename to download. If present, the result will automatically be downloaded
   * @param invertY true to invert the picture in the Y dimension
   * @param toArrayBuffer true to convert the data to an ArrayBuffer (encoded as `mimeType`) instead of a base64 string
   * @param quality The quality of the image if lossy mimeType is used (e.g. image/jpeg, image/webp). See {@link https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toBlob | HTMLCanvasElement.toBlob()}'s `quality` parameter.
   * @returns a promise that resolve to the final data
   */
  static DumpDataAsync(width, height, data, mimeType = "image/png", fileName, invertY = false, toArrayBuffer = false, quality) {
    return new Promise((resolve) => {
      _DumpTools.DumpData(width, height, data, (result) => resolve(result), mimeType, fileName, invertY, toArrayBuffer, quality);
    });
  }
  /**
   * Dumps an array buffer
   * @param width defines the rendering width
   * @param height defines the rendering height
   * @param data the data array
   * @param successCallback defines the callback triggered once the data are available
   * @param mimeType defines the mime type of the result
   * @param fileName defines the filename to download. If present, the result will automatically be downloaded
   * @param invertY true to invert the picture in the Y dimension
   * @param toArrayBuffer true to convert the data to an ArrayBuffer (encoded as `mimeType`) instead of a base64 string
   * @param quality The quality of the image if lossy mimeType is used (e.g. image/jpeg, image/webp). See {@link https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toBlob | HTMLCanvasElement.toBlob()}'s `quality` parameter.
   */
  static DumpData(width, height, data, successCallback, mimeType = "image/png", fileName, invertY = false, toArrayBuffer = false, quality) {
    const renderer = _DumpTools._CreateDumpRenderer();
    renderer.engine.setSize(width, height, true);
    if (data instanceof Float32Array) {
      const data2 = new Uint8Array(data.length);
      let n = data.length;
      while (n--) {
        const v = data[n];
        data2[n] = Math.round(Scalar.Clamp(v) * 255);
      }
      data = data2;
    }
    const texture = renderer.engine.createRawTexture(data, width, height, 5, false, !invertY, 1);
    renderer.renderer.setViewport();
    renderer.renderer.applyEffectWrapper(renderer.wrapper);
    renderer.wrapper.effect._bindTexture("textureSampler", texture);
    renderer.renderer.draw();
    if (toArrayBuffer) {
      Tools.ToBlob(renderer.canvas, (blob) => {
        const fileReader = new FileReader();
        fileReader.onload = (event) => {
          const arrayBuffer = event.target.result;
          if (successCallback) {
            successCallback(arrayBuffer);
          }
        };
        fileReader.readAsArrayBuffer(blob);
      }, mimeType, quality);
    } else {
      Tools.EncodeScreenshotCanvasData(renderer.canvas, successCallback, mimeType, fileName, quality);
    }
    texture.dispose();
  }
  /**
   * Dispose the dump tools associated resources
   */
  static Dispose() {
    if (_DumpTools._DumpToolsEngine) {
      _DumpTools._DumpToolsEngine.wrapper.dispose();
      _DumpTools._DumpToolsEngine.renderer.dispose();
      _DumpTools._DumpToolsEngine.engine.dispose();
    }
    _DumpTools._DumpToolsEngine = null;
  }
};
var initSideEffects = () => {
  Tools.DumpData = DumpTools.DumpData;
  Tools.DumpDataAsync = DumpTools.DumpDataAsync;
  Tools.DumpFramebuffer = DumpTools.DumpFramebuffer;
};
initSideEffects();

// node_modules/@babylonjs/core/Engines/Extensions/engine.renderTargetCube.js
ThinEngine.prototype.createRenderTargetCubeTexture = function(size, options) {
  const rtWrapper = this._createHardwareRenderTargetWrapper(false, true, size);
  const fullOptions = {
    generateMipMaps: true,
    generateDepthBuffer: true,
    generateStencilBuffer: false,
    type: 0,
    samplingMode: 3,
    format: 5,
    ...options
  };
  fullOptions.generateStencilBuffer = fullOptions.generateDepthBuffer && fullOptions.generateStencilBuffer;
  if (fullOptions.type === 1 && !this._caps.textureFloatLinearFiltering) {
    fullOptions.samplingMode = 1;
  } else if (fullOptions.type === 2 && !this._caps.textureHalfFloatLinearFiltering) {
    fullOptions.samplingMode = 1;
  }
  const gl = this._gl;
  const texture = new InternalTexture(this, InternalTextureSource.RenderTarget);
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
  const filters = this._getSamplingParameters(fullOptions.samplingMode, fullOptions.generateMipMaps);
  if (fullOptions.type === 1 && !this._caps.textureFloat) {
    fullOptions.type = 0;
    Logger.Warn("Float textures are not supported. Cube render target forced to TEXTURETYPE_UNESIGNED_BYTE type");
  }
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, filters.mag);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, filters.min);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  for (let face = 0; face < 6; face++) {
    gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, this._getRGBABufferInternalSizedFormat(fullOptions.type, fullOptions.format), size, size, 0, this._getInternalFormat(fullOptions.format), this._getWebGLTextureType(fullOptions.type), null);
  }
  const framebuffer = gl.createFramebuffer();
  this._bindUnboundFramebuffer(framebuffer);
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(fullOptions.generateStencilBuffer, fullOptions.generateDepthBuffer, size, size);
  if (fullOptions.generateMipMaps) {
    gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
  this._bindUnboundFramebuffer(null);
  rtWrapper._framebuffer = framebuffer;
  rtWrapper._generateDepthBuffer = fullOptions.generateDepthBuffer;
  rtWrapper._generateStencilBuffer = fullOptions.generateStencilBuffer;
  texture.width = size;
  texture.height = size;
  texture.isReady = true;
  texture.isCube = true;
  texture.samples = 1;
  texture.generateMipMaps = fullOptions.generateMipMaps;
  texture.samplingMode = fullOptions.samplingMode;
  texture.type = fullOptions.type;
  texture.format = fullOptions.format;
  this._internalTexturesCache.push(texture);
  rtWrapper.setTextures(texture);
  return rtWrapper;
};

// node_modules/@babylonjs/core/Materials/Textures/renderTargetTexture.js
var RenderTargetTexture = class _RenderTargetTexture extends Texture {
  /**
   * Use this list to define the list of mesh you want to render.
   */
  get renderList() {
    return this._renderList;
  }
  set renderList(value) {
    if (this._unObserveRenderList) {
      this._unObserveRenderList();
      this._unObserveRenderList = null;
    }
    if (value) {
      this._unObserveRenderList = _ObserveArray(value, this._renderListHasChanged);
    }
    this._renderList = value;
  }
  /**
   * Post-processes for this render target
   */
  get postProcesses() {
    return this._postProcesses;
  }
  get _prePassEnabled() {
    return !!this._prePassRenderTarget && this._prePassRenderTarget.enabled;
  }
  /**
   * Set a after unbind callback in the texture.
   * This has been kept for backward compatibility and use of onAfterUnbindObservable is recommended.
   */
  set onAfterUnbind(callback) {
    if (this._onAfterUnbindObserver) {
      this.onAfterUnbindObservable.remove(this._onAfterUnbindObserver);
    }
    this._onAfterUnbindObserver = this.onAfterUnbindObservable.add(callback);
  }
  /**
   * Set a before render callback in the texture.
   * This has been kept for backward compatibility and use of onBeforeRenderObservable is recommended.
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * Set a after render callback in the texture.
   * This has been kept for backward compatibility and use of onAfterRenderObservable is recommended.
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * Set a clear callback in the texture.
   * This has been kept for backward compatibility and use of onClearObservable is recommended.
   */
  set onClear(callback) {
    if (this._onClearObserver) {
      this.onClearObservable.remove(this._onClearObserver);
    }
    this._onClearObserver = this.onClearObservable.add(callback);
  }
  /**
   * Gets the render pass ids used by the render target texture. For a single render target the array length will be 1, for a cube texture it will be 6 and for
   * a 2D texture array it will return an array of ids the size of the 2D texture array
   */
  get renderPassIds() {
    return this._renderPassIds;
  }
  /**
   * Gets the current value of the refreshId counter
   */
  get currentRefreshId() {
    return this._currentRefreshId;
  }
  /**
   * Sets a specific material to be used to render a mesh/a list of meshes in this render target texture
   * @param mesh mesh or array of meshes
   * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering in the case of a cube texture (6 rendering) and a 2D texture array (as many rendering as the length of the array)
   */
  setMaterialForRendering(mesh, material) {
    let meshes;
    if (!Array.isArray(mesh)) {
      meshes = [mesh];
    } else {
      meshes = mesh;
    }
    for (let j = 0; j < meshes.length; ++j) {
      for (let i = 0; i < this._renderPassIds.length; ++i) {
        meshes[j].setMaterialForRenderPass(this._renderPassIds[i], material !== void 0 ? Array.isArray(material) ? material[i] : material : void 0);
      }
    }
  }
  /**
   * Define if the texture has multiple draw buffers or if false a single draw buffer.
   */
  get isMulti() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.isMulti) ?? false;
  }
  /**
   * Gets render target creation options that were used.
   */
  get renderTargetOptions() {
    return this._renderTargetOptions;
  }
  /**
   * Gets the render target wrapper associated with this render target
   */
  get renderTarget() {
    return this._renderTarget;
  }
  _onRatioRescale() {
    if (this._sizeRatio) {
      this.resize(this._initialSizeParameter);
    }
  }
  /**
   * Gets or sets the size of the bounding box associated with the texture (when in cube mode)
   * When defined, the cubemap will switch to local mode
   * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
   * @example https://www.babylonjs-playground.com/#RNASML
   */
  set boundingBoxSize(value) {
    if (this._boundingBoxSize && this._boundingBoxSize.equals(value)) {
      return;
    }
    this._boundingBoxSize = value;
    const scene = this.getScene();
    if (scene) {
      scene.markAllMaterialsAsDirty(1);
    }
  }
  get boundingBoxSize() {
    return this._boundingBoxSize;
  }
  /**
   * In case the RTT has been created with a depth texture, get the associated
   * depth texture.
   * Otherwise, return null.
   */
  get depthStencilTexture() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a._depthStencilTexture) ?? null;
  }
  /** @internal */
  constructor(name6, size, scene, generateMipMaps = false, doNotChangeAspectRatio = true, type = 0, isCube = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, generateDepthBuffer = true, generateStencilBuffer = false, isMulti = false, format = 5, delayAllocation = false, samples, creationFlags, noColorAttachment = false, useSRGBBuffer = false) {
    let colorAttachment = void 0;
    let gammaSpace = true;
    if (typeof generateMipMaps === "object") {
      const options = generateMipMaps;
      generateMipMaps = !!options.generateMipMaps;
      doNotChangeAspectRatio = options.doNotChangeAspectRatio ?? true;
      type = options.type ?? 0;
      isCube = !!options.isCube;
      samplingMode = options.samplingMode ?? Texture.TRILINEAR_SAMPLINGMODE;
      generateDepthBuffer = options.generateDepthBuffer ?? true;
      generateStencilBuffer = !!options.generateStencilBuffer;
      isMulti = !!options.isMulti;
      format = options.format ?? 5;
      delayAllocation = !!options.delayAllocation;
      samples = options.samples;
      creationFlags = options.creationFlags;
      noColorAttachment = !!options.noColorAttachment;
      useSRGBBuffer = !!options.useSRGBBuffer;
      colorAttachment = options.colorAttachment;
      gammaSpace = options.gammaSpace ?? gammaSpace;
    }
    super(null, scene, !generateMipMaps, void 0, samplingMode, void 0, void 0, void 0, void 0, format);
    this._unObserveRenderList = null;
    this._renderListHasChanged = (_functionName, previousLength) => {
      var _a;
      const newLength = this._renderList ? this._renderList.length : 0;
      if (previousLength === 0 && newLength > 0 || newLength === 0) {
        (_a = this.getScene()) == null ? void 0 : _a.meshes.forEach((mesh) => {
          mesh._markSubMeshesAsLightDirty();
        });
      }
    };
    this.renderParticles = true;
    this.renderSprites = false;
    this.forceLayerMaskCheck = false;
    this.ignoreCameraViewport = false;
    this.onBeforeBindObservable = new Observable();
    this.onAfterUnbindObservable = new Observable();
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this.onClearObservable = new Observable();
    this.onResizeObservable = new Observable();
    this._cleared = false;
    this.skipInitialClear = false;
    this._currentRefreshId = -1;
    this._refreshRate = 1;
    this._samples = 1;
    this._canRescale = true;
    this._renderTarget = null;
    this.boundingBoxPosition = Vector3.Zero();
    scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = this.getScene().getEngine();
    this._gammaSpace = gammaSpace;
    this._coordinatesMode = Texture.PROJECTION_MODE;
    this.renderList = [];
    this.name = name6;
    this.isRenderTarget = true;
    this._initialSizeParameter = size;
    this._renderPassIds = [];
    this._isCubeData = isCube;
    this._processSizeParameter(size);
    this.renderPassId = this._renderPassIds[0];
    this._resizeObserver = engine.onResizeObservable.add(() => {
    });
    this._generateMipMaps = generateMipMaps ? true : false;
    this._doNotChangeAspectRatio = doNotChangeAspectRatio;
    this._renderingManager = new RenderingManager(scene);
    this._renderingManager._useSceneAutoClearSetup = true;
    if (isMulti) {
      return;
    }
    this._renderTargetOptions = {
      generateMipMaps,
      type,
      format: this._format ?? void 0,
      samplingMode: this.samplingMode,
      generateDepthBuffer,
      generateStencilBuffer,
      samples,
      creationFlags,
      noColorAttachment,
      useSRGBBuffer,
      colorAttachment,
      label: this.name
    };
    if (this.samplingMode === Texture.NEAREST_SAMPLINGMODE) {
      this.wrapU = Texture.CLAMP_ADDRESSMODE;
      this.wrapV = Texture.CLAMP_ADDRESSMODE;
    }
    if (!delayAllocation) {
      if (isCube) {
        this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
        this.coordinatesMode = Texture.INVCUBIC_MODE;
        this._textureMatrix = Matrix.Identity();
      } else {
        this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
      }
      this._texture = this._renderTarget.texture;
      if (samples !== void 0) {
        this.samples = samples;
      }
    }
  }
  /**
   * Creates a depth stencil texture.
   * This is only available in WebGL 2 or with the depth texture extension available.
   * @param comparisonFunction Specifies the comparison function to set on the texture. If 0 or undefined, the texture is not in comparison mode (default: 0)
   * @param bilinearFiltering Specifies whether or not bilinear filtering is enable on the texture (default: true)
   * @param generateStencil Specifies whether or not a stencil should be allocated in the texture (default: false)
   * @param samples sample count of the depth/stencil texture (default: 1)
   * @param format format of the depth texture (default: 14)
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14) {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.createDepthStencilTexture(comparisonFunction, bilinearFiltering, generateStencil, samples, format);
  }
  _releaseRenderPassId() {
    if (this._scene) {
      const engine = this._scene.getEngine();
      for (let i = 0; i < this._renderPassIds.length; ++i) {
        engine.releaseRenderPassId(this._renderPassIds[i]);
      }
    }
    this._renderPassIds = [];
  }
  _createRenderPassId() {
    this._releaseRenderPassId();
    const engine = this._scene.getEngine();
    const numPasses = this._isCubeData ? 6 : this.getRenderLayers() || 1;
    for (let i = 0; i < numPasses; ++i) {
      this._renderPassIds[i] = engine.createRenderPassId(`RenderTargetTexture - ${this.name}#${i}`);
    }
  }
  _processSizeParameter(size, createRenderPassIds = true) {
    if (size.ratio) {
      this._sizeRatio = size.ratio;
      const engine = this._getEngine();
      this._size = {
        width: this._bestReflectionRenderTargetDimension(engine.getRenderWidth(), this._sizeRatio),
        height: this._bestReflectionRenderTargetDimension(engine.getRenderHeight(), this._sizeRatio)
      };
    } else {
      this._size = size;
    }
    if (createRenderPassIds) {
      this._createRenderPassId();
    }
  }
  /**
   * Define the number of samples to use in case of MSAA.
   * It defaults to one meaning no MSAA has been enabled.
   */
  get samples() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.samples) ?? this._samples;
  }
  set samples(value) {
    if (this._renderTarget) {
      this._samples = this._renderTarget.setSamples(value);
    }
  }
  /**
   * Resets the refresh counter of the texture and start bak from scratch.
   * Could be useful to regenerate the texture if it is setup to render only once.
   */
  resetRefreshCounter() {
    this._currentRefreshId = -1;
  }
  /**
   * Define the refresh rate of the texture or the rendering frequency.
   * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
   */
  get refreshRate() {
    return this._refreshRate;
  }
  set refreshRate(value) {
    this._refreshRate = value;
    this.resetRefreshCounter();
  }
  /**
   * Adds a post process to the render target rendering passes.
   * @param postProcess define the post process to add
   */
  addPostProcess(postProcess) {
    if (!this._postProcessManager) {
      const scene = this.getScene();
      if (!scene) {
        return;
      }
      this._postProcessManager = new PostProcessManager(scene);
      this._postProcesses = new Array();
    }
    this._postProcesses.push(postProcess);
    this._postProcesses[0].autoClear = false;
  }
  /**
   * Clear all the post processes attached to the render target
   * @param dispose define if the cleared post processes should also be disposed (false by default)
   */
  clearPostProcesses(dispose = false) {
    if (!this._postProcesses) {
      return;
    }
    if (dispose) {
      for (const postProcess of this._postProcesses) {
        postProcess.dispose();
      }
    }
    this._postProcesses = [];
  }
  /**
   * Remove one of the post process from the list of attached post processes to the texture
   * @param postProcess define the post process to remove from the list
   */
  removePostProcess(postProcess) {
    if (!this._postProcesses) {
      return;
    }
    const index = this._postProcesses.indexOf(postProcess);
    if (index === -1) {
      return;
    }
    this._postProcesses.splice(index, 1);
    if (this._postProcesses.length > 0) {
      this._postProcesses[0].autoClear = false;
    }
  }
  /** @internal */
  _shouldRender() {
    if (this._currentRefreshId === -1) {
      this._currentRefreshId = 1;
      return true;
    }
    if (this.refreshRate === this._currentRefreshId) {
      this._currentRefreshId = 1;
      return true;
    }
    this._currentRefreshId++;
    return false;
  }
  /**
   * Gets the actual render size of the texture.
   * @returns the width of the render size
   */
  getRenderSize() {
    return this.getRenderWidth();
  }
  /**
   * Gets the actual render width of the texture.
   * @returns the width of the render size
   */
  getRenderWidth() {
    if (this._size.width) {
      return this._size.width;
    }
    return this._size;
  }
  /**
   * Gets the actual render height of the texture.
   * @returns the height of the render size
   */
  getRenderHeight() {
    if (this._size.width) {
      return this._size.height;
    }
    return this._size;
  }
  /**
   * Gets the actual number of layers of the texture.
   * @returns the number of layers
   */
  getRenderLayers() {
    const layers = this._size.layers;
    if (layers) {
      return layers;
    }
    return 0;
  }
  /**
   * Don't allow this render target texture to rescale. Mainly used to prevent rescaling by the scene optimizer.
   */
  disableRescaling() {
    this._canRescale = false;
  }
  /**
   * Get if the texture can be rescaled or not.
   */
  get canRescale() {
    return this._canRescale;
  }
  /**
   * Resize the texture using a ratio.
   * @param ratio the ratio to apply to the texture size in order to compute the new target size
   */
  scale(ratio) {
    const newSize = Math.max(1, this.getRenderSize() * ratio);
    this.resize(newSize);
  }
  /**
   * Get the texture reflection matrix used to rotate/transform the reflection.
   * @returns the reflection matrix
   */
  getReflectionTextureMatrix() {
    if (this.isCube) {
      return this._textureMatrix;
    }
    return super.getReflectionTextureMatrix();
  }
  /**
   * Resize the texture to a new desired size.
   * Be careful as it will recreate all the data in the new texture.
   * @param size Define the new size. It can be:
   *   - a number for squared texture,
   *   - an object containing { width: number, height: number }
   *   - or an object containing a ratio { ratio: number }
   */
  resize(size) {
    var _a;
    const wasCube = this.isCube;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this._processSizeParameter(size, false);
    if (wasCube) {
      this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
    } else {
      this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
    }
    this._texture = this._renderTarget.texture;
    if (this._renderTargetOptions.samples !== void 0) {
      this.samples = this._renderTargetOptions.samples;
    }
    if (this.onResizeObservable.hasObservers()) {
      this.onResizeObservable.notifyObservers(this);
    }
  }
  /**
   * Renders all the objects from the render list into the texture.
   * @param useCameraPostProcess Define if camera post processes should be used during the rendering
   * @param dumpForDebug Define if the rendering result should be dumped (copied) for debugging purpose
   */
  render(useCameraPostProcess = false, dumpForDebug = false) {
    this._render(useCameraPostProcess, dumpForDebug);
  }
  /**
   * This function will check if the render target texture can be rendered (textures are loaded, shaders are compiled)
   * @returns true if all required resources are ready
   */
  isReadyForRendering() {
    return this._render(false, false, true);
  }
  _render(useCameraPostProcess = false, dumpForDebug = false, checkReadiness = false) {
    const scene = this.getScene();
    if (!scene) {
      return checkReadiness;
    }
    const engine = scene.getEngine();
    if (this.useCameraPostProcesses !== void 0) {
      useCameraPostProcess = this.useCameraPostProcesses;
    }
    if (this._waitingRenderList) {
      if (!this.renderListPredicate) {
        this.renderList = [];
        for (let index = 0; index < this._waitingRenderList.length; index++) {
          const id = this._waitingRenderList[index];
          const mesh = scene.getMeshById(id);
          if (mesh) {
            this.renderList.push(mesh);
          }
        }
      }
      this._waitingRenderList = void 0;
    }
    if (this.renderListPredicate) {
      if (this.renderList) {
        this.renderList.length = 0;
      } else {
        this.renderList = [];
      }
      const scene2 = this.getScene();
      if (!scene2) {
        return checkReadiness;
      }
      const sceneMeshes = scene2.meshes;
      for (let index = 0; index < sceneMeshes.length; index++) {
        const mesh = sceneMeshes[index];
        if (this.renderListPredicate(mesh)) {
          this.renderList.push(mesh);
        }
      }
    }
    const currentRenderPassId = engine.currentRenderPassId;
    this.onBeforeBindObservable.notifyObservers(this);
    const camera = this.activeCamera ?? scene.activeCamera;
    const sceneCamera = scene.activeCamera;
    if (camera) {
      if (camera !== scene.activeCamera) {
        scene.setTransformMatrix(camera.getViewMatrix(), camera.getProjectionMatrix(true));
        scene.activeCamera = camera;
      }
      engine.setViewport(camera.rigParent ? camera.rigParent.viewport : camera.viewport, this.getRenderWidth(), this.getRenderHeight());
    }
    this._defaultRenderListPrepared = false;
    let returnValue = checkReadiness;
    if (!checkReadiness) {
      if (this.is2DArray && !this.isMulti) {
        for (let layer = 0; layer < this.getRenderLayers(); layer++) {
          this._renderToTarget(0, useCameraPostProcess, dumpForDebug, layer, camera);
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      } else if (this.isCube && !this.isMulti) {
        for (let face = 0; face < 6; face++) {
          this._renderToTarget(face, useCameraPostProcess, dumpForDebug, void 0, camera);
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      } else {
        this._renderToTarget(0, useCameraPostProcess, dumpForDebug, void 0, camera);
      }
    } else {
      if (!scene.getViewMatrix()) {
        scene.updateTransformMatrix();
      }
      const numLayers = this.is2DArray ? this.getRenderLayers() : this.isCube ? 6 : 1;
      for (let layer = 0; layer < numLayers && returnValue; layer++) {
        let currentRenderList = null;
        const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
        const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
        engine.currentRenderPassId = this._renderPassIds[layer];
        this.onBeforeRenderObservable.notifyObservers(layer);
        if (this.getCustomRenderList) {
          currentRenderList = this.getCustomRenderList(layer, defaultRenderList, defaultRenderListLength);
        }
        if (!currentRenderList) {
          currentRenderList = defaultRenderList;
        }
        if (!this._doNotChangeAspectRatio) {
          scene.updateTransformMatrix(true);
        }
        for (let i = 0; i < currentRenderList.length && returnValue; ++i) {
          const mesh = currentRenderList[i];
          if (!mesh.isEnabled() || mesh.isBlocked || !mesh.isVisible || !mesh.subMeshes) {
            continue;
          }
          if (this.customIsReadyFunction) {
            if (!this.customIsReadyFunction(mesh, this.refreshRate, checkReadiness)) {
              returnValue = false;
              continue;
            }
          } else if (!mesh.isReady(true)) {
            returnValue = false;
            continue;
          }
        }
        this.onAfterRenderObservable.notifyObservers(layer);
        if (this.is2DArray || this.isCube) {
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      }
    }
    this.onAfterUnbindObservable.notifyObservers(this);
    engine.currentRenderPassId = currentRenderPassId;
    if (sceneCamera) {
      scene.activeCamera = sceneCamera;
      if (this.activeCamera && this.activeCamera !== scene.activeCamera) {
        scene.setTransformMatrix(scene.activeCamera.getViewMatrix(), scene.activeCamera.getProjectionMatrix(true));
      }
      engine.setViewport(scene.activeCamera.viewport);
    }
    scene.resetCachedMaterial();
    return returnValue;
  }
  _bestReflectionRenderTargetDimension(renderDimension, scale) {
    const minimum = 128;
    const x = renderDimension * scale;
    const curved = Engine.NearestPOT(x + minimum * minimum / (minimum + x));
    return Math.min(Engine.FloorPOT(renderDimension), curved);
  }
  _prepareRenderingManager(currentRenderList, currentRenderListLength, camera, checkLayerMask) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this._renderingManager.reset();
    const sceneRenderId = scene.getRenderId();
    for (let meshIndex = 0; meshIndex < currentRenderListLength; meshIndex++) {
      const mesh = currentRenderList[meshIndex];
      if (mesh && !mesh.isBlocked) {
        if (this.customIsReadyFunction) {
          if (!this.customIsReadyFunction(mesh, this.refreshRate, false)) {
            this.resetRefreshCounter();
            continue;
          }
        } else if (!mesh.isReady(this.refreshRate === 0)) {
          this.resetRefreshCounter();
          continue;
        }
        if (!mesh._internalAbstractMeshDataInfo._currentLODIsUpToDate && scene.activeCamera) {
          mesh._internalAbstractMeshDataInfo._currentLOD = scene.customLODSelector ? scene.customLODSelector(mesh, this.activeCamera || scene.activeCamera) : mesh.getLOD(this.activeCamera || scene.activeCamera);
          mesh._internalAbstractMeshDataInfo._currentLODIsUpToDate = true;
        }
        if (!mesh._internalAbstractMeshDataInfo._currentLOD) {
          continue;
        }
        let meshToRender = mesh._internalAbstractMeshDataInfo._currentLOD;
        meshToRender._preActivateForIntermediateRendering(sceneRenderId);
        let isMasked;
        if (checkLayerMask && camera) {
          isMasked = (mesh.layerMask & camera.layerMask) === 0;
        } else {
          isMasked = false;
        }
        if (mesh.isEnabled() && mesh.isVisible && mesh.subMeshes && !isMasked) {
          if (meshToRender !== mesh) {
            meshToRender._activate(sceneRenderId, true);
          }
          if (mesh._activate(sceneRenderId, true) && mesh.subMeshes.length) {
            if (!mesh.isAnInstance) {
              meshToRender._internalAbstractMeshDataInfo._onlyForInstancesIntermediate = false;
            } else {
              if (mesh._internalAbstractMeshDataInfo._actAsRegularMesh) {
                meshToRender = mesh;
              }
            }
            meshToRender._internalAbstractMeshDataInfo._isActiveIntermediate = true;
            for (let subIndex = 0; subIndex < meshToRender.subMeshes.length; subIndex++) {
              const subMesh = meshToRender.subMeshes[subIndex];
              this._renderingManager.dispatch(subMesh, meshToRender);
            }
          }
        }
      }
    }
    for (let particleIndex = 0; particleIndex < scene.particleSystems.length; particleIndex++) {
      const particleSystem = scene.particleSystems[particleIndex];
      const emitter = particleSystem.emitter;
      if (!particleSystem.isStarted() || !emitter || emitter.position && !emitter.isEnabled()) {
        continue;
      }
      this._renderingManager.dispatchParticles(particleSystem);
    }
  }
  /**
   * @internal
   * @param faceIndex face index to bind to if this is a cubetexture
   * @param layer defines the index of the texture to bind in the array
   */
  _bindFrameBuffer(faceIndex = 0, layer = 0) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    if (this._renderTarget) {
      engine.bindFramebuffer(this._renderTarget, this.isCube ? faceIndex : void 0, void 0, void 0, this.ignoreCameraViewport, 0, layer);
    }
  }
  _unbindFrameBuffer(engine, faceIndex) {
    if (!this._renderTarget) {
      return;
    }
    engine.unBindFramebuffer(this._renderTarget, this.isCube, () => {
      this.onAfterRenderObservable.notifyObservers(faceIndex);
    });
  }
  /**
   * @internal
   */
  _prepareFrame(scene, faceIndex, layer, useCameraPostProcess) {
    if (this._postProcessManager) {
      if (!this._prePassEnabled) {
        this._postProcessManager._prepareFrame(this._texture, this._postProcesses);
      }
    } else if (!useCameraPostProcess || !scene.postProcessManager._prepareFrame(this._texture)) {
      this._bindFrameBuffer(faceIndex, layer);
    }
  }
  _renderToTarget(faceIndex, useCameraPostProcess, dumpForDebug, layer = 0, camera = null) {
    var _a, _b, _c;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    (_a = engine._debugPushGroup) == null ? void 0 : _a.call(engine, `render to face #${faceIndex} layer #${layer}`, 1);
    this._prepareFrame(scene, faceIndex, layer, useCameraPostProcess);
    if (this.is2DArray) {
      engine.currentRenderPassId = this._renderPassIds[layer];
      this.onBeforeRenderObservable.notifyObservers(layer);
    } else {
      engine.currentRenderPassId = this._renderPassIds[faceIndex];
      this.onBeforeRenderObservable.notifyObservers(faceIndex);
    }
    const fastPath = engine.snapshotRendering && engine.snapshotRenderingMode === 1;
    if (!fastPath) {
      let currentRenderList = null;
      const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
      const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
      if (this.getCustomRenderList) {
        currentRenderList = this.getCustomRenderList(this.is2DArray ? layer : faceIndex, defaultRenderList, defaultRenderListLength);
      }
      if (!currentRenderList) {
        if (!this._defaultRenderListPrepared) {
          this._prepareRenderingManager(defaultRenderList, defaultRenderListLength, camera, !this.renderList || this.forceLayerMaskCheck);
          this._defaultRenderListPrepared = true;
        }
        currentRenderList = defaultRenderList;
      } else {
        this._prepareRenderingManager(currentRenderList, currentRenderList.length, camera, this.forceLayerMaskCheck);
      }
      for (const step of scene._beforeRenderTargetClearStage) {
        step.action(this, faceIndex, layer);
      }
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else if (!this.skipInitialClear) {
        engine.clear(this.clearColor || scene.clearColor, true, true, true);
      }
      if (!this._doNotChangeAspectRatio) {
        scene.updateTransformMatrix(true);
      }
      for (const step of scene._beforeRenderTargetDrawStage) {
        step.action(this, faceIndex, layer);
      }
      this._renderingManager.render(this.customRenderFunction, currentRenderList, this.renderParticles, this.renderSprites);
      for (const step of scene._afterRenderTargetDrawStage) {
        step.action(this, faceIndex, layer);
      }
      const saveGenerateMipMaps = ((_b = this._texture) == null ? void 0 : _b.generateMipMaps) ?? false;
      if (this._texture) {
        this._texture.generateMipMaps = false;
      }
      if (this._postProcessManager) {
        this._postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, faceIndex, this._postProcesses, this.ignoreCameraViewport);
      } else if (useCameraPostProcess) {
        scene.postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, faceIndex);
      }
      for (const step of scene._afterRenderTargetPostProcessStage) {
        step.action(this, faceIndex, layer);
      }
      if (this._texture) {
        this._texture.generateMipMaps = saveGenerateMipMaps;
      }
      if (!this._doNotChangeAspectRatio) {
        scene.updateTransformMatrix(true);
      }
      if (dumpForDebug) {
        DumpTools.DumpFramebuffer(this.getRenderWidth(), this.getRenderHeight(), engine);
      }
    } else {
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else {
        if (!this.skipInitialClear) {
          engine.clear(this.clearColor || scene.clearColor, true, true, true);
        }
      }
    }
    this._unbindFrameBuffer(engine, faceIndex);
    if (this._texture && this.isCube && faceIndex === 5) {
      engine.generateMipMapsForCubemap(this._texture);
    }
    (_c = engine._debugPopGroup) == null ? void 0 : _c.call(engine, 1);
  }
  /**
   * Overrides the default sort function applied in the rendering group to prepare the meshes.
   * This allowed control for front to back rendering or reversely depending of the special needs.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
   * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
   * @param transparentSortCompareFn The transparent queue comparison function use to sort.
   */
  setRenderingOrder(renderingGroupId, opaqueSortCompareFn = null, alphaTestSortCompareFn = null, transparentSortCompareFn = null) {
    this._renderingManager.setRenderingOrder(renderingGroupId, opaqueSortCompareFn, alphaTestSortCompareFn, transparentSortCompareFn);
  }
  /**
   * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
   */
  setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil) {
    this._renderingManager.setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil);
    this._renderingManager._useSceneAutoClearSetup = false;
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    const textureSize = this.getSize();
    const newTexture = new _RenderTargetTexture(this.name, textureSize, this.getScene(), this._renderTargetOptions.generateMipMaps, this._doNotChangeAspectRatio, this._renderTargetOptions.type, this.isCube, this._renderTargetOptions.samplingMode, this._renderTargetOptions.generateDepthBuffer, this._renderTargetOptions.generateStencilBuffer, void 0, this._renderTargetOptions.format, void 0, this._renderTargetOptions.samples);
    newTexture.hasAlpha = this.hasAlpha;
    newTexture.level = this.level;
    newTexture.coordinatesMode = this.coordinatesMode;
    if (this.renderList) {
      newTexture.renderList = this.renderList.slice(0);
    }
    return newTexture;
  }
  /**
   * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
   * @returns The JSON representation of the texture
   */
  serialize() {
    if (!this.name) {
      return null;
    }
    const serializationObject = super.serialize();
    serializationObject.renderTargetSize = this.getRenderSize();
    serializationObject.renderList = [];
    if (this.renderList) {
      for (let index = 0; index < this.renderList.length; index++) {
        serializationObject.renderList.push(this.renderList[index].id);
      }
    }
    return serializationObject;
  }
  /**
   *  This will remove the attached framebuffer objects. The texture will not be able to be used as render target anymore
   */
  disposeFramebufferObjects() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose(true);
  }
  /**
   * Release and destroy the underlying lower level texture aka internalTexture.
   */
  releaseInternalTexture() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.releaseTextures();
    this._texture = null;
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    var _a;
    this.onResizeObservable.clear();
    this.onClearObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onAfterUnbindObservable.clear();
    this.onBeforeBindObservable.clear();
    this.onBeforeRenderObservable.clear();
    if (this._postProcessManager) {
      this._postProcessManager.dispose();
      this._postProcessManager = null;
    }
    if (this._prePassRenderTarget) {
      this._prePassRenderTarget.dispose();
    }
    this._releaseRenderPassId();
    this.clearPostProcesses(true);
    if (this._resizeObserver) {
      this.getScene().getEngine().onResizeObservable.remove(this._resizeObserver);
      this._resizeObserver = null;
    }
    this.renderList = null;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    let index = scene.customRenderTargets.indexOf(this);
    if (index >= 0) {
      scene.customRenderTargets.splice(index, 1);
    }
    for (const camera of scene.cameras) {
      index = camera.customRenderTargets.indexOf(this);
      if (index >= 0) {
        camera.customRenderTargets.splice(index, 1);
      }
    }
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    this._texture = null;
    super.dispose();
  }
  /** @internal */
  _rebuild() {
    if (this.refreshRate === _RenderTargetTexture.REFRESHRATE_RENDER_ONCE) {
      this.refreshRate = _RenderTargetTexture.REFRESHRATE_RENDER_ONCE;
    }
    if (this._postProcessManager) {
      this._postProcessManager._rebuild();
    }
  }
  /**
   * Clear the info related to rendering groups preventing retention point in material dispose.
   */
  freeRenderingGroups() {
    if (this._renderingManager) {
      this._renderingManager.freeRenderingGroups();
    }
  }
  /**
   * Gets the number of views the corresponding to the texture (eg. a MultiviewRenderTarget will have > 1)
   * @returns the view count
   */
  getViewCount() {
    return 1;
  }
};
RenderTargetTexture.REFRESHRATE_RENDER_ONCE = 0;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYFRAME = 1;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYTWOFRAMES = 2;
Texture._CreateRenderTargetTexture = (name6, renderTargetSize, scene, generateMipMaps, creationFlags) => {
  return new RenderTargetTexture(name6, renderTargetSize, scene, generateMipMaps);
};

// node_modules/@babylonjs/core/Shaders/passCube.fragment.js
var name3 = "passCubePixelShader";
var shader3 = `varying vec2 vUV;uniform samplerCube textureSampler;
#define CUSTOM_FRAGMENT_DEFINITIONS
void main(void) 
{vec2 uv=vUV*2.0-1.0;
#ifdef POSITIVEX
gl_FragColor=textureCube(textureSampler,vec3(1.001,uv.y,uv.x));
#endif
#ifdef NEGATIVEX
gl_FragColor=textureCube(textureSampler,vec3(-1.001,uv.y,uv.x));
#endif
#ifdef POSITIVEY
gl_FragColor=textureCube(textureSampler,vec3(uv.y,1.001,uv.x));
#endif
#ifdef NEGATIVEY
gl_FragColor=textureCube(textureSampler,vec3(uv.y,-1.001,uv.x));
#endif
#ifdef POSITIVEZ
gl_FragColor=textureCube(textureSampler,vec3(uv,1.001));
#endif
#ifdef NEGATIVEZ
gl_FragColor=textureCube(textureSampler,vec3(uv,-1.001));
#endif
}`;
ShaderStore.ShadersStore[name3] = shader3;

// node_modules/@babylonjs/core/PostProcesses/passPostProcess.js
var PassPostProcess = class _PassPostProcess extends PostProcess {
  /**
   * Gets a string identifying the name of the class
   * @returns "PassPostProcess" string
   */
  getClassName() {
    return "PassPostProcess";
  }
  /**
   * Creates the PassPostProcess
   * @param name The name of the effect.
   * @param options The required width/height ratio to downsize to before computing the render pass.
   * @param camera The camera to apply the render pass to.
   * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
   * @param engine The engine which the post process will be applied. (default: current engine)
   * @param reusable If the post process can be reused on the same frame. (default: false)
   * @param textureType The type of texture to be used when performing the post processing.
   * @param blockCompilation If compilation of the shader should not be done in the constructor. The updateEffect method can be used to compile the shader at a later time. (default: false)
   */
  constructor(name6, options, camera = null, samplingMode, engine, reusable, textureType = 0, blockCompilation = false) {
    super(name6, "pass", null, null, options, camera, samplingMode, engine, reusable, void 0, textureType, void 0, null, blockCompilation);
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PassPostProcess(parsedPostProcess.name, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable);
    }, parsedPostProcess, scene, rootUrl);
  }
};
RegisterClass("BABYLON.PassPostProcess", PassPostProcess);
var PassCubePostProcess = class _PassCubePostProcess extends PostProcess {
  /**
   * Gets or sets the cube face to display.
   *  * 0 is +X
   *  * 1 is -X
   *  * 2 is +Y
   *  * 3 is -Y
   *  * 4 is +Z
   *  * 5 is -Z
   */
  get face() {
    return this._face;
  }
  set face(value) {
    if (value < 0 || value > 5) {
      return;
    }
    this._face = value;
    switch (this._face) {
      case 0:
        this.updateEffect("#define POSITIVEX");
        break;
      case 1:
        this.updateEffect("#define NEGATIVEX");
        break;
      case 2:
        this.updateEffect("#define POSITIVEY");
        break;
      case 3:
        this.updateEffect("#define NEGATIVEY");
        break;
      case 4:
        this.updateEffect("#define POSITIVEZ");
        break;
      case 5:
        this.updateEffect("#define NEGATIVEZ");
        break;
    }
  }
  /**
   * Gets a string identifying the name of the class
   * @returns "PassCubePostProcess" string
   */
  getClassName() {
    return "PassCubePostProcess";
  }
  /**
   * Creates the PassCubePostProcess
   * @param name The name of the effect.
   * @param options The required width/height ratio to downsize to before computing the render pass.
   * @param camera The camera to apply the render pass to.
   * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
   * @param engine The engine which the post process will be applied. (default: current engine)
   * @param reusable If the post process can be reused on the same frame. (default: false)
   * @param textureType The type of texture to be used when performing the post processing.
   * @param blockCompilation If compilation of the shader should not be done in the constructor. The updateEffect method can be used to compile the shader at a later time. (default: false)
   */
  constructor(name6, options, camera = null, samplingMode, engine, reusable, textureType = 0, blockCompilation = false) {
    super(name6, "passCube", null, null, options, camera, samplingMode, engine, reusable, "#define POSITIVEX", textureType, void 0, null, blockCompilation);
    this._face = 0;
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PassCubePostProcess(parsedPostProcess.name, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable);
    }, parsedPostProcess, scene, rootUrl);
  }
};
Engine._RescalePostProcessFactory = (engine) => {
  return new PassPostProcess("rescale", 1, null, 2, engine, false, 0);
};

// node_modules/@babylonjs/core/Maths/sphericalPolynomial.js
var SH3ylmBasisConstants = [
  Math.sqrt(1 / (4 * Math.PI)),
  -Math.sqrt(3 / (4 * Math.PI)),
  Math.sqrt(3 / (4 * Math.PI)),
  -Math.sqrt(3 / (4 * Math.PI)),
  Math.sqrt(15 / (4 * Math.PI)),
  -Math.sqrt(15 / (4 * Math.PI)),
  Math.sqrt(5 / (16 * Math.PI)),
  -Math.sqrt(15 / (4 * Math.PI)),
  Math.sqrt(15 / (16 * Math.PI))
  // l22
];
var SH3ylmBasisTrigonometricTerms = [
  () => 1,
  (direction) => direction.y,
  (direction) => direction.z,
  (direction) => direction.x,
  (direction) => direction.x * direction.y,
  (direction) => direction.y * direction.z,
  (direction) => 3 * direction.z * direction.z - 1,
  (direction) => direction.x * direction.z,
  (direction) => direction.x * direction.x - direction.y * direction.y
  // l22
];
var applySH3 = (lm, direction) => {
  return SH3ylmBasisConstants[lm] * SH3ylmBasisTrigonometricTerms[lm](direction);
};
var SHCosKernelConvolution = [Math.PI, 2 * Math.PI / 3, 2 * Math.PI / 3, 2 * Math.PI / 3, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4];
var SphericalHarmonics = class _SphericalHarmonics {
  constructor() {
    this.preScaled = false;
    this.l00 = Vector3.Zero();
    this.l1_1 = Vector3.Zero();
    this.l10 = Vector3.Zero();
    this.l11 = Vector3.Zero();
    this.l2_2 = Vector3.Zero();
    this.l2_1 = Vector3.Zero();
    this.l20 = Vector3.Zero();
    this.l21 = Vector3.Zero();
    this.l22 = Vector3.Zero();
  }
  /**
   * Adds a light to the spherical harmonics
   * @param direction the direction of the light
   * @param color the color of the light
   * @param deltaSolidAngle the delta solid angle of the light
   */
  addLight(direction, color, deltaSolidAngle) {
    TmpVectors.Vector3[0].set(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    const c = TmpVectors.Vector3[1];
    colorVector.scaleToRef(deltaSolidAngle, c);
    c.scaleToRef(applySH3(0, direction), TmpVectors.Vector3[2]);
    this.l00.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(1, direction), TmpVectors.Vector3[2]);
    this.l1_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(2, direction), TmpVectors.Vector3[2]);
    this.l10.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(3, direction), TmpVectors.Vector3[2]);
    this.l11.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(4, direction), TmpVectors.Vector3[2]);
    this.l2_2.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(5, direction), TmpVectors.Vector3[2]);
    this.l2_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(6, direction), TmpVectors.Vector3[2]);
    this.l20.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(7, direction), TmpVectors.Vector3[2]);
    this.l21.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(8, direction), TmpVectors.Vector3[2]);
    this.l22.addInPlace(TmpVectors.Vector3[2]);
  }
  /**
   * Scales the spherical harmonics by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.l00.scaleInPlace(scale);
    this.l1_1.scaleInPlace(scale);
    this.l10.scaleInPlace(scale);
    this.l11.scaleInPlace(scale);
    this.l2_2.scaleInPlace(scale);
    this.l2_1.scaleInPlace(scale);
    this.l20.scaleInPlace(scale);
    this.l21.scaleInPlace(scale);
    this.l22.scaleInPlace(scale);
  }
  /**
   * Convert from incident radiance (Li) to irradiance (E) by applying convolution with the cosine-weighted hemisphere.
   *
   * ```
   * E_lm = A_l * L_lm
   * ```
   *
   * In spherical harmonics this convolution amounts to scaling factors for each frequency band.
   * This corresponds to equation 5 in "An Efficient Representation for Irradiance Environment Maps", where
   * the scaling factors are given in equation 9.
   */
  convertIncidentRadianceToIrradiance() {
    this.l00.scaleInPlace(SHCosKernelConvolution[0]);
    this.l1_1.scaleInPlace(SHCosKernelConvolution[1]);
    this.l10.scaleInPlace(SHCosKernelConvolution[2]);
    this.l11.scaleInPlace(SHCosKernelConvolution[3]);
    this.l2_2.scaleInPlace(SHCosKernelConvolution[4]);
    this.l2_1.scaleInPlace(SHCosKernelConvolution[5]);
    this.l20.scaleInPlace(SHCosKernelConvolution[6]);
    this.l21.scaleInPlace(SHCosKernelConvolution[7]);
    this.l22.scaleInPlace(SHCosKernelConvolution[8]);
  }
  /**
   * Convert from irradiance to outgoing radiance for Lambertian BDRF, suitable for efficient shader evaluation.
   *
   * ```
   * L = (1/pi) * E * rho
   * ```
   *
   * This is done by an additional scale by 1/pi, so is a fairly trivial operation but important conceptually.
   */
  convertIrradianceToLambertianRadiance() {
    this.scaleInPlace(1 / Math.PI);
  }
  /**
   * Integrates the reconstruction coefficients directly in to the SH preventing further
   * required operations at run time.
   *
   * This is simply done by scaling back the SH with Ylm constants parameter.
   * The trigonometric part being applied by the shader at run time.
   */
  preScaleForRendering() {
    this.preScaled = true;
    this.l00.scaleInPlace(SH3ylmBasisConstants[0]);
    this.l1_1.scaleInPlace(SH3ylmBasisConstants[1]);
    this.l10.scaleInPlace(SH3ylmBasisConstants[2]);
    this.l11.scaleInPlace(SH3ylmBasisConstants[3]);
    this.l2_2.scaleInPlace(SH3ylmBasisConstants[4]);
    this.l2_1.scaleInPlace(SH3ylmBasisConstants[5]);
    this.l20.scaleInPlace(SH3ylmBasisConstants[6]);
    this.l21.scaleInPlace(SH3ylmBasisConstants[7]);
    this.l22.scaleInPlace(SH3ylmBasisConstants[8]);
  }
  /**
   * update the spherical harmonics coefficients from the given array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromArray(data) {
    Vector3.FromArrayToRef(data[0], 0, this.l00);
    Vector3.FromArrayToRef(data[1], 0, this.l1_1);
    Vector3.FromArrayToRef(data[2], 0, this.l10);
    Vector3.FromArrayToRef(data[3], 0, this.l11);
    Vector3.FromArrayToRef(data[4], 0, this.l2_2);
    Vector3.FromArrayToRef(data[5], 0, this.l2_1);
    Vector3.FromArrayToRef(data[6], 0, this.l20);
    Vector3.FromArrayToRef(data[7], 0, this.l21);
    Vector3.FromArrayToRef(data[8], 0, this.l22);
    return this;
  }
  /**
   * update the spherical harmonics coefficients from the given floats array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromFloatsArray(data) {
    Vector3.FromFloatsToRef(data[0], data[1], data[2], this.l00);
    Vector3.FromFloatsToRef(data[3], data[4], data[5], this.l1_1);
    Vector3.FromFloatsToRef(data[6], data[7], data[8], this.l10);
    Vector3.FromFloatsToRef(data[9], data[10], data[11], this.l11);
    Vector3.FromFloatsToRef(data[12], data[13], data[14], this.l2_2);
    Vector3.FromFloatsToRef(data[15], data[16], data[17], this.l2_1);
    Vector3.FromFloatsToRef(data[18], data[19], data[20], this.l20);
    Vector3.FromFloatsToRef(data[21], data[22], data[23], this.l21);
    Vector3.FromFloatsToRef(data[24], data[25], data[26], this.l22);
    return this;
  }
  /**
   * Constructs a spherical harmonics from an array.
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics
   */
  static FromArray(data) {
    const sh = new _SphericalHarmonics();
    return sh.updateFromArray(data);
  }
  // Keep for references.
  /**
   * Gets the spherical harmonics from polynomial
   * @param polynomial the spherical polynomial
   * @returns the spherical harmonics
   */
  static FromPolynomial(polynomial) {
    const result = new _SphericalHarmonics();
    result.l00 = polynomial.xx.scale(0.376127).add(polynomial.yy.scale(0.376127)).add(polynomial.zz.scale(0.376126));
    result.l1_1 = polynomial.y.scale(0.977204);
    result.l10 = polynomial.z.scale(0.977204);
    result.l11 = polynomial.x.scale(0.977204);
    result.l2_2 = polynomial.xy.scale(1.16538);
    result.l2_1 = polynomial.yz.scale(1.16538);
    result.l20 = polynomial.zz.scale(1.34567).subtract(polynomial.xx.scale(0.672834)).subtract(polynomial.yy.scale(0.672834));
    result.l21 = polynomial.zx.scale(1.16538);
    result.l22 = polynomial.xx.scale(1.16538).subtract(polynomial.yy.scale(1.16538));
    result.l1_1.scaleInPlace(-1);
    result.l11.scaleInPlace(-1);
    result.l2_1.scaleInPlace(-1);
    result.l21.scaleInPlace(-1);
    result.scaleInPlace(Math.PI);
    return result;
  }
};
var SphericalPolynomial = class _SphericalPolynomial {
  constructor() {
    this.x = Vector3.Zero();
    this.y = Vector3.Zero();
    this.z = Vector3.Zero();
    this.xx = Vector3.Zero();
    this.yy = Vector3.Zero();
    this.zz = Vector3.Zero();
    this.xy = Vector3.Zero();
    this.yz = Vector3.Zero();
    this.zx = Vector3.Zero();
  }
  /**
   * The spherical harmonics used to create the polynomials.
   */
  get preScaledHarmonics() {
    if (!this._harmonics) {
      this._harmonics = SphericalHarmonics.FromPolynomial(this);
    }
    if (!this._harmonics.preScaled) {
      this._harmonics.preScaleForRendering();
    }
    return this._harmonics;
  }
  /**
   * Adds an ambient color to the spherical polynomial
   * @param color the color to add
   */
  addAmbient(color) {
    TmpVectors.Vector3[0].copyFromFloats(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    this.xx.addInPlace(colorVector);
    this.yy.addInPlace(colorVector);
    this.zz.addInPlace(colorVector);
  }
  /**
   * Scales the spherical polynomial by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.x.scaleInPlace(scale);
    this.y.scaleInPlace(scale);
    this.z.scaleInPlace(scale);
    this.xx.scaleInPlace(scale);
    this.yy.scaleInPlace(scale);
    this.zz.scaleInPlace(scale);
    this.yz.scaleInPlace(scale);
    this.zx.scaleInPlace(scale);
    this.xy.scaleInPlace(scale);
  }
  /**
   * Updates the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  updateFromHarmonics(harmonics) {
    this._harmonics = harmonics;
    this.x.copyFrom(harmonics.l11);
    this.x.scaleInPlace(1.02333).scaleInPlace(-1);
    this.y.copyFrom(harmonics.l1_1);
    this.y.scaleInPlace(1.02333).scaleInPlace(-1);
    this.z.copyFrom(harmonics.l10);
    this.z.scaleInPlace(1.02333);
    this.xx.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.247708);
    TmpVectors.Vector3[1].copyFrom(harmonics.l22).scaleInPlace(0.429043);
    this.xx.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).addInPlace(TmpVectors.Vector3[1]);
    this.yy.copyFrom(harmonics.l00);
    this.yy.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).subtractInPlace(TmpVectors.Vector3[1]);
    this.zz.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.495417);
    this.zz.scaleInPlace(0.886277).addInPlace(TmpVectors.Vector3[0]);
    this.yz.copyFrom(harmonics.l2_1);
    this.yz.scaleInPlace(0.858086).scaleInPlace(-1);
    this.zx.copyFrom(harmonics.l21);
    this.zx.scaleInPlace(0.858086).scaleInPlace(-1);
    this.xy.copyFrom(harmonics.l2_2);
    this.xy.scaleInPlace(0.858086);
    this.scaleInPlace(1 / Math.PI);
    return this;
  }
  /**
   * Gets the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  static FromHarmonics(harmonics) {
    const result = new _SphericalPolynomial();
    return result.updateFromHarmonics(harmonics);
  }
  /**
   * Constructs a spherical polynomial from an array.
   * @param data defines the 9x3 coefficients (x, y, z, xx, yy, zz, yz, zx, xy)
   * @returns the spherical polynomial
   */
  static FromArray(data) {
    const sp = new _SphericalPolynomial();
    Vector3.FromArrayToRef(data[0], 0, sp.x);
    Vector3.FromArrayToRef(data[1], 0, sp.y);
    Vector3.FromArrayToRef(data[2], 0, sp.z);
    Vector3.FromArrayToRef(data[3], 0, sp.xx);
    Vector3.FromArrayToRef(data[4], 0, sp.yy);
    Vector3.FromArrayToRef(data[5], 0, sp.zz);
    Vector3.FromArrayToRef(data[6], 0, sp.yz);
    Vector3.FromArrayToRef(data[7], 0, sp.zx);
    Vector3.FromArrayToRef(data[8], 0, sp.xy);
    return sp;
  }
};

// node_modules/@babylonjs/core/Misc/textureTools.js
function CreateResizedCopy(texture, width, height, useBilinearMode = true) {
  const scene = texture.getScene();
  const engine = scene.getEngine();
  const rtt = new RenderTargetTexture("resized" + texture.name, { width, height }, scene, !texture.noMipmap, true, texture._texture.type, false, texture.samplingMode, false);
  rtt.wrapU = texture.wrapU;
  rtt.wrapV = texture.wrapV;
  rtt.uOffset = texture.uOffset;
  rtt.vOffset = texture.vOffset;
  rtt.uScale = texture.uScale;
  rtt.vScale = texture.vScale;
  rtt.uAng = texture.uAng;
  rtt.vAng = texture.vAng;
  rtt.wAng = texture.wAng;
  rtt.coordinatesIndex = texture.coordinatesIndex;
  rtt.level = texture.level;
  rtt.anisotropicFilteringLevel = texture.anisotropicFilteringLevel;
  rtt._texture.isReady = false;
  texture.wrapU = Texture.CLAMP_ADDRESSMODE;
  texture.wrapV = Texture.CLAMP_ADDRESSMODE;
  const passPostProcess = new PassPostProcess("pass", 1, null, useBilinearMode ? Texture.BILINEAR_SAMPLINGMODE : Texture.NEAREST_SAMPLINGMODE, engine, false, 0);
  passPostProcess.externalTextureSamplerBinding = true;
  passPostProcess.getEffect().executeWhenCompiled(() => {
    passPostProcess.onApply = function(effect) {
      effect.setTexture("textureSampler", texture);
    };
    const internalTexture = rtt.renderTarget;
    if (internalTexture) {
      scene.postProcessManager.directRender([passPostProcess], internalTexture);
      engine.unBindFramebuffer(internalTexture);
      rtt.disposeFramebufferObjects();
      passPostProcess.dispose();
      rtt.getInternalTexture().isReady = true;
    }
  });
  return rtt;
}
function ApplyPostProcess(postProcessName, internalTexture, scene, type, samplingMode, format, width, height) {
  const engine = internalTexture.getEngine();
  internalTexture.isReady = false;
  samplingMode = samplingMode ?? internalTexture.samplingMode;
  type = type ?? internalTexture.type;
  format = format ?? internalTexture.format;
  width = width ?? internalTexture.width;
  height = height ?? internalTexture.height;
  if (type === -1) {
    type = 0;
  }
  return new Promise((resolve) => {
    const postProcess = new PostProcess("postprocess", postProcessName, null, null, 1, null, samplingMode, engine, false, void 0, type, void 0, null, false, format);
    postProcess.externalTextureSamplerBinding = true;
    const encodedTexture = engine.createRenderTargetTexture({ width, height }, {
      generateDepthBuffer: false,
      generateMipMaps: false,
      generateStencilBuffer: false,
      samplingMode,
      type,
      format
    });
    postProcess.getEffect().executeWhenCompiled(() => {
      postProcess.onApply = (effect) => {
        effect._bindTexture("textureSampler", internalTexture);
        effect.setFloat2("scale", 1, 1);
      };
      scene.postProcessManager.directRender([postProcess], encodedTexture, true);
      engine.restoreDefaultFramebuffer();
      engine._releaseTexture(internalTexture);
      if (postProcess) {
        postProcess.dispose();
      }
      encodedTexture._swapAndDie(internalTexture);
      internalTexture.type = type;
      internalTexture.format = 5;
      internalTexture.isReady = true;
      resolve(internalTexture);
    });
  });
}
var floatView;
var int32View;
function ToHalfFloat(value) {
  if (!floatView) {
    floatView = new Float32Array(1);
    int32View = new Int32Array(floatView.buffer);
  }
  floatView[0] = value;
  const x = int32View[0];
  let bits = x >> 16 & 32768;
  let m = x >> 12 & 2047;
  const e = x >> 23 & 255;
  if (e < 103) {
    return bits;
  }
  if (e > 142) {
    bits |= 31744;
    bits |= (e == 255 ? 0 : 1) && x & 8388607;
    return bits;
  }
  if (e < 113) {
    m |= 2048;
    bits |= (m >> 114 - e) + (m >> 113 - e & 1);
    return bits;
  }
  bits |= e - 112 << 10 | m >> 1;
  bits += m & 1;
  return bits;
}
function FromHalfFloat(value) {
  const s = (value & 32768) >> 15;
  const e = (value & 31744) >> 10;
  const f = value & 1023;
  if (e === 0) {
    return (s ? -1 : 1) * Math.pow(2, -14) * (f / Math.pow(2, 10));
  } else if (e == 31) {
    return f ? NaN : (s ? -1 : 1) * Infinity;
  }
  return (s ? -1 : 1) * Math.pow(2, e - 15) * (1 + f / Math.pow(2, 10));
}
var ProcessAsync = async (texture, width, height, face, lod) => {
  const scene = texture.getScene();
  const engine = scene.getEngine();
  let lodPostProcess;
  if (!texture.isCube) {
    lodPostProcess = new PostProcess("lod", "lod", ["lod", "gamma"], null, 1, null, Texture.NEAREST_NEAREST_MIPNEAREST, engine);
  } else {
    const faceDefines = ["#define POSITIVEX", "#define NEGATIVEX", "#define POSITIVEY", "#define NEGATIVEY", "#define POSITIVEZ", "#define NEGATIVEZ"];
    lodPostProcess = new PostProcess("lodCube", "lodCube", ["lod", "gamma"], null, 1, null, Texture.NEAREST_NEAREST_MIPNEAREST, engine, false, faceDefines[face]);
  }
  await new Promise((resolve) => {
    lodPostProcess.getEffect().executeWhenCompiled(() => {
      resolve(0);
    });
  });
  const rtt = new RenderTargetTexture("temp", { width, height }, scene, false);
  lodPostProcess.onApply = function(effect) {
    effect.setTexture("textureSampler", texture);
    effect.setFloat("lod", lod);
    effect.setBool("gamma", texture.gammaSpace);
  };
  const internalTexture = texture.getInternalTexture();
  try {
    if (rtt.renderTarget && internalTexture) {
      const samplingMode = internalTexture.samplingMode;
      if (lod !== 0) {
        texture.updateSamplingMode(Texture.NEAREST_NEAREST_MIPNEAREST);
      } else {
        texture.updateSamplingMode(Texture.NEAREST_NEAREST);
      }
      scene.postProcessManager.directRender([lodPostProcess], rtt.renderTarget, true);
      texture.updateSamplingMode(samplingMode);
      const bufferView = await engine.readPixels(0, 0, width, height);
      const data = new Uint8Array(bufferView.buffer, 0, bufferView.byteLength);
      engine.unBindFramebuffer(rtt.renderTarget);
      return data;
    } else {
      throw Error("Render to texture failed.");
    }
  } finally {
    rtt.dispose();
    lodPostProcess.dispose();
  }
};
async function GetTextureDataAsync(texture, width, height, face = 0, lod = 0) {
  if (!texture.isReady() && texture._texture) {
    await new Promise((resolve, reject) => {
      if (texture._texture === null) {
        reject(0);
        return;
      }
      texture._texture.onLoadedObservable.addOnce(() => {
        resolve(0);
      });
    });
  }
  return await ProcessAsync(texture, width, height, face, lod);
}
var TextureTools = {
  /**
   * Uses the GPU to create a copy texture rescaled at a given size
   * @param texture Texture to copy from
   * @param width defines the desired width
   * @param height defines the desired height
   * @param useBilinearMode defines if bilinear mode has to be used
   * @returns the generated texture
   */
  CreateResizedCopy,
  /**
   * Apply a post process to a texture
   * @param postProcessName name of the fragment post process
   * @param internalTexture the texture to encode
   * @param scene the scene hosting the texture
   * @param type type of the output texture. If not provided, use the one from internalTexture
   * @param samplingMode sampling mode to use to sample the source texture. If not provided, use the one from internalTexture
   * @param format format of the output texture. If not provided, use the one from internalTexture
   * @returns a promise with the internalTexture having its texture replaced by the result of the processing
   */
  ApplyPostProcess,
  /**
   * Converts a number to half float
   * @param value number to convert
   * @returns converted number
   */
  ToHalfFloat,
  /**
   * Converts a half float to a number
   * @param value half float to convert
   * @returns converted half float
   */
  FromHalfFloat,
  /**
   * Gets the data of the specified texture by rendering it to an intermediate RGBA texture and retrieving the bytes from it.
   * This is convienent to get 8-bit RGBA values for a texture in a GPU compressed format.
   * @param texture the source texture
   * @param width the width of the result, which does not have to match the source texture width
   * @param height the height of the result, which does not have to match the source texture height
   * @param face if the texture has multiple faces, the face index to use for the source
   * @param channels a filter for which of the RGBA channels to return in the result
   * @param lod if the texture has multiple LODs, the lod index to use for the source
   * @returns the 8-bit texture data
   */
  GetTextureDataAsync
};

// node_modules/@babylonjs/core/Shaders/rgbdDecode.fragment.js
var name4 = "rgbdDecodePixelShader";
var shader4 = `varying vec2 vUV;uniform sampler2D textureSampler;
#include<helperFunctions>
#define CUSTOM_FRAGMENT_DEFINITIONS
void main(void) 
{gl_FragColor=vec4(fromRGBD(texture2D(textureSampler,vUV)),1.0);}`;
ShaderStore.ShadersStore[name4] = shader4;

// node_modules/@babylonjs/core/Misc/rgbdTextureTools.js
var RGBDTextureTools = class {
  /**
   * Expand the RGBD Texture from RGBD to Half Float if possible.
   * @param texture the texture to expand.
   */
  static ExpandRGBDTexture(texture) {
    const internalTexture = texture._texture;
    if (!internalTexture || !texture.isRGBD) {
      return;
    }
    const engine = internalTexture.getEngine();
    const caps = engine.getCaps();
    const isReady = internalTexture.isReady;
    let expandTexture = false;
    if (caps.textureHalfFloatRender && caps.textureHalfFloatLinearFiltering) {
      expandTexture = true;
      internalTexture.type = 2;
    } else if (caps.textureFloatRender && caps.textureFloatLinearFiltering) {
      expandTexture = true;
      internalTexture.type = 1;
    }
    if (expandTexture) {
      internalTexture.isReady = false;
      internalTexture._isRGBD = false;
      internalTexture.invertY = false;
    }
    const expandRGBDTexture = () => {
      const rgbdPostProcess = new PostProcess("rgbdDecode", "rgbdDecode", null, null, 1, null, 3, engine, false, void 0, internalTexture.type, void 0, null, false);
      rgbdPostProcess.externalTextureSamplerBinding = true;
      const expandedTexture = engine.createRenderTargetTexture(internalTexture.width, {
        generateDepthBuffer: false,
        generateMipMaps: false,
        generateStencilBuffer: false,
        samplingMode: internalTexture.samplingMode,
        type: internalTexture.type,
        format: 5
      });
      rgbdPostProcess.getEffect().executeWhenCompiled(() => {
        rgbdPostProcess.onApply = (effect) => {
          effect._bindTexture("textureSampler", internalTexture);
          effect.setFloat2("scale", 1, 1);
        };
        texture.getScene().postProcessManager.directRender([rgbdPostProcess], expandedTexture, true);
        engine.restoreDefaultFramebuffer();
        engine._releaseTexture(internalTexture);
        if (rgbdPostProcess) {
          rgbdPostProcess.dispose();
        }
        expandedTexture._swapAndDie(internalTexture);
        internalTexture.isReady = true;
      });
    };
    if (expandTexture) {
      if (isReady) {
        expandRGBDTexture();
      } else {
        texture.onLoadObservable.addOnce(expandRGBDTexture);
      }
    }
  }
  /**
   * Encode the texture to RGBD if possible.
   * @param internalTexture the texture to encode
   * @param scene the scene hosting the texture
   * @param outputTextureType type of the texture in which the encoding is performed
   * @returns a promise with the internalTexture having its texture replaced by the result of the processing
   */
  static EncodeTextureToRGBD(internalTexture, scene, outputTextureType = 0) {
    return ApplyPostProcess("rgbdEncode", internalTexture, scene, outputTextureType, 1, 5);
  }
};

// node_modules/@babylonjs/core/Misc/HighDynamicRange/cubemapToSphericalPolynomial.js
var FileFaceOrientation = class {
  constructor(name6, worldAxisForNormal, worldAxisForFileX, worldAxisForFileY) {
    this.name = name6;
    this.worldAxisForNormal = worldAxisForNormal;
    this.worldAxisForFileX = worldAxisForFileX;
    this.worldAxisForFileY = worldAxisForFileY;
  }
};
var CubeMapToSphericalPolynomialTools = class {
  /**
   * Converts a texture to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param texture The texture to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapTextureToSphericalPolynomial(texture) {
    var _a;
    if (!texture.isCube) {
      return null;
    }
    (_a = texture.getScene()) == null ? void 0 : _a.getEngine().flushFramebuffer();
    const size = texture.getSize().width;
    const rightPromise = texture.readPixels(0, void 0, void 0, false);
    const leftPromise = texture.readPixels(1, void 0, void 0, false);
    let upPromise;
    let downPromise;
    if (texture.isRenderTarget) {
      upPromise = texture.readPixels(3, void 0, void 0, false);
      downPromise = texture.readPixels(2, void 0, void 0, false);
    } else {
      upPromise = texture.readPixels(2, void 0, void 0, false);
      downPromise = texture.readPixels(3, void 0, void 0, false);
    }
    const frontPromise = texture.readPixels(4, void 0, void 0, false);
    const backPromise = texture.readPixels(5, void 0, void 0, false);
    const gammaSpace = texture.gammaSpace;
    const format = 5;
    let type = 0;
    if (texture.textureType == 1 || texture.textureType == 2) {
      type = 1;
    }
    return new Promise((resolve) => {
      Promise.all([leftPromise, rightPromise, upPromise, downPromise, frontPromise, backPromise]).then(([left, right, up, down, front, back]) => {
        const cubeInfo = {
          size,
          right,
          left,
          up,
          down,
          front,
          back,
          format,
          type,
          gammaSpace
        };
        resolve(this.ConvertCubeMapToSphericalPolynomial(cubeInfo));
      });
    });
  }
  /**
   * Compute the area on the unit sphere of the rectangle defined by (x,y) and the origin
   * See https://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/
   * @param x
   * @param y
   * @returns the area
   */
  static _AreaElement(x, y) {
    return Math.atan2(x * y, Math.sqrt(x * x + y * y + 1));
  }
  /**
   * Converts a cubemap to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param cubeInfo The Cube map to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapToSphericalPolynomial(cubeInfo) {
    const sphericalHarmonics = new SphericalHarmonics();
    let totalSolidAngle = 0;
    const du = 2 / cubeInfo.size;
    const dv = du;
    const halfTexel = 0.5 * du;
    const minUV = halfTexel - 1;
    for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
      const fileFace = this._FileFaces[faceIndex];
      const dataArray = cubeInfo[fileFace.name];
      let v = minUV;
      const stride = cubeInfo.format === 5 ? 4 : 3;
      for (let y = 0; y < cubeInfo.size; y++) {
        let u = minUV;
        for (let x = 0; x < cubeInfo.size; x++) {
          const worldDirection = fileFace.worldAxisForFileX.scale(u).add(fileFace.worldAxisForFileY.scale(v)).add(fileFace.worldAxisForNormal);
          worldDirection.normalize();
          const deltaSolidAngle = this._AreaElement(u - halfTexel, v - halfTexel) - this._AreaElement(u - halfTexel, v + halfTexel) - this._AreaElement(u + halfTexel, v - halfTexel) + this._AreaElement(u + halfTexel, v + halfTexel);
          let r = dataArray[y * cubeInfo.size * stride + x * stride + 0];
          let g = dataArray[y * cubeInfo.size * stride + x * stride + 1];
          let b = dataArray[y * cubeInfo.size * stride + x * stride + 2];
          if (isNaN(r)) {
            r = 0;
          }
          if (isNaN(g)) {
            g = 0;
          }
          if (isNaN(b)) {
            b = 0;
          }
          if (cubeInfo.type === 0) {
            r /= 255;
            g /= 255;
            b /= 255;
          }
          if (cubeInfo.gammaSpace) {
            r = Math.pow(Scalar.Clamp(r), ToLinearSpace);
            g = Math.pow(Scalar.Clamp(g), ToLinearSpace);
            b = Math.pow(Scalar.Clamp(b), ToLinearSpace);
          }
          const max = this.MAX_HDRI_VALUE;
          if (this.PRESERVE_CLAMPED_COLORS) {
            const currentMax = Math.max(r, g, b);
            if (currentMax > max) {
              const factor = max / currentMax;
              r *= factor;
              g *= factor;
              b *= factor;
            }
          } else {
            r = Scalar.Clamp(r, 0, max);
            g = Scalar.Clamp(g, 0, max);
            b = Scalar.Clamp(b, 0, max);
          }
          const color = new Color3(r, g, b);
          sphericalHarmonics.addLight(worldDirection, color, deltaSolidAngle);
          totalSolidAngle += deltaSolidAngle;
          u += du;
        }
        v += dv;
      }
    }
    const sphereSolidAngle = 4 * Math.PI;
    const facesProcessed = 6;
    const expectedSolidAngle = sphereSolidAngle * facesProcessed / 6;
    const correctionFactor = expectedSolidAngle / totalSolidAngle;
    sphericalHarmonics.scaleInPlace(correctionFactor);
    sphericalHarmonics.convertIncidentRadianceToIrradiance();
    sphericalHarmonics.convertIrradianceToLambertianRadiance();
    return SphericalPolynomial.FromHarmonics(sphericalHarmonics);
  }
};
CubeMapToSphericalPolynomialTools._FileFaces = [
  new FileFaceOrientation("right", new Vector3(1, 0, 0), new Vector3(0, 0, -1), new Vector3(0, -1, 0)),
  new FileFaceOrientation("left", new Vector3(-1, 0, 0), new Vector3(0, 0, 1), new Vector3(0, -1, 0)),
  new FileFaceOrientation("up", new Vector3(0, 1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, 1)),
  new FileFaceOrientation("down", new Vector3(0, -1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, -1)),
  new FileFaceOrientation("front", new Vector3(0, 0, 1), new Vector3(1, 0, 0), new Vector3(0, -1, 0)),
  new FileFaceOrientation("back", new Vector3(0, 0, -1), new Vector3(-1, 0, 0), new Vector3(0, -1, 0))
  // -Z bottom
];
CubeMapToSphericalPolynomialTools.MAX_HDRI_VALUE = 4096;
CubeMapToSphericalPolynomialTools.PRESERVE_CLAMPED_COLORS = false;

// node_modules/@babylonjs/core/Materials/Textures/baseTexture.polynomial.js
BaseTexture.prototype.forceSphericalPolynomialsRecompute = function() {
  if (this._texture) {
    this._texture._sphericalPolynomial = null;
    this._texture._sphericalPolynomialPromise = null;
    this._texture._sphericalPolynomialComputed = false;
  }
};
Object.defineProperty(BaseTexture.prototype, "sphericalPolynomial", {
  get: function() {
    if (this._texture) {
      if (this._texture._sphericalPolynomial || this._texture._sphericalPolynomialComputed) {
        return this._texture._sphericalPolynomial;
      }
      if (this._texture.isReady) {
        if (!this._texture._sphericalPolynomialPromise) {
          this._texture._sphericalPolynomialPromise = CubeMapToSphericalPolynomialTools.ConvertCubeMapTextureToSphericalPolynomial(this);
          if (this._texture._sphericalPolynomialPromise === null) {
            this._texture._sphericalPolynomialComputed = true;
          } else {
            this._texture._sphericalPolynomialPromise.then((sphericalPolynomial) => {
              this._texture._sphericalPolynomial = sphericalPolynomial;
              this._texture._sphericalPolynomialComputed = true;
            });
          }
        }
        return null;
      }
    }
    return null;
  },
  set: function(value) {
    if (this._texture) {
      this._texture._sphericalPolynomial = value;
    }
  },
  enumerable: true,
  configurable: true
});

// node_modules/@babylonjs/core/Shaders/rgbdEncode.fragment.js
var name5 = "rgbdEncodePixelShader";
var shader5 = `varying vec2 vUV;uniform sampler2D textureSampler;
#include<helperFunctions>
#define CUSTOM_FRAGMENT_DEFINITIONS
void main(void) 
{gl_FragColor=toRGBD(texture2D(textureSampler,vUV).rgb);}`;
ShaderStore.ShadersStore[name5] = shader5;

// node_modules/@babylonjs/core/Misc/environmentTextureTools.js
var DefaultEnvironmentTextureImageType = "image/png";
var CurrentVersion = 2;
var MagicBytes = [134, 22, 135, 150, 246, 214, 150, 54];
function GetEnvInfo(data) {
  const dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);
  let pos = 0;
  for (let i = 0; i < MagicBytes.length; i++) {
    if (dataView.getUint8(pos++) !== MagicBytes[i]) {
      Logger.Error("Not a babylon environment map");
      return null;
    }
  }
  let manifestString = "";
  let charCode = 0;
  while (charCode = dataView.getUint8(pos++)) {
    manifestString += String.fromCharCode(charCode);
  }
  let manifest = JSON.parse(manifestString);
  manifest = normalizeEnvInfo(manifest);
  if (manifest.specular) {
    manifest.specular.specularDataPosition = pos;
    manifest.specular.lodGenerationScale = manifest.specular.lodGenerationScale || 0.8;
  }
  return manifest;
}
function normalizeEnvInfo(info) {
  if (info.version > CurrentVersion) {
    throw new Error(`Unsupported babylon environment map version "${info.version}". Latest supported version is "${CurrentVersion}".`);
  }
  if (info.version === 2) {
    return info;
  }
  info = { ...info, version: 2, imageType: DefaultEnvironmentTextureImageType };
  return info;
}
async function CreateEnvTextureAsync(texture, options = {}) {
  var _a;
  const internalTexture = texture.getInternalTexture();
  if (!internalTexture) {
    return Promise.reject("The cube texture is invalid.");
  }
  const imageType = options.imageType ?? DefaultEnvironmentTextureImageType;
  const engine = internalTexture.getEngine();
  if (texture.textureType !== 2 && texture.textureType !== 1 && texture.textureType !== 0 && texture.textureType !== 0 && texture.textureType !== 7 && texture.textureType !== -1) {
    return Promise.reject("The cube texture should allow HDR (Full Float or Half Float).");
  }
  let textureType = 1;
  if (!engine.getCaps().textureFloatRender) {
    textureType = 2;
    if (!engine.getCaps().textureHalfFloatRender) {
      return Promise.reject("Env texture can only be created when the browser supports half float or full float rendering.");
    }
  }
  texture.sphericalPolynomial;
  const sphericalPolynomialPromise = (_a = texture.getInternalTexture()) == null ? void 0 : _a._sphericalPolynomialPromise;
  const cubeWidth = internalTexture.width;
  const hostingScene = new Scene(engine);
  const specularTextures = {};
  engine.flushFramebuffer();
  const mipmapsCount = Scalar.ILog2(internalTexture.width);
  for (let i = 0; i <= mipmapsCount; i++) {
    const faceWidth = Math.pow(2, mipmapsCount - i);
    for (let face = 0; face < 6; face++) {
      let faceData = await texture.readPixels(face, i, void 0, false);
      if (faceData && faceData.byteLength === faceData.length) {
        const faceDataFloat = new Float32Array(faceData.byteLength * 4);
        for (let i2 = 0; i2 < faceData.byteLength; i2++) {
          faceDataFloat[i2] = faceData[i2] / 255;
          faceDataFloat[i2] = Math.pow(faceDataFloat[i2], 2.2);
        }
        faceData = faceDataFloat;
      } else if (faceData && texture.gammaSpace) {
        const floatData = faceData;
        for (let i2 = 0; i2 < floatData.length; i2++) {
          floatData[i2] = Math.pow(floatData[i2], 2.2);
        }
      }
      const tempTexture = engine.createRawTexture(faceData, faceWidth, faceWidth, 5, false, true, 1, null, textureType);
      await RGBDTextureTools.EncodeTextureToRGBD(tempTexture, hostingScene, textureType);
      const rgbdEncodedData = await engine._readTexturePixels(tempTexture, faceWidth, faceWidth);
      const imageEncodedData = await DumpTools.DumpDataAsync(faceWidth, faceWidth, rgbdEncodedData, imageType, void 0, false, true, options.imageQuality);
      specularTextures[i * 6 + face] = imageEncodedData;
      tempTexture.dispose();
    }
  }
  hostingScene.dispose();
  if (sphericalPolynomialPromise) {
    await sphericalPolynomialPromise;
  }
  const info = {
    version: CurrentVersion,
    width: cubeWidth,
    imageType,
    irradiance: _CreateEnvTextureIrradiance(texture),
    specular: {
      mipmaps: [],
      lodGenerationScale: texture.lodGenerationScale
    }
  };
  let position = 0;
  for (let i = 0; i <= mipmapsCount; i++) {
    for (let face = 0; face < 6; face++) {
      const byteLength = specularTextures[i * 6 + face].byteLength;
      info.specular.mipmaps.push({
        length: byteLength,
        position
      });
      position += byteLength;
    }
  }
  const infoString = JSON.stringify(info);
  const infoBuffer = new ArrayBuffer(infoString.length + 1);
  const infoView = new Uint8Array(infoBuffer);
  for (let i = 0, strLen = infoString.length; i < strLen; i++) {
    infoView[i] = infoString.charCodeAt(i);
  }
  infoView[infoString.length] = 0;
  const totalSize = MagicBytes.length + position + infoBuffer.byteLength;
  const finalBuffer = new ArrayBuffer(totalSize);
  const finalBufferView = new Uint8Array(finalBuffer);
  const dataView = new DataView(finalBuffer);
  let pos = 0;
  for (let i = 0; i < MagicBytes.length; i++) {
    dataView.setUint8(pos++, MagicBytes[i]);
  }
  finalBufferView.set(new Uint8Array(infoBuffer), pos);
  pos += infoBuffer.byteLength;
  for (let i = 0; i <= mipmapsCount; i++) {
    for (let face = 0; face < 6; face++) {
      const dataBuffer = specularTextures[i * 6 + face];
      finalBufferView.set(new Uint8Array(dataBuffer), pos);
      pos += dataBuffer.byteLength;
    }
  }
  return finalBuffer;
}
function _CreateEnvTextureIrradiance(texture) {
  const polynmials = texture.sphericalPolynomial;
  if (polynmials == null) {
    return null;
  }
  return {
    x: [polynmials.x.x, polynmials.x.y, polynmials.x.z],
    y: [polynmials.y.x, polynmials.y.y, polynmials.y.z],
    z: [polynmials.z.x, polynmials.z.y, polynmials.z.z],
    xx: [polynmials.xx.x, polynmials.xx.y, polynmials.xx.z],
    yy: [polynmials.yy.x, polynmials.yy.y, polynmials.yy.z],
    zz: [polynmials.zz.x, polynmials.zz.y, polynmials.zz.z],
    yz: [polynmials.yz.x, polynmials.yz.y, polynmials.yz.z],
    zx: [polynmials.zx.x, polynmials.zx.y, polynmials.zx.z],
    xy: [polynmials.xy.x, polynmials.xy.y, polynmials.xy.z]
  };
}
function CreateImageDataArrayBufferViews(data, info) {
  info = normalizeEnvInfo(info);
  const specularInfo = info.specular;
  let mipmapsCount = Scalar.Log2(info.width);
  mipmapsCount = Math.round(mipmapsCount) + 1;
  if (specularInfo.mipmaps.length !== 6 * mipmapsCount) {
    throw new Error(`Unsupported specular mipmaps number "${specularInfo.mipmaps.length}"`);
  }
  const imageData = new Array(mipmapsCount);
  for (let i = 0; i < mipmapsCount; i++) {
    imageData[i] = new Array(6);
    for (let face = 0; face < 6; face++) {
      const imageInfo = specularInfo.mipmaps[i * 6 + face];
      imageData[i][face] = new Uint8Array(data.buffer, data.byteOffset + specularInfo.specularDataPosition + imageInfo.position, imageInfo.length);
    }
  }
  return imageData;
}
function UploadEnvLevelsAsync(texture, data, info) {
  info = normalizeEnvInfo(info);
  const specularInfo = info.specular;
  if (!specularInfo) {
    return Promise.resolve();
  }
  texture._lodGenerationScale = specularInfo.lodGenerationScale;
  const imageData = CreateImageDataArrayBufferViews(data, info);
  return UploadLevelsAsync(texture, imageData, info.imageType);
}
function _OnImageReadyAsync(image, engine, expandTexture, rgbdPostProcess, url, face, i, generateNonLODTextures, lodTextures, cubeRtt, texture) {
  return new Promise((resolve, reject) => {
    if (expandTexture) {
      const tempTexture = engine.createTexture(null, true, true, null, 1, null, (message) => {
        reject(message);
      }, image);
      rgbdPostProcess.getEffect().executeWhenCompiled(() => {
        rgbdPostProcess.externalTextureSamplerBinding = true;
        rgbdPostProcess.onApply = (effect) => {
          effect._bindTexture("textureSampler", tempTexture);
          effect.setFloat2("scale", 1, engine._features.needsInvertingBitmap && image instanceof ImageBitmap ? -1 : 1);
        };
        if (!engine.scenes.length) {
          return;
        }
        engine.scenes[0].postProcessManager.directRender([rgbdPostProcess], cubeRtt, true, face, i);
        engine.restoreDefaultFramebuffer();
        tempTexture.dispose();
        URL.revokeObjectURL(url);
        resolve();
      });
    } else {
      engine._uploadImageToTexture(texture, image, face, i);
      if (generateNonLODTextures) {
        const lodTexture = lodTextures[i];
        if (lodTexture) {
          engine._uploadImageToTexture(lodTexture._texture, image, face, 0);
        }
      }
      resolve();
    }
  });
}
function UploadLevelsAsync(texture, imageData, imageType = DefaultEnvironmentTextureImageType) {
  if (!Tools.IsExponentOfTwo(texture.width)) {
    throw new Error("Texture size must be a power of two");
  }
  const mipmapsCount = Scalar.ILog2(texture.width) + 1;
  const engine = texture.getEngine();
  let expandTexture = false;
  let generateNonLODTextures = false;
  let rgbdPostProcess = null;
  let cubeRtt = null;
  let lodTextures = null;
  const caps = engine.getCaps();
  texture.format = 5;
  texture.type = 0;
  texture.generateMipMaps = true;
  texture._cachedAnisotropicFilteringLevel = null;
  engine.updateTextureSamplingMode(3, texture);
  if (!caps.textureLOD) {
    expandTexture = false;
    generateNonLODTextures = true;
    lodTextures = {};
  } else if (!engine._features.supportRenderAndCopyToLodForFloatTextures) {
    expandTexture = false;
  } else if (caps.textureHalfFloatRender && caps.textureHalfFloatLinearFiltering) {
    expandTexture = true;
    texture.type = 2;
  } else if (caps.textureFloatRender && caps.textureFloatLinearFiltering) {
    expandTexture = true;
    texture.type = 1;
  }
  if (expandTexture) {
    rgbdPostProcess = new PostProcess("rgbdDecode", "rgbdDecode", null, null, 1, null, 3, engine, false, void 0, texture.type, void 0, null, false);
    texture._isRGBD = false;
    texture.invertY = false;
    cubeRtt = engine.createRenderTargetCubeTexture(texture.width, {
      generateDepthBuffer: false,
      generateMipMaps: true,
      generateStencilBuffer: false,
      samplingMode: 3,
      type: texture.type,
      format: 5
    });
  } else {
    texture._isRGBD = true;
    texture.invertY = true;
    if (generateNonLODTextures) {
      const mipSlices = 3;
      const scale = texture._lodGenerationScale;
      const offset = texture._lodGenerationOffset;
      for (let i = 0; i < mipSlices; i++) {
        const smoothness = i / (mipSlices - 1);
        const roughness = 1 - smoothness;
        const minLODIndex = offset;
        const maxLODIndex = (mipmapsCount - 1) * scale + offset;
        const lodIndex = minLODIndex + (maxLODIndex - minLODIndex) * roughness;
        const mipmapIndex = Math.round(Math.min(Math.max(lodIndex, 0), maxLODIndex));
        const glTextureFromLod = new InternalTexture(engine, InternalTextureSource.Temp);
        glTextureFromLod.isCube = true;
        glTextureFromLod.invertY = true;
        glTextureFromLod.generateMipMaps = false;
        engine.updateTextureSamplingMode(2, glTextureFromLod);
        const lodTexture = new BaseTexture(null);
        lodTexture._isCube = true;
        lodTexture._texture = glTextureFromLod;
        lodTextures[mipmapIndex] = lodTexture;
        switch (i) {
          case 0:
            texture._lodTextureLow = lodTexture;
            break;
          case 1:
            texture._lodTextureMid = lodTexture;
            break;
          case 2:
            texture._lodTextureHigh = lodTexture;
            break;
        }
      }
    }
  }
  const promises = [];
  for (let i = 0; i < imageData.length; i++) {
    for (let face = 0; face < 6; face++) {
      const bytes = imageData[i][face];
      const blob = new Blob([bytes], { type: imageType });
      const url = URL.createObjectURL(blob);
      let promise;
      if (engine._features.forceBitmapOverHTMLImageElement) {
        promise = engine.createImageBitmap(blob, { premultiplyAlpha: "none" }).then((img) => {
          return _OnImageReadyAsync(img, engine, expandTexture, rgbdPostProcess, url, face, i, generateNonLODTextures, lodTextures, cubeRtt, texture);
        });
      } else {
        const image = new Image();
        image.src = url;
        promise = new Promise((resolve, reject) => {
          image.onload = () => {
            _OnImageReadyAsync(image, engine, expandTexture, rgbdPostProcess, url, face, i, generateNonLODTextures, lodTextures, cubeRtt, texture).then(() => resolve()).catch((reason) => {
              reject(reason);
            });
          };
          image.onerror = (error) => {
            reject(error);
          };
        });
      }
      promises.push(promise);
    }
  }
  if (imageData.length < mipmapsCount) {
    let data;
    const size = Math.pow(2, mipmapsCount - 1 - imageData.length);
    const dataLength = size * size * 4;
    switch (texture.type) {
      case 0: {
        data = new Uint8Array(dataLength);
        break;
      }
      case 2: {
        data = new Uint16Array(dataLength);
        break;
      }
      case 1: {
        data = new Float32Array(dataLength);
        break;
      }
    }
    for (let i = imageData.length; i < mipmapsCount; i++) {
      for (let face = 0; face < 6; face++) {
        engine._uploadArrayBufferViewToTexture(texture, data, face, i);
      }
    }
  }
  return Promise.all(promises).then(() => {
    if (cubeRtt) {
      engine._releaseTexture(texture);
      cubeRtt._swapAndDie(texture);
    }
    if (rgbdPostProcess) {
      rgbdPostProcess.dispose();
    }
    if (generateNonLODTextures) {
      if (texture._lodTextureHigh && texture._lodTextureHigh._texture) {
        texture._lodTextureHigh._texture.isReady = true;
      }
      if (texture._lodTextureMid && texture._lodTextureMid._texture) {
        texture._lodTextureMid._texture.isReady = true;
      }
      if (texture._lodTextureLow && texture._lodTextureLow._texture) {
        texture._lodTextureLow._texture.isReady = true;
      }
    }
  });
}
function UploadEnvSpherical(texture, info) {
  info = normalizeEnvInfo(info);
  const irradianceInfo = info.irradiance;
  if (!irradianceInfo) {
    return;
  }
  const sp = new SphericalPolynomial();
  Vector3.FromArrayToRef(irradianceInfo.x, 0, sp.x);
  Vector3.FromArrayToRef(irradianceInfo.y, 0, sp.y);
  Vector3.FromArrayToRef(irradianceInfo.z, 0, sp.z);
  Vector3.FromArrayToRef(irradianceInfo.xx, 0, sp.xx);
  Vector3.FromArrayToRef(irradianceInfo.yy, 0, sp.yy);
  Vector3.FromArrayToRef(irradianceInfo.zz, 0, sp.zz);
  Vector3.FromArrayToRef(irradianceInfo.yz, 0, sp.yz);
  Vector3.FromArrayToRef(irradianceInfo.zx, 0, sp.zx);
  Vector3.FromArrayToRef(irradianceInfo.xy, 0, sp.xy);
  texture._sphericalPolynomial = sp;
}
function _UpdateRGBDAsync(internalTexture, data, sphericalPolynomial, lodScale, lodOffset) {
  const proxy = internalTexture.getEngine().createRawCubeTexture(null, internalTexture.width, internalTexture.format, internalTexture.type, internalTexture.generateMipMaps, internalTexture.invertY, internalTexture.samplingMode, internalTexture._compression);
  const proxyPromise = UploadLevelsAsync(proxy, data).then(() => internalTexture);
  internalTexture.onRebuildCallback = (_internalTexture) => {
    return {
      proxy: proxyPromise,
      isReady: true,
      isAsync: true
    };
  };
  internalTexture._source = InternalTextureSource.CubeRawRGBD;
  internalTexture._bufferViewArrayArray = data;
  internalTexture._lodGenerationScale = lodScale;
  internalTexture._lodGenerationOffset = lodOffset;
  internalTexture._sphericalPolynomial = sphericalPolynomial;
  return UploadLevelsAsync(internalTexture, data).then(() => {
    internalTexture.isReady = true;
    return internalTexture;
  });
}
var EnvironmentTextureTools = {
  /**
   * Gets the environment info from an env file.
   * @param data The array buffer containing the .env bytes.
   * @returns the environment file info (the json header) if successfully parsed, normalized to the latest supported version.
   */
  GetEnvInfo,
  /**
   * Creates an environment texture from a loaded cube texture.
   * @param texture defines the cube texture to convert in env file
   * @param options options for the conversion process
   * @param options.imageType the mime type for the encoded images, with support for "image/png" (default) and "image/webp"
   * @param options.imageQuality the image quality of encoded WebP images.
   * @returns a promise containing the environment data if successful.
   */
  CreateEnvTextureAsync,
  /**
   * Creates the ArrayBufferViews used for initializing environment texture image data.
   * @param data the image data
   * @param info parameters that determine what views will be created for accessing the underlying buffer
   * @returns the views described by info providing access to the underlying buffer
   */
  CreateImageDataArrayBufferViews,
  /**
   * Uploads the texture info contained in the env file to the GPU.
   * @param texture defines the internal texture to upload to
   * @param data defines the data to load
   * @param info defines the texture info retrieved through the GetEnvInfo method
   * @returns a promise
   */
  UploadEnvLevelsAsync,
  /**
   * Uploads the levels of image data to the GPU.
   * @param texture defines the internal texture to upload to
   * @param imageData defines the array buffer views of image data [mipmap][face]
   * @param imageType the mime type of the image data
   * @returns a promise
   */
  UploadLevelsAsync,
  /**
   * Uploads spherical polynomials information to the texture.
   * @param texture defines the texture we are trying to upload the information to
   * @param info defines the environment texture info retrieved through the GetEnvInfo method
   */
  UploadEnvSpherical
};

// node_modules/@babylonjs/core/Misc/workerPool.js
var WorkerPool = class {
  /**
   * Constructor
   * @param workers Array of workers to use for actions
   */
  constructor(workers) {
    this._pendingActions = new Array();
    this._workerInfos = workers.map((worker) => ({
      workerPromise: Promise.resolve(worker),
      idle: true
    }));
  }
  /**
   * Terminates all workers and clears any pending actions.
   */
  dispose() {
    for (const workerInfo of this._workerInfos) {
      workerInfo.workerPromise.then((worker) => {
        worker.terminate();
      });
    }
    this._workerInfos.length = 0;
    this._pendingActions.length = 0;
  }
  /**
   * Pushes an action to the worker pool. If all the workers are active, the action will be
   * pended until a worker has completed its action.
   * @param action The action to perform. Call onComplete when the action is complete.
   */
  push(action) {
    if (!this._executeOnIdleWorker(action)) {
      this._pendingActions.push(action);
    }
  }
  _executeOnIdleWorker(action) {
    for (const workerInfo of this._workerInfos) {
      if (workerInfo.idle) {
        this._execute(workerInfo, action);
        return true;
      }
    }
    return false;
  }
  _execute(workerInfo, action) {
    workerInfo.idle = false;
    workerInfo.workerPromise.then((worker) => {
      action(worker, () => {
        const nextAction = this._pendingActions.shift();
        if (nextAction) {
          this._execute(workerInfo, nextAction);
        } else {
          workerInfo.idle = true;
        }
      });
    });
  }
};
var AutoReleaseWorkerPool = class _AutoReleaseWorkerPool extends WorkerPool {
  constructor(maxWorkers, createWorkerAsync, options = _AutoReleaseWorkerPool.DefaultOptions) {
    super([]);
    this._maxWorkers = maxWorkers;
    this._createWorkerAsync = createWorkerAsync;
    this._options = options;
  }
  push(action) {
    if (!this._executeOnIdleWorker(action)) {
      if (this._workerInfos.length < this._maxWorkers) {
        const workerInfo = {
          workerPromise: this._createWorkerAsync(),
          idle: false
        };
        this._workerInfos.push(workerInfo);
        this._execute(workerInfo, action);
      } else {
        this._pendingActions.push(action);
      }
    }
  }
  _execute(workerInfo, action) {
    if (workerInfo.timeoutId) {
      clearTimeout(workerInfo.timeoutId);
      delete workerInfo.timeoutId;
    }
    super._execute(workerInfo, (worker, onComplete) => {
      action(worker, () => {
        onComplete();
        if (workerInfo.idle) {
          workerInfo.timeoutId = setTimeout(() => {
            workerInfo.workerPromise.then((worker2) => {
              worker2.terminate();
            });
            const indexOf = this._workerInfos.indexOf(workerInfo);
            if (indexOf !== -1) {
              this._workerInfos.splice(indexOf, 1);
            }
          }, this._options.idleTimeElapsedBeforeRelease);
        }
      });
    });
  }
};
AutoReleaseWorkerPool.DefaultOptions = {
  idleTimeElapsedBeforeRelease: 1e3
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.cubeTexture.js
ThinEngine.prototype._createDepthStencilCubeTexture = function(size, options) {
  const internalTexture = new InternalTexture(this, InternalTextureSource.DepthStencil);
  internalTexture.isCube = true;
  if (this.webGLVersion === 1) {
    Logger.Error("Depth cube texture is not supported by WebGL 1.");
    return internalTexture;
  }
  const internalOptions = {
    bilinearFiltering: false,
    comparisonFunction: 0,
    generateStencil: false,
    ...options
  };
  const gl = this._gl;
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, internalTexture, true);
  this._setupDepthStencilTexture(internalTexture, size, internalOptions.generateStencil, internalOptions.bilinearFiltering, internalOptions.comparisonFunction);
  for (let face = 0; face < 6; face++) {
    if (internalOptions.generateStencil) {
      gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, gl.DEPTH24_STENCIL8, size, size, 0, gl.DEPTH_STENCIL, gl.UNSIGNED_INT_24_8, null);
    } else {
      gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, gl.DEPTH_COMPONENT24, size, size, 0, gl.DEPTH_COMPONENT, gl.UNSIGNED_INT, null);
    }
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
  this._internalTexturesCache.push(internalTexture);
  return internalTexture;
};
ThinEngine.prototype._partialLoadFile = function(url, index, loadedFiles, onfinish, onErrorCallBack = null) {
  const onload = (data) => {
    loadedFiles[index] = data;
    loadedFiles._internalCount++;
    if (loadedFiles._internalCount === 6) {
      onfinish(loadedFiles);
    }
  };
  const onerror = (request, exception) => {
    if (onErrorCallBack && request) {
      onErrorCallBack(request.status + " " + request.statusText, exception);
    }
  };
  this._loadFile(url, onload, void 0, void 0, true, onerror);
};
ThinEngine.prototype._cascadeLoadFiles = function(scene, onfinish, files, onError = null) {
  const loadedFiles = [];
  loadedFiles._internalCount = 0;
  for (let index = 0; index < 6; index++) {
    this._partialLoadFile(files[index], index, loadedFiles, onfinish, onError);
  }
};
ThinEngine.prototype._cascadeLoadImgs = function(scene, texture, onfinish, files, onError = null, mimeType) {
  const loadedImages = [];
  loadedImages._internalCount = 0;
  for (let index = 0; index < 6; index++) {
    this._partialLoadImg(files[index], index, loadedImages, scene, texture, onfinish, onError, mimeType);
  }
};
ThinEngine.prototype._partialLoadImg = function(url, index, loadedImages, scene, texture, onfinish, onErrorCallBack = null, mimeType) {
  const tokenPendingData = RandomGUID();
  const onload = (img) => {
    loadedImages[index] = img;
    loadedImages._internalCount++;
    if (scene) {
      scene.removePendingData(tokenPendingData);
    }
    if (loadedImages._internalCount === 6 && onfinish) {
      onfinish(texture, loadedImages);
    }
  };
  const onerror = (message, exception) => {
    if (scene) {
      scene.removePendingData(tokenPendingData);
    }
    if (onErrorCallBack) {
      onErrorCallBack(message, exception);
    }
  };
  LoadImage(url, onload, onerror, scene ? scene.offlineProvider : null, mimeType);
  if (scene) {
    scene.addPendingData(tokenPendingData);
  }
};
ThinEngine.prototype._setCubeMapTextureParams = function(texture, loadMipmap, maxLevel) {
  const gl = this._gl;
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, loadMipmap ? gl.LINEAR_MIPMAP_LINEAR : gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  texture.samplingMode = loadMipmap ? 3 : 2;
  if (loadMipmap && this.getCaps().textureMaxLevel && maxLevel !== void 0 && maxLevel > 0) {
    gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAX_LEVEL, maxLevel);
    texture._maxLodLevel = maxLevel;
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
};
ThinEngine.prototype.createCubeTextureBase = function(rootUrl, scene, files, noMipmap, onLoad = null, onError = null, format, forcedExtension = null, createPolynomials = false, lodScale = 0, lodOffset = 0, fallback = null, beforeLoadCubeDataCallback = null, imageHandler = null, useSRGBBuffer = false) {
  const texture = fallback ? fallback : new InternalTexture(this, InternalTextureSource.Cube);
  texture.isCube = true;
  texture.url = rootUrl;
  texture.generateMipMaps = !noMipmap;
  texture._lodGenerationScale = lodScale;
  texture._lodGenerationOffset = lodOffset;
  texture._useSRGBBuffer = !!useSRGBBuffer && this._caps.supportSRGBBuffers && (this.webGLVersion > 1 || this.isWebGPU || !!noMipmap);
  if (texture !== fallback) {
    texture.label = rootUrl.substring(0, 60);
  }
  if (!this._doNotHandleContextLost) {
    texture._extension = forcedExtension;
    texture._files = files;
  }
  const originalRootUrl = rootUrl;
  if (this._transformTextureUrl && !fallback) {
    rootUrl = this._transformTextureUrl(rootUrl);
  }
  const rootUrlWithoutUriParams = rootUrl.split("?")[0];
  const lastDot = rootUrlWithoutUriParams.lastIndexOf(".");
  const extension = forcedExtension ? forcedExtension : lastDot > -1 ? rootUrlWithoutUriParams.substring(lastDot).toLowerCase() : "";
  let loader = null;
  for (const availableLoader of ThinEngine._TextureLoaders) {
    if (availableLoader.canLoad(extension)) {
      loader = availableLoader;
      break;
    }
  }
  const onInternalError = (request, exception) => {
    if (rootUrl === originalRootUrl) {
      if (onError && request) {
        onError(request.status + " " + request.statusText, exception);
      }
    } else {
      Logger.Warn(`Failed to load ${rootUrl}, falling back to the ${originalRootUrl}`);
      this.createCubeTextureBase(originalRootUrl, scene, files, !!noMipmap, onLoad, onError, format, forcedExtension, createPolynomials, lodScale, lodOffset, texture, beforeLoadCubeDataCallback, imageHandler, useSRGBBuffer);
    }
  };
  if (loader) {
    const onloaddata = (data) => {
      if (beforeLoadCubeDataCallback) {
        beforeLoadCubeDataCallback(texture, data);
      }
      loader.loadCubeData(data, texture, createPolynomials, onLoad, onError);
    };
    if (files && files.length === 6) {
      if (loader.supportCascades) {
        this._cascadeLoadFiles(scene, (images) => onloaddata(images.map((image) => new Uint8Array(image))), files, onError);
      } else {
        if (onError) {
          onError("Textures type does not support cascades.");
        } else {
          Logger.Warn("Texture loader does not support cascades.");
        }
      }
    } else {
      this._loadFile(rootUrl, (data) => onloaddata(new Uint8Array(data)), void 0, void 0, true, onInternalError);
    }
  } else {
    if (!files || files.length === 0) {
      throw new Error("Cannot load cubemap because files were not defined, or the correct loader was not found.");
    }
    this._cascadeLoadImgs(scene, texture, (texture2, imgs) => {
      if (imageHandler) {
        imageHandler(texture2, imgs);
      }
    }, files, onError);
  }
  this._internalTexturesCache.push(texture);
  return texture;
};
ThinEngine.prototype.createCubeTexture = function(rootUrl, scene, files, noMipmap, onLoad = null, onError = null, format, forcedExtension = null, createPolynomials = false, lodScale = 0, lodOffset = 0, fallback = null, loaderOptions, useSRGBBuffer = false) {
  const gl = this._gl;
  return this.createCubeTextureBase(rootUrl, scene, files, !!noMipmap, onLoad, onError, format, forcedExtension, createPolynomials, lodScale, lodOffset, fallback, (texture) => this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true), (texture, imgs) => {
    const width = this.needPOTTextures ? ThinEngine.GetExponentOfTwo(imgs[0].width, this._caps.maxCubemapTextureSize) : imgs[0].width;
    const height = width;
    const faces = [
      gl.TEXTURE_CUBE_MAP_POSITIVE_X,
      gl.TEXTURE_CUBE_MAP_POSITIVE_Y,
      gl.TEXTURE_CUBE_MAP_POSITIVE_Z,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_X,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_Y,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_Z
    ];
    this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
    this._unpackFlipY(false);
    const internalFormat = format ? this._getInternalFormat(format, texture._useSRGBBuffer) : texture._useSRGBBuffer ? this._glSRGBExtensionValues.SRGB8_ALPHA8 : gl.RGBA;
    let texelFormat = format ? this._getInternalFormat(format) : gl.RGBA;
    if (texture._useSRGBBuffer && this.webGLVersion === 1) {
      texelFormat = internalFormat;
    }
    for (let index = 0; index < faces.length; index++) {
      if (imgs[index].width !== width || imgs[index].height !== height) {
        this._prepareWorkingCanvas();
        if (!this._workingCanvas || !this._workingContext) {
          Logger.Warn("Cannot create canvas to resize texture.");
          return;
        }
        this._workingCanvas.width = width;
        this._workingCanvas.height = height;
        this._workingContext.drawImage(imgs[index], 0, 0, imgs[index].width, imgs[index].height, 0, 0, width, height);
        gl.texImage2D(faces[index], 0, internalFormat, texelFormat, gl.UNSIGNED_BYTE, this._workingCanvas);
      } else {
        gl.texImage2D(faces[index], 0, internalFormat, texelFormat, gl.UNSIGNED_BYTE, imgs[index]);
      }
    }
    if (!noMipmap) {
      gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
    }
    this._setCubeMapTextureParams(texture, !noMipmap);
    texture.width = width;
    texture.height = height;
    texture.isReady = true;
    if (format) {
      texture.format = format;
    }
    texture.onLoadedObservable.notifyObservers(texture);
    texture.onLoadedObservable.clear();
    if (onLoad) {
      onLoad();
    }
  }, !!useSRGBBuffer);
};

export {
  Size,
  Space,
  Axis,
  Coordinate,
  Orientation,
  BezierCurve,
  Angle,
  Arc2,
  Path2,
  Path3D,
  Curve3,
  Viewport,
  CompatibilityOptions,
  PerformanceMonitor,
  RollingAverage,
  allocateAndCopyTypedBuffer,
  Engine,
  ThinTexture,
  BaseTexture,
  GenerateBase64StringFromPixelData,
  GenerateBase64StringFromTexture,
  GenerateBase64StringFromTextureAsync,
  CopyTools,
  Texture,
  PositionNormalVertex,
  PositionNormalTextureVertex,
  RenderTargetWrapper,
  PostProcess,
  EffectRenderer,
  EffectWrapper,
  DumpTools,
  RenderTargetTexture,
  PassPostProcess,
  PassCubePostProcess,
  SphericalHarmonics,
  SphericalPolynomial,
  CreateResizedCopy,
  ApplyPostProcess,
  ToHalfFloat,
  FromHalfFloat,
  GetTextureDataAsync,
  TextureTools,
  RGBDTextureTools,
  CubeMapToSphericalPolynomialTools,
  GetEnvInfo,
  normalizeEnvInfo,
  CreateEnvTextureAsync,
  CreateImageDataArrayBufferViews,
  UploadEnvLevelsAsync,
  UploadLevelsAsync,
  UploadEnvSpherical,
  _UpdateRGBDAsync,
  EnvironmentTextureTools,
  WorkerPool,
  AutoReleaseWorkerPool
};
//# sourceMappingURL=chunk-QYYEDPSX.js.map
